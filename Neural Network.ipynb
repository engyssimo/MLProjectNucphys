{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a33ddaf",
   "metadata": {},
   "source": [
    "### Import independencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f99868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import random, seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5eb34",
   "metadata": {},
   "source": [
    "# Part I: Data overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaeea9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n",
      "None\n",
      "----------------------------\n",
      "(145460, 23)\n"
     ]
    }
   ],
   "source": [
    "# Loading our dataset \n",
    "data = pd.read_csv('weatherAUS.csv')\n",
    "print(data.info())\n",
    "print(\"----------------------------\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de607774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>...</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
       "0   Albury     13.4     22.9       0.6          NaN       NaN           W   \n",
       "1   Albury      7.4     25.1       0.0          NaN       NaN         WNW   \n",
       "2   Albury     12.9     25.7       0.0          NaN       NaN         WSW   \n",
       "3   Albury      9.2     28.0       0.0          NaN       NaN          NE   \n",
       "4   Albury     17.5     32.3       1.0          NaN       NaN           W   \n",
       "\n",
       "   WindGustSpeed WindDir9am WindDir3pm  ...  Pressure3pm  Cloud9am  Cloud3pm  \\\n",
       "0           44.0          W        WNW  ...       1007.1       8.0       NaN   \n",
       "1           44.0        NNW        WSW  ...       1007.8       NaN       NaN   \n",
       "2           46.0          W        WSW  ...       1008.7       NaN       2.0   \n",
       "3           24.0         SE          E  ...       1012.8       NaN       NaN   \n",
       "4           41.0        ENE         NW  ...       1006.0       7.0       8.0   \n",
       "\n",
       "   Temp9am  Temp3pm  RainToday  RainTomorrow  Year  Month  Day  \n",
       "0     16.9     21.8         No            No  2008     12    1  \n",
       "1     17.2     24.3         No            No  2008     12    2  \n",
       "2     21.0     23.2         No            No  2008     12    3  \n",
       "3     18.1     26.5         No            No  2008     12    4  \n",
       "4     17.8     29.7         No            No  2008     12    5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our dataset \n",
    "data = pd.read_csv('weatherAUS.csv')\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])       # Change to datetime type so we can then divide into year , month and day\n",
    "data[\"Year\"] = data[\"Date\"].dt.year\n",
    "data[\"Month\"] = data[\"Date\"].dt.month\n",
    "data[\"Day\"] = data[\"Date\"].dt.day\n",
    "data.drop(\"Date\",axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0256499a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "Year                 0\n",
       "Month                0\n",
       "Day                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a98646",
   "metadata": {},
   "source": [
    "# Part II: Data preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5194a1",
   "metadata": {},
   "source": [
    "## A. Categorical features:  Replace missing values by common and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbf3a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>WNW</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>WSW</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>NE</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>W</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location WindGustDir WindDir9am WindDir3pm RainToday RainTomorrow\n",
       "0   Albury           W          W        WNW        No           No\n",
       "1   Albury         WNW        NNW        WSW        No           No\n",
       "2   Albury         WSW          W        WSW        No           No\n",
       "3   Albury          NE         SE          E        No           No\n",
       "4   Albury           W        ENE         NW        No           No"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical feature\n",
    "cat_feature = [i for i in data.columns if data[i].dtype=='O']\n",
    "data[cat_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e03c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_feature:\n",
    "    if data[col].isnull().sum() !=0 : \n",
    "        common = data[col].mode()[0]         # returns the most frequent value \n",
    "        data[col] = data[col].fillna(common)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85723f5a",
   "metadata": {},
   "source": [
    "## B: Model\n",
    "Two models are used, Convolutional and Fully_dense => Try to play with design of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2965431d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29b4c621310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "array  = image.imread('design.png')\n",
    "plt.figure(figsize = (20,6))\n",
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d03bafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense , Dropout, Conv1D, Reshape, BatchNormalization as BN\n",
    "import tensorflow as tf\n",
    "\n",
    "def train_model(model, name, train_data, val_data, batch_size=100, epochs=15):\n",
    "    def lr_scheduler(epochs):\n",
    "        if epochs < 10:\n",
    "            return 1e-3\n",
    "        else:\n",
    "            if epochs < 20:\n",
    "                return 1e-4\n",
    "            else:\n",
    "                return 1e-5\n",
    "\n",
    "    filepath =  './models/' + name + '.hdf5'\n",
    "    saving = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                monitor='val_accuracy',\n",
    "                                                save_best_only=True,\n",
    "                                                 save_weights_only=True)\n",
    "    history = model.fit(\n",
    "    train_data[0], train_data[1],\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_data,\n",
    "    verbose=2,\n",
    "    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler), saving]\n",
    "    )   \n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def fully_dense_model(num_features, train_data, val_data, \n",
    "                      units=32, activation='tanh', rate=0.1):\n",
    "    inputs = tf.keras.layers.Input(shape=(num_features,))\n",
    "    x = Dense(4*units, activation=activation)(inputs)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Dense(2*units, activation=activation)(x)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Dense(units, activation=activation)(x)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    name = 'fully_dense_num-features=' + str(num_features)\n",
    "    file_path = './models/' + name + '.hdf5'\n",
    "    train_model(model, name, train_data, val_data)\n",
    "    model.load_weights(file_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def convolution_model(num_features, train_data, val_data, \n",
    "                      units=128, channels=16, kernel_size=5, \n",
    "                      activation='tanh', rate=0.1):\n",
    "    inputs = tf.keras.layers.Input(shape=(num_features,))\n",
    "    x = Dense(units, activation=activation)(inputs)\n",
    "    x = Reshape((units, 1))(x)\n",
    "    x = BN()(x)\n",
    "    x = Conv1D(2*channels, kernel_size, activation=activation)(x)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Conv1D(channels, kernel_size, activation=activation)(x)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Conv1D(1, kernel_size, activation=activation)(x)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    name = 'convolution_num-features=' + str(num_features)\n",
    "    file_path = './models/' + name + '.hdf5'\n",
    "    train_model(model, name, train_data, val_data)\n",
    "    model.load_weights(file_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd6039",
   "metadata": {},
   "source": [
    "## C: Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed72f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "698f7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical variables to numeric ones\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in cat_feature:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(df[col].values))\n",
    "    df[col] = lbl.transform(df[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd58b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
       "0         2     13.4     22.9       0.6          NaN       NaN           13   \n",
       "1         2      7.4     25.1       0.0          NaN       NaN           14   \n",
       "2         2     12.9     25.7       0.0          NaN       NaN           15   \n",
       "3         2      9.2     28.0       0.0          NaN       NaN            4   \n",
       "4         2     17.5     32.3       1.0          NaN       NaN           13   \n",
       "\n",
       "   WindGustSpeed  WindDir9am  WindDir3pm  ...  Pressure3pm  Cloud9am  \\\n",
       "0           44.0          13          14  ...       1007.1       8.0   \n",
       "1           44.0           6          15  ...       1007.8       NaN   \n",
       "2           46.0          13          15  ...       1008.7       NaN   \n",
       "3           24.0           9           0  ...       1012.8       NaN   \n",
       "4           41.0           1           7  ...       1006.0       7.0   \n",
       "\n",
       "   Cloud3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  Year  Month  Day  \n",
       "0       NaN     16.9     21.8          0             0  2008     12    1  \n",
       "1       NaN     17.2     24.3          0             0  2008     12    2  \n",
       "2       2.0     21.0     23.2          0             0  2008     12    3  \n",
       "3       NaN     18.1     26.5          0             0  2008     12    4  \n",
       "4       8.0     17.8     29.7          0             0  2008     12    5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603e196",
   "metadata": {},
   "source": [
    "## D: Handle NaN values: replaced by mean values \n",
    "This part should be seperated between train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac7d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_drop = []\n",
    "frac = np.arange(0,0.9,0.1)\n",
    "N = len(df.index)\n",
    "for f in frac:\n",
    "    buff = [i for i in df.columns if (df[i].isnull().sum())/N > f ]\n",
    "    n_drop.append(len(buff))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79985f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29b4c2d4520>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(frac, n_drop, 'o--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e0305d",
   "metadata": {},
   "source": [
    "Then i would choose different slpitting rate of 0.1, 0.2, 0.3, 0.4 and 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74898e",
   "metadata": {},
   "source": [
    "## Part III: Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27664d63",
   "metadata": {},
   "source": [
    "Split and standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2df20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "nan_col = [i for i in df.columns if df[i].isnull().sum() != 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59dd57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_handle_nan(X_train, X_test, nan_frac):\n",
    "    global nan_col,df\n",
    "    buff = [i for i in nan_col if (df[i].isnull().sum())/N < nan_frac]\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    for col in  nan_col:\n",
    "        if col in buff:\n",
    "            X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
    "            X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
    "        else:\n",
    "            X_train = X_train.drop(columns=col)\n",
    "            X_test = X_test.drop(columns=col)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0ca3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df,test_size=0.2, random_state=0)\n",
    "X_train = df_train.drop([\"RainTomorrow\"], axis=1)\n",
    "y_train = df_train.RainTomorrow\n",
    "X_test = df_test.drop([\"RainTomorrow\"], axis=1)\n",
    "y_test = df_test.RainTomorrow\n",
    "X_train,X_test = mean_handle_nan(X_train,X_test, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b011bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da86baca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1164/1164 [==============================] - 8s 6ms/step - loss: 0.3779 - binary_accuracy: 0.8397 - val_loss: 0.3701 - val_binary_accuracy: 0.8436\n",
      "Epoch 2/15\n",
      "1164/1164 [==============================] - 7s 6ms/step - loss: 0.3672 - binary_accuracy: 0.8434 - val_loss: 0.3645 - val_binary_accuracy: 0.8447\n",
      "Epoch 3/15\n",
      "1164/1164 [==============================] - 7s 6ms/step - loss: 0.3623 - binary_accuracy: 0.8456 - val_loss: 0.3673 - val_binary_accuracy: 0.8447\n",
      "Epoch 4/15\n",
      "1164/1164 [==============================] - 7s 6ms/step - loss: 0.3579 - binary_accuracy: 0.8466 - val_loss: 0.3606 - val_binary_accuracy: 0.8468\n",
      "Epoch 5/15\n",
      "1164/1164 [==============================] - 7s 6ms/step - loss: 0.3548 - binary_accuracy: 0.8482 - val_loss: 0.3597 - val_binary_accuracy: 0.8466\n",
      "Epoch 6/15\n",
      "1164/1164 [==============================] - 7s 6ms/step - loss: 0.3507 - binary_accuracy: 0.8498 - val_loss: 0.3609 - val_binary_accuracy: 0.8488\n",
      "Epoch 7/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3473 - binary_accuracy: 0.8516 - val_loss: 0.3620 - val_binary_accuracy: 0.8474\n",
      "Epoch 8/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3433 - binary_accuracy: 0.8538 - val_loss: 0.3568 - val_binary_accuracy: 0.8482\n",
      "Epoch 9/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3395 - binary_accuracy: 0.8549 - val_loss: 0.3574 - val_binary_accuracy: 0.8498\n",
      "Epoch 10/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3352 - binary_accuracy: 0.8574 - val_loss: 0.3583 - val_binary_accuracy: 0.8473\n",
      "Epoch 11/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3308 - binary_accuracy: 0.8594 - val_loss: 0.3597 - val_binary_accuracy: 0.8474\n",
      "Epoch 12/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3260 - binary_accuracy: 0.8616 - val_loss: 0.3617 - val_binary_accuracy: 0.8471\n",
      "Epoch 13/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3208 - binary_accuracy: 0.8638 - val_loss: 0.3658 - val_binary_accuracy: 0.8467\n",
      "Epoch 14/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3147 - binary_accuracy: 0.8670 - val_loss: 0.3653 - val_binary_accuracy: 0.8442\n",
      "Epoch 15/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3090 - binary_accuracy: 0.8692 - val_loss: 0.3673 - val_binary_accuracy: 0.8478\n",
      "binary_accuracy: 84.78%\n"
     ]
    }
   ],
   "source": [
    " # create model\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim= X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(712, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping( patience = 12, min_delta = 0.001,\n",
    "                                               restore_best_weights =True )\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, epochs= 15, batch_size=100, \n",
    "                     validation_data=(X_test, y_test),\n",
    "                    verbose=1)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff5918d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3769 - binary_accuracy: 0.8395 - val_loss: 0.3664 - val_binary_accuracy: 0.8442\n",
      "Epoch 2/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3669 - binary_accuracy: 0.8441 - val_loss: 0.3673 - val_binary_accuracy: 0.8448\n",
      "Epoch 3/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3619 - binary_accuracy: 0.8454 - val_loss: 0.3615 - val_binary_accuracy: 0.8473\n",
      "Epoch 4/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3577 - binary_accuracy: 0.8467 - val_loss: 0.3589 - val_binary_accuracy: 0.8487\n",
      "Epoch 5/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3540 - binary_accuracy: 0.8484 - val_loss: 0.3586 - val_binary_accuracy: 0.8488\n",
      "Epoch 6/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3502 - binary_accuracy: 0.8506 - val_loss: 0.3611 - val_binary_accuracy: 0.8488\n",
      "Epoch 7/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3469 - binary_accuracy: 0.8516 - val_loss: 0.3587 - val_binary_accuracy: 0.8487\n",
      "Epoch 8/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3432 - binary_accuracy: 0.8532 - val_loss: 0.3613 - val_binary_accuracy: 0.8481\n",
      "Epoch 9/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3387 - binary_accuracy: 0.8555 - val_loss: 0.3563 - val_binary_accuracy: 0.8496\n",
      "Epoch 10/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3351 - binary_accuracy: 0.8574 - val_loss: 0.3604 - val_binary_accuracy: 0.8476\n",
      "Epoch 11/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3308 - binary_accuracy: 0.8594 - val_loss: 0.3612 - val_binary_accuracy: 0.8480\n",
      "Epoch 12/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3249 - binary_accuracy: 0.8621 - val_loss: 0.3608 - val_binary_accuracy: 0.8470\n",
      "Epoch 13/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3201 - binary_accuracy: 0.8632 - val_loss: 0.3686 - val_binary_accuracy: 0.8466\n",
      "Epoch 14/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3141 - binary_accuracy: 0.8661 - val_loss: 0.3714 - val_binary_accuracy: 0.8451\n",
      "Epoch 15/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3083 - binary_accuracy: 0.8697 - val_loss: 0.3761 - val_binary_accuracy: 0.8454\n",
      "binary_accuracy: 84.54%\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3761 - binary_accuracy: 0.8454\n",
      "Epoch 1/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3640 - binary_accuracy: 0.8432 - val_loss: 0.3555 - val_binary_accuracy: 0.8477\n",
      "Epoch 2/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3518 - binary_accuracy: 0.8486 - val_loss: 0.3515 - val_binary_accuracy: 0.8508\n",
      "Epoch 3/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3464 - binary_accuracy: 0.8507 - val_loss: 0.3484 - val_binary_accuracy: 0.8508\n",
      "Epoch 4/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3410 - binary_accuracy: 0.8536 - val_loss: 0.3454 - val_binary_accuracy: 0.8518\n",
      "Epoch 5/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3369 - binary_accuracy: 0.8547 - val_loss: 0.3460 - val_binary_accuracy: 0.8541\n",
      "Epoch 6/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3331 - binary_accuracy: 0.8576 - val_loss: 0.3445 - val_binary_accuracy: 0.8521\n",
      "Epoch 7/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3291 - binary_accuracy: 0.8583 - val_loss: 0.3425 - val_binary_accuracy: 0.8538\n",
      "Epoch 8/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3246 - binary_accuracy: 0.8607 - val_loss: 0.3436 - val_binary_accuracy: 0.8520\n",
      "Epoch 9/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3201 - binary_accuracy: 0.8631 - val_loss: 0.3457 - val_binary_accuracy: 0.8535\n",
      "Epoch 10/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3146 - binary_accuracy: 0.8649 - val_loss: 0.3443 - val_binary_accuracy: 0.8524\n",
      "Epoch 11/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3090 - binary_accuracy: 0.8679 - val_loss: 0.3476 - val_binary_accuracy: 0.8525\n",
      "Epoch 12/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3034 - binary_accuracy: 0.8707 - val_loss: 0.3465 - val_binary_accuracy: 0.8516\n",
      "Epoch 13/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2959 - binary_accuracy: 0.8745 - val_loss: 0.3543 - val_binary_accuracy: 0.8499\n",
      "Epoch 14/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2893 - binary_accuracy: 0.8767 - val_loss: 0.3568 - val_binary_accuracy: 0.8502\n",
      "Epoch 15/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2807 - binary_accuracy: 0.8811 - val_loss: 0.3578 - val_binary_accuracy: 0.8494\n",
      "binary_accuracy: 84.94%\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3578 - binary_accuracy: 0.8494\n",
      "Epoch 1/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3651 - binary_accuracy: 0.8433 - val_loss: 0.3545 - val_binary_accuracy: 0.8480\n",
      "Epoch 2/15\n",
      "1164/1164 [==============================] - 9s 8ms/step - loss: 0.3517 - binary_accuracy: 0.8485 - val_loss: 0.3578 - val_binary_accuracy: 0.8492\n",
      "Epoch 3/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3471 - binary_accuracy: 0.8509 - val_loss: 0.3520 - val_binary_accuracy: 0.8493\n",
      "Epoch 4/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3419 - binary_accuracy: 0.8531 - val_loss: 0.3511 - val_binary_accuracy: 0.8515\n",
      "Epoch 5/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3376 - binary_accuracy: 0.8545 - val_loss: 0.3465 - val_binary_accuracy: 0.8535\n",
      "Epoch 6/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3338 - binary_accuracy: 0.8558 - val_loss: 0.3439 - val_binary_accuracy: 0.8534\n",
      "Epoch 7/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3301 - binary_accuracy: 0.8583 - val_loss: 0.3421 - val_binary_accuracy: 0.8553\n",
      "Epoch 8/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3257 - binary_accuracy: 0.8599 - val_loss: 0.3418 - val_binary_accuracy: 0.8542\n",
      "Epoch 9/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3210 - binary_accuracy: 0.8626 - val_loss: 0.3422 - val_binary_accuracy: 0.8540\n",
      "Epoch 10/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3166 - binary_accuracy: 0.8642 - val_loss: 0.3429 - val_binary_accuracy: 0.8532\n",
      "Epoch 11/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3110 - binary_accuracy: 0.8672 - val_loss: 0.3444 - val_binary_accuracy: 0.8524\n",
      "Epoch 12/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3046 - binary_accuracy: 0.8698 - val_loss: 0.3457 - val_binary_accuracy: 0.8530\n",
      "Epoch 13/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2987 - binary_accuracy: 0.8731 - val_loss: 0.3531 - val_binary_accuracy: 0.8506\n",
      "Epoch 14/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2913 - binary_accuracy: 0.8753 - val_loss: 0.3539 - val_binary_accuracy: 0.8510\n",
      "Epoch 15/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2845 - binary_accuracy: 0.8792 - val_loss: 0.3574 - val_binary_accuracy: 0.8490\n",
      "binary_accuracy: 84.90%\n",
      "910/910 [==============================] - ETA: 0s - loss: 0.3575 - binary_accuracy: 0.8487- ETA: 0s - loss: 0.3572 - binary_accuracy: 0 - 2s 2ms/step - loss: 0.3574 - binary_accuracy: 0.8490\n",
      "Epoch 1/15\n",
      "1164/1164 [==============================] - 9s 7ms/step - loss: 0.3627 - binary_accuracy: 0.8440 - val_loss: 0.3554 - val_binary_accuracy: 0.8488\n",
      "Epoch 2/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3508 - binary_accuracy: 0.8483 - val_loss: 0.3508 - val_binary_accuracy: 0.8511\n",
      "Epoch 3/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3448 - binary_accuracy: 0.8514 - val_loss: 0.3516 - val_binary_accuracy: 0.8512\n",
      "Epoch 4/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3408 - binary_accuracy: 0.8538 - val_loss: 0.3431 - val_binary_accuracy: 0.8534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3364 - binary_accuracy: 0.8555 - val_loss: 0.3459 - val_binary_accuracy: 0.8529\n",
      "Epoch 6/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3323 - binary_accuracy: 0.8571 - val_loss: 0.3452 - val_binary_accuracy: 0.8522\n",
      "Epoch 7/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3281 - binary_accuracy: 0.8592 - val_loss: 0.3455 - val_binary_accuracy: 0.8539\n",
      "Epoch 8/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3232 - binary_accuracy: 0.8609 - val_loss: 0.3413 - val_binary_accuracy: 0.8534\n",
      "Epoch 9/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3178 - binary_accuracy: 0.8640 - val_loss: 0.3437 - val_binary_accuracy: 0.8525\n",
      "Epoch 10/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3116 - binary_accuracy: 0.8662 - val_loss: 0.3447 - val_binary_accuracy: 0.8526\n",
      "Epoch 11/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3060 - binary_accuracy: 0.8697 - val_loss: 0.3446 - val_binary_accuracy: 0.8511\n",
      "Epoch 12/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2986 - binary_accuracy: 0.8731 - val_loss: 0.3476 - val_binary_accuracy: 0.8516\n",
      "Epoch 13/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2911 - binary_accuracy: 0.8762 - val_loss: 0.3515 - val_binary_accuracy: 0.8509\n",
      "Epoch 14/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2830 - binary_accuracy: 0.8806 - val_loss: 0.3594 - val_binary_accuracy: 0.8506\n",
      "Epoch 15/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2746 - binary_accuracy: 0.8843 - val_loss: 0.3672 - val_binary_accuracy: 0.8478\n",
      "binary_accuracy: 84.78%\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3672 - binary_accuracy: 0.8478A: 1s - loss: 0.3745 - binary_accuracy: 0. - ETA: 0s - loss: 0.3742 - binary - ETA: 0s - loss: 0.3676 - binary_accuracy: 0.847\n",
      "Epoch 1/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3561 - binary_accuracy: 0.8452 - val_loss: 0.3474 - val_binary_accuracy: 0.8502\n",
      "Epoch 2/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3437 - binary_accuracy: 0.8513 - val_loss: 0.3451 - val_binary_accuracy: 0.8517\n",
      "Epoch 3/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3374 - binary_accuracy: 0.8553 - val_loss: 0.3400 - val_binary_accuracy: 0.8537\n",
      "Epoch 4/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3328 - binary_accuracy: 0.8562 - val_loss: 0.3424 - val_binary_accuracy: 0.8537\n",
      "Epoch 5/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3281 - binary_accuracy: 0.8588 - val_loss: 0.3370 - val_binary_accuracy: 0.8542\n",
      "Epoch 6/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3232 - binary_accuracy: 0.8611 - val_loss: 0.3380 - val_binary_accuracy: 0.8540\n",
      "Epoch 7/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3177 - binary_accuracy: 0.8636 - val_loss: 0.3392 - val_binary_accuracy: 0.8537\n",
      "Epoch 8/15\n",
      "1164/1164 [==============================] - 9s 7ms/step - loss: 0.3121 - binary_accuracy: 0.8661 - val_loss: 0.3423 - val_binary_accuracy: 0.8536\n",
      "Epoch 9/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.3065 - binary_accuracy: 0.8682 - val_loss: 0.3364 - val_binary_accuracy: 0.8554\n",
      "Epoch 10/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2992 - binary_accuracy: 0.8715 - val_loss: 0.3442 - val_binary_accuracy: 0.8553\n",
      "Epoch 11/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2915 - binary_accuracy: 0.8758 - val_loss: 0.3444 - val_binary_accuracy: 0.8515\n",
      "Epoch 12/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2827 - binary_accuracy: 0.8799 - val_loss: 0.3432 - val_binary_accuracy: 0.8538\n",
      "Epoch 13/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2726 - binary_accuracy: 0.8850 - val_loss: 0.3558 - val_binary_accuracy: 0.8508\n",
      "Epoch 14/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2622 - binary_accuracy: 0.8887 - val_loss: 0.3619 - val_binary_accuracy: 0.8478\n",
      "Epoch 15/15\n",
      "1164/1164 [==============================] - 8s 7ms/step - loss: 0.2501 - binary_accuracy: 0.8952 - val_loss: 0.3657 - val_binary_accuracy: 0.8489\n",
      "binary_accuracy: 84.89%\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3657 - binary_accuracy: 0.8489\n"
     ]
    }
   ],
   "source": [
    "best_model= None\n",
    "best_rate=0\n",
    "best = 0\n",
    "\n",
    "f= open(\"results2.txt\",\"w+\")\n",
    "f.write('invalid_rate , features , accuracy \\n' )\n",
    "for invalid_rate in [0.1,0.2,0.3, 0.4,0.5]:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df,test_size=0.2, random_state=0)\n",
    "    X_train = df_train.drop([\"RainTomorrow\"], axis=1)\n",
    "    y_train = df_train.RainTomorrow\n",
    "    X_test = df_test.drop([\"RainTomorrow\"], axis=1)\n",
    "    y_test = df_test.RainTomorrow\n",
    "    \n",
    "    X_train,X_test = mean_handle_nan(X_train,X_test, invalid_rate)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train= scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    model = Sequential()\n",
    "    num_features = X_train.shape[1]\n",
    "    model.add(Dense(1024, input_dim= num_features, activation='relu'))\n",
    "    model.add(Dense(712, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping( patience = 12, min_delta = 0.001,\n",
    "                                                   restore_best_weights =True )\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train, epochs= 15, batch_size=100, \n",
    "                     validation_data=(X_test, y_test),\n",
    "                    verbose=1)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    loss, accuracy = model.evaluate(X_test,y_test)\n",
    "    string = str(invalid_rate)+' '+str(num_features)+' '+str(accuracy) +'\\n'\n",
    "    f.write(string)\n",
    "    if best < accuracy:\n",
    "            best = accuracy\n",
    "            best_rate = invalid_rate\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14a63b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rate:  0.2 best accuracy:  0.8494431376457214\n"
     ]
    }
   ],
   "source": [
    "print('best rate: ', best_rate, 'best accuracy: ', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814b51f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               3200      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 1)           4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 124, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 120, 16)          64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 116, 1)           4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 116)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,366\n",
      "Trainable params: 6,266\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 26s - loss: 0.3841 - accuracy: 0.8316 - val_loss: 0.3550 - val_accuracy: 0.8478 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 25s - loss: 0.3559 - accuracy: 0.8466 - val_loss: 0.3518 - val_accuracy: 0.8499 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 25s - loss: 0.3500 - accuracy: 0.8489 - val_loss: 0.3489 - val_accuracy: 0.8493 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 25s - loss: 0.3464 - accuracy: 0.8503 - val_loss: 0.3458 - val_accuracy: 0.8512 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 25s - loss: 0.3446 - accuracy: 0.8514 - val_loss: 0.3451 - val_accuracy: 0.8521 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 25s - loss: 0.3418 - accuracy: 0.8527 - val_loss: 0.3436 - val_accuracy: 0.8518 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 25s - loss: 0.3409 - accuracy: 0.8532 - val_loss: 0.3422 - val_accuracy: 0.8543 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 24s - loss: 0.3392 - accuracy: 0.8542 - val_loss: 0.3434 - val_accuracy: 0.8526 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 24s - loss: 0.3378 - accuracy: 0.8543 - val_loss: 0.3414 - val_accuracy: 0.8553 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 25s - loss: 0.3371 - accuracy: 0.8545 - val_loss: 0.3414 - val_accuracy: 0.8548 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 24s - loss: 0.3319 - accuracy: 0.8570 - val_loss: 0.3401 - val_accuracy: 0.8550 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 24s - loss: 0.3299 - accuracy: 0.8583 - val_loss: 0.3400 - val_accuracy: 0.8549 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 24s - loss: 0.3292 - accuracy: 0.8582 - val_loss: 0.3400 - val_accuracy: 0.8547 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 24s - loss: 0.3293 - accuracy: 0.8579 - val_loss: 0.3399 - val_accuracy: 0.8552 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 25s - loss: 0.3288 - accuracy: 0.8587 - val_loss: 0.3402 - val_accuracy: 0.8551 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "num_features = X_train.shape[1]\n",
    "model = convolution_model(num_features, (X_train,y_train), (X_test, y_test), units=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dd67a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3414 - accuracy: 0.8553\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e30e648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               3200      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,465\n",
      "Trainable params: 14,017\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 7s - loss: 0.4042 - accuracy: 0.8204 - val_loss: 0.3577 - val_accuracy: 0.8449 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 4s - loss: 0.3656 - accuracy: 0.8412 - val_loss: 0.3576 - val_accuracy: 0.8452 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 4s - loss: 0.3584 - accuracy: 0.8448 - val_loss: 0.3494 - val_accuracy: 0.8483 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 3s - loss: 0.3554 - accuracy: 0.8465 - val_loss: 0.3511 - val_accuracy: 0.8482 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 8s - loss: 0.3535 - accuracy: 0.8473 - val_loss: 0.3475 - val_accuracy: 0.8511 - lr: 0.0010 - 8s/epoch - 7ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 3s - loss: 0.3514 - accuracy: 0.8483 - val_loss: 0.3466 - val_accuracy: 0.8515 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 3s - loss: 0.3492 - accuracy: 0.8489 - val_loss: 0.3457 - val_accuracy: 0.8506 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 7s - loss: 0.3473 - accuracy: 0.8496 - val_loss: 0.3458 - val_accuracy: 0.8512 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 3s - loss: 0.3466 - accuracy: 0.8497 - val_loss: 0.3445 - val_accuracy: 0.8529 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 3s - loss: 0.3455 - accuracy: 0.8506 - val_loss: 0.3442 - val_accuracy: 0.8526 - lr: 0.0010 - 3s/epoch - 2ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 3s - loss: 0.3410 - accuracy: 0.8529 - val_loss: 0.3416 - val_accuracy: 0.8540 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 3s - loss: 0.3395 - accuracy: 0.8533 - val_loss: 0.3411 - val_accuracy: 0.8537 - lr: 1.0000e-04 - 3s/epoch - 2ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 4s - loss: 0.3389 - accuracy: 0.8535 - val_loss: 0.3406 - val_accuracy: 0.8537 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 3s - loss: 0.3383 - accuracy: 0.8538 - val_loss: 0.3406 - val_accuracy: 0.8540 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 4s - loss: 0.3385 - accuracy: 0.8542 - val_loss: 0.3408 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "910/910 [==============================] - 1s 729us/step - loss: 0.3416 - accuracy: 0.8540\n"
     ]
    }
   ],
   "source": [
    "model = fully_dense_model(num_features,  (X_train,y_train), (X_test, y_test), units=32)\n",
    "loss, accuracy = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339fc83f",
   "metadata": {},
   "source": [
    "## Part IV: Choosing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88ac4a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 18)]              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               2432      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,697\n",
      "Trainable params: 13,249\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 7s - loss: 0.4208 - accuracy: 0.8149 - val_loss: 0.3771 - val_accuracy: 0.8398 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 3s - loss: 0.3852 - accuracy: 0.8362 - val_loss: 0.3728 - val_accuracy: 0.8412 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 5s - loss: 0.3799 - accuracy: 0.8381 - val_loss: 0.3703 - val_accuracy: 0.8433 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 3s - loss: 0.3769 - accuracy: 0.8392 - val_loss: 0.3694 - val_accuracy: 0.8424 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 6s - loss: 0.3750 - accuracy: 0.8396 - val_loss: 0.3697 - val_accuracy: 0.8430 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 3s - loss: 0.3740 - accuracy: 0.8412 - val_loss: 0.3697 - val_accuracy: 0.8421 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 5s - loss: 0.3728 - accuracy: 0.8406 - val_loss: 0.3667 - val_accuracy: 0.8447 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 3s - loss: 0.3710 - accuracy: 0.8419 - val_loss: 0.3646 - val_accuracy: 0.8459 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 3s - loss: 0.3697 - accuracy: 0.8426 - val_loss: 0.3648 - val_accuracy: 0.8451 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 3s - loss: 0.3689 - accuracy: 0.8423 - val_loss: 0.3633 - val_accuracy: 0.8467 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 3s - loss: 0.3646 - accuracy: 0.8445 - val_loss: 0.3616 - val_accuracy: 0.8471 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 5s - loss: 0.3641 - accuracy: 0.8443 - val_loss: 0.3611 - val_accuracy: 0.8471 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 3s - loss: 0.3631 - accuracy: 0.8451 - val_loss: 0.3610 - val_accuracy: 0.8476 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 6s - loss: 0.3634 - accuracy: 0.8446 - val_loss: 0.3608 - val_accuracy: 0.8465 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 3s - loss: 0.3630 - accuracy: 0.8454 - val_loss: 0.3608 - val_accuracy: 0.8469 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 761us/step - loss: 0.3610 - accuracy: 0.8476\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 18)]              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               2432      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,598\n",
      "Trainable params: 5,498\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 24s - loss: 0.3983 - accuracy: 0.8287 - val_loss: 0.3756 - val_accuracy: 0.8406 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 25s - loss: 0.3767 - accuracy: 0.8408 - val_loss: 0.3718 - val_accuracy: 0.8440 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 24s - loss: 0.3721 - accuracy: 0.8426 - val_loss: 0.3695 - val_accuracy: 0.8441 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 25s - loss: 0.3691 - accuracy: 0.8432 - val_loss: 0.3669 - val_accuracy: 0.8460 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 24s - loss: 0.3672 - accuracy: 0.8444 - val_loss: 0.3654 - val_accuracy: 0.8448 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 24s - loss: 0.3661 - accuracy: 0.8437 - val_loss: 0.3649 - val_accuracy: 0.8443 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 24s - loss: 0.3643 - accuracy: 0.8454 - val_loss: 0.3644 - val_accuracy: 0.8456 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 24s - loss: 0.3627 - accuracy: 0.8459 - val_loss: 0.3634 - val_accuracy: 0.8461 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 25s - loss: 0.3627 - accuracy: 0.8457 - val_loss: 0.3636 - val_accuracy: 0.8473 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 24s - loss: 0.3614 - accuracy: 0.8463 - val_loss: 0.3614 - val_accuracy: 0.8479 - lr: 0.0010 - 24s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "1164/1164 - 24s - loss: 0.3567 - accuracy: 0.8478 - val_loss: 0.3605 - val_accuracy: 0.8471 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 24s - loss: 0.3554 - accuracy: 0.8489 - val_loss: 0.3605 - val_accuracy: 0.8471 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 24s - loss: 0.3549 - accuracy: 0.8493 - val_loss: 0.3604 - val_accuracy: 0.8473 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 26s - loss: 0.3552 - accuracy: 0.8487 - val_loss: 0.3603 - val_accuracy: 0.8473 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 25s - loss: 0.3545 - accuracy: 0.8497 - val_loss: 0.3603 - val_accuracy: 0.8472 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3614 - accuracy: 0.8479\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               2688      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,953\n",
      "Trainable params: 13,505\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 7s - loss: 0.4113 - accuracy: 0.8188 - val_loss: 0.3648 - val_accuracy: 0.8443 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 4s - loss: 0.3738 - accuracy: 0.8402 - val_loss: 0.3612 - val_accuracy: 0.8449 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 6s - loss: 0.3675 - accuracy: 0.8422 - val_loss: 0.3572 - val_accuracy: 0.8483 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 3s - loss: 0.3650 - accuracy: 0.8434 - val_loss: 0.3597 - val_accuracy: 0.8468 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 3s - loss: 0.3618 - accuracy: 0.8448 - val_loss: 0.3567 - val_accuracy: 0.8486 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 3s - loss: 0.3596 - accuracy: 0.8456 - val_loss: 0.3524 - val_accuracy: 0.8494 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 3s - loss: 0.3583 - accuracy: 0.8454 - val_loss: 0.3514 - val_accuracy: 0.8486 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 3s - loss: 0.3570 - accuracy: 0.8462 - val_loss: 0.3502 - val_accuracy: 0.8505 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 3s - loss: 0.3555 - accuracy: 0.8474 - val_loss: 0.3515 - val_accuracy: 0.8503 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 4s - loss: 0.3540 - accuracy: 0.8478 - val_loss: 0.3503 - val_accuracy: 0.8509 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 3s - loss: 0.3503 - accuracy: 0.8492 - val_loss: 0.3473 - val_accuracy: 0.8519 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 4s - loss: 0.3488 - accuracy: 0.8498 - val_loss: 0.3469 - val_accuracy: 0.8526 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 4s - loss: 0.3484 - accuracy: 0.8508 - val_loss: 0.3470 - val_accuracy: 0.8531 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 4s - loss: 0.3479 - accuracy: 0.8510 - val_loss: 0.3464 - val_accuracy: 0.8531 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 4s - loss: 0.3474 - accuracy: 0.8501 - val_loss: 0.3463 - val_accuracy: 0.8534 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 788us/step - loss: 0.3463 - accuracy: 0.85340s - loss: 0.3527 - ac\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               2688      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,854\n",
      "Trainable params: 5,754\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 32s - loss: 0.3899 - accuracy: 0.8303 - val_loss: 0.3648 - val_accuracy: 0.8445 - lr: 0.0010 - 32s/epoch - 27ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 30s - loss: 0.3638 - accuracy: 0.8442 - val_loss: 0.3609 - val_accuracy: 0.8449 - lr: 0.0010 - 30s/epoch - 26ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 30s - loss: 0.3589 - accuracy: 0.8461 - val_loss: 0.3571 - val_accuracy: 0.8476 - lr: 0.0010 - 30s/epoch - 26ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 30s - loss: 0.3552 - accuracy: 0.8474 - val_loss: 0.3550 - val_accuracy: 0.8477 - lr: 0.0010 - 30s/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "1164/1164 - 28s - loss: 0.3524 - accuracy: 0.8485 - val_loss: 0.3525 - val_accuracy: 0.8501 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 27s - loss: 0.3513 - accuracy: 0.8497 - val_loss: 0.3526 - val_accuracy: 0.8496 - lr: 0.0010 - 27s/epoch - 23ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 26s - loss: 0.3495 - accuracy: 0.8487 - val_loss: 0.3500 - val_accuracy: 0.8507 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 26s - loss: 0.3481 - accuracy: 0.8512 - val_loss: 0.3498 - val_accuracy: 0.8515 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 26s - loss: 0.3472 - accuracy: 0.8512 - val_loss: 0.3519 - val_accuracy: 0.8504 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 26s - loss: 0.3462 - accuracy: 0.8516 - val_loss: 0.3481 - val_accuracy: 0.8506 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 26s - loss: 0.3409 - accuracy: 0.8539 - val_loss: 0.3467 - val_accuracy: 0.8514 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 26s - loss: 0.3402 - accuracy: 0.8538 - val_loss: 0.3463 - val_accuracy: 0.8524 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 26s - loss: 0.3396 - accuracy: 0.8543 - val_loss: 0.3462 - val_accuracy: 0.8531 - lr: 1.0000e-04 - 26s/epoch - 23ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 26s - loss: 0.3396 - accuracy: 0.8547 - val_loss: 0.3461 - val_accuracy: 0.8529 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 26s - loss: 0.3383 - accuracy: 0.8555 - val_loss: 0.3459 - val_accuracy: 0.8531 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3459 - accuracy: 0.8531\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               2688      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,953\n",
      "Trainable params: 13,505\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 9s - loss: 0.4094 - accuracy: 0.8190 - val_loss: 0.3672 - val_accuracy: 0.8414 - lr: 0.0010 - 9s/epoch - 8ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 3s - loss: 0.3737 - accuracy: 0.8401 - val_loss: 0.3606 - val_accuracy: 0.8456 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 4s - loss: 0.3673 - accuracy: 0.8415 - val_loss: 0.3579 - val_accuracy: 0.8481 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 3s - loss: 0.3629 - accuracy: 0.8444 - val_loss: 0.3598 - val_accuracy: 0.8455 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 7s - loss: 0.3619 - accuracy: 0.8444 - val_loss: 0.3569 - val_accuracy: 0.8468 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 9s - loss: 0.3593 - accuracy: 0.8450 - val_loss: 0.3527 - val_accuracy: 0.8501 - lr: 0.0010 - 9s/epoch - 7ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 3s - loss: 0.3576 - accuracy: 0.8453 - val_loss: 0.3513 - val_accuracy: 0.8507 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 4s - loss: 0.3560 - accuracy: 0.8463 - val_loss: 0.3517 - val_accuracy: 0.8506 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 3s - loss: 0.3543 - accuracy: 0.8473 - val_loss: 0.3503 - val_accuracy: 0.8506 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 3s - loss: 0.3531 - accuracy: 0.8485 - val_loss: 0.3491 - val_accuracy: 0.8523 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 3s - loss: 0.3495 - accuracy: 0.8499 - val_loss: 0.3468 - val_accuracy: 0.8529 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 3s - loss: 0.3479 - accuracy: 0.8505 - val_loss: 0.3467 - val_accuracy: 0.8526 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 5s - loss: 0.3481 - accuracy: 0.8504 - val_loss: 0.3466 - val_accuracy: 0.8528 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 7s - loss: 0.3464 - accuracy: 0.8513 - val_loss: 0.3462 - val_accuracy: 0.8534 - lr: 1.0000e-04 - 7s/epoch - 6ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 3s - loss: 0.3461 - accuracy: 0.8512 - val_loss: 0.3463 - val_accuracy: 0.8530 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 921us/step - loss: 0.3462 - accuracy: 0.8534\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 128)               2688      \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,854\n",
      "Trainable params: 5,754\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1164/1164 - 26s - loss: 0.3888 - accuracy: 0.8313 - val_loss: 0.3659 - val_accuracy: 0.8448 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 25s - loss: 0.3648 - accuracy: 0.8439 - val_loss: 0.3585 - val_accuracy: 0.8480 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 25s - loss: 0.3601 - accuracy: 0.8450 - val_loss: 0.3557 - val_accuracy: 0.8473 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 25s - loss: 0.3561 - accuracy: 0.8474 - val_loss: 0.3551 - val_accuracy: 0.8480 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 25s - loss: 0.3549 - accuracy: 0.8474 - val_loss: 0.3540 - val_accuracy: 0.8481 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 26s - loss: 0.3525 - accuracy: 0.8486 - val_loss: 0.3524 - val_accuracy: 0.8511 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 26s - loss: 0.3510 - accuracy: 0.8497 - val_loss: 0.3526 - val_accuracy: 0.8505 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 26s - loss: 0.3498 - accuracy: 0.8503 - val_loss: 0.3502 - val_accuracy: 0.8510 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 26s - loss: 0.3480 - accuracy: 0.8501 - val_loss: 0.3497 - val_accuracy: 0.8514 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 26s - loss: 0.3478 - accuracy: 0.8505 - val_loss: 0.3495 - val_accuracy: 0.8501 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 25s - loss: 0.3430 - accuracy: 0.8533 - val_loss: 0.3478 - val_accuracy: 0.8511 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 26s - loss: 0.3412 - accuracy: 0.8536 - val_loss: 0.3477 - val_accuracy: 0.8522 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 26s - loss: 0.3412 - accuracy: 0.8536 - val_loss: 0.3474 - val_accuracy: 0.8520 - lr: 1.0000e-04 - 26s/epoch - 23ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 26s - loss: 0.3405 - accuracy: 0.8542 - val_loss: 0.3473 - val_accuracy: 0.8524 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 26s - loss: 0.3405 - accuracy: 0.8539 - val_loss: 0.3472 - val_accuracy: 0.8524 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3472 - accuracy: 0.8524\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 21)]              0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               2816      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,081\n",
      "Trainable params: 13,633\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 5s - loss: 0.4095 - accuracy: 0.8179 - val_loss: 0.3640 - val_accuracy: 0.8440 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 6s - loss: 0.3719 - accuracy: 0.8406 - val_loss: 0.3592 - val_accuracy: 0.8455 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 3s - loss: 0.3663 - accuracy: 0.8428 - val_loss: 0.3565 - val_accuracy: 0.8476 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 5s - loss: 0.3632 - accuracy: 0.8432 - val_loss: 0.3521 - val_accuracy: 0.8488 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 3s - loss: 0.3608 - accuracy: 0.8453 - val_loss: 0.3509 - val_accuracy: 0.8499 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 3s - loss: 0.3577 - accuracy: 0.8453 - val_loss: 0.3537 - val_accuracy: 0.8478 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 5s - loss: 0.3554 - accuracy: 0.8463 - val_loss: 0.3492 - val_accuracy: 0.8502 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 3s - loss: 0.3535 - accuracy: 0.8479 - val_loss: 0.3487 - val_accuracy: 0.8499 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 9s - loss: 0.3531 - accuracy: 0.8480 - val_loss: 0.3496 - val_accuracy: 0.8515 - lr: 0.0010 - 9s/epoch - 7ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 3s - loss: 0.3522 - accuracy: 0.8480 - val_loss: 0.3471 - val_accuracy: 0.8512 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 4s - loss: 0.3473 - accuracy: 0.8501 - val_loss: 0.3448 - val_accuracy: 0.8517 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 3s - loss: 0.3456 - accuracy: 0.8517 - val_loss: 0.3445 - val_accuracy: 0.8518 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 3s - loss: 0.3451 - accuracy: 0.8519 - val_loss: 0.3441 - val_accuracy: 0.8526 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 3s - loss: 0.3456 - accuracy: 0.8509 - val_loss: 0.3442 - val_accuracy: 0.8524 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 4s - loss: 0.3447 - accuracy: 0.8520 - val_loss: 0.3440 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "910/910 [==============================] - 1s 855us/step - loss: 0.3440 - accuracy: 0.8533\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 21)]              0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               2816      \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flatten_4 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,982\n",
      "Trainable params: 5,882\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 26s - loss: 0.3884 - accuracy: 0.8313 - val_loss: 0.3638 - val_accuracy: 0.8430 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 25s - loss: 0.3638 - accuracy: 0.8442 - val_loss: 0.3576 - val_accuracy: 0.8462 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 25s - loss: 0.3590 - accuracy: 0.8460 - val_loss: 0.3555 - val_accuracy: 0.8462 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 25s - loss: 0.3553 - accuracy: 0.8469 - val_loss: 0.3511 - val_accuracy: 0.8492 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 25s - loss: 0.3529 - accuracy: 0.8477 - val_loss: 0.3524 - val_accuracy: 0.8487 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 25s - loss: 0.3508 - accuracy: 0.8488 - val_loss: 0.3492 - val_accuracy: 0.8497 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 25s - loss: 0.3490 - accuracy: 0.8501 - val_loss: 0.3504 - val_accuracy: 0.8495 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 25s - loss: 0.3485 - accuracy: 0.8506 - val_loss: 0.3478 - val_accuracy: 0.8496 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 25s - loss: 0.3468 - accuracy: 0.8516 - val_loss: 0.3479 - val_accuracy: 0.8507 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 25s - loss: 0.3458 - accuracy: 0.8514 - val_loss: 0.3508 - val_accuracy: 0.8504 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 25s - loss: 0.3408 - accuracy: 0.8541 - val_loss: 0.3452 - val_accuracy: 0.8518 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 25s - loss: 0.3402 - accuracy: 0.8536 - val_loss: 0.3447 - val_accuracy: 0.8519 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 25s - loss: 0.3392 - accuracy: 0.8546 - val_loss: 0.3449 - val_accuracy: 0.8516 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 26s - loss: 0.3390 - accuracy: 0.8542 - val_loss: 0.3446 - val_accuracy: 0.8516 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 25s - loss: 0.3383 - accuracy: 0.8551 - val_loss: 0.3446 - val_accuracy: 0.8512 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3447 - accuracy: 0.8519\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 128)               3200      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,465\n",
      "Trainable params: 14,017\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 8s - loss: 0.4047 - accuracy: 0.8191 - val_loss: 0.3598 - val_accuracy: 0.8449 - lr: 0.0010 - 8s/epoch - 7ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 5s - loss: 0.3660 - accuracy: 0.8420 - val_loss: 0.3534 - val_accuracy: 0.8478 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 4s - loss: 0.3606 - accuracy: 0.8443 - val_loss: 0.3513 - val_accuracy: 0.8465 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 3s - loss: 0.3565 - accuracy: 0.8464 - val_loss: 0.3478 - val_accuracy: 0.8500 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 3s - loss: 0.3531 - accuracy: 0.8478 - val_loss: 0.3478 - val_accuracy: 0.8505 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 5s - loss: 0.3512 - accuracy: 0.8484 - val_loss: 0.3480 - val_accuracy: 0.8501 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 3s - loss: 0.3486 - accuracy: 0.8494 - val_loss: 0.3454 - val_accuracy: 0.8514 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 3s - loss: 0.3472 - accuracy: 0.8504 - val_loss: 0.3443 - val_accuracy: 0.8524 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 3s - loss: 0.3455 - accuracy: 0.8512 - val_loss: 0.3431 - val_accuracy: 0.8521 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 3s - loss: 0.3449 - accuracy: 0.8509 - val_loss: 0.3416 - val_accuracy: 0.8538 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 3s - loss: 0.3405 - accuracy: 0.8538 - val_loss: 0.3394 - val_accuracy: 0.8545 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 5s - loss: 0.3380 - accuracy: 0.8543 - val_loss: 0.3389 - val_accuracy: 0.8543 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 3s - loss: 0.3381 - accuracy: 0.8537 - val_loss: 0.3391 - val_accuracy: 0.8545 - lr: 1.0000e-04 - 3s/epoch - 2ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 3s - loss: 0.3379 - accuracy: 0.8539 - val_loss: 0.3386 - val_accuracy: 0.8537 - lr: 1.0000e-04 - 3s/epoch - 2ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 5s - loss: 0.3374 - accuracy: 0.8547 - val_loss: 0.3385 - val_accuracy: 0.8542 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "910/910 [==============================] - 1s 737us/step - loss: 0.3394 - accuracy: 0.8545\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 128)               3200      \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,366\n",
      "Trainable params: 6,266\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1164/1164 - 26s - loss: 0.3830 - accuracy: 0.8330 - val_loss: 0.3593 - val_accuracy: 0.8441 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 26s - loss: 0.3573 - accuracy: 0.8453 - val_loss: 0.3519 - val_accuracy: 0.8486 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 25s - loss: 0.3512 - accuracy: 0.8484 - val_loss: 0.3497 - val_accuracy: 0.8506 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 26s - loss: 0.3480 - accuracy: 0.8498 - val_loss: 0.3493 - val_accuracy: 0.8497 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 25s - loss: 0.3448 - accuracy: 0.8506 - val_loss: 0.3457 - val_accuracy: 0.8517 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 25s - loss: 0.3431 - accuracy: 0.8524 - val_loss: 0.3474 - val_accuracy: 0.8503 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 25s - loss: 0.3413 - accuracy: 0.8526 - val_loss: 0.3440 - val_accuracy: 0.8531 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 25s - loss: 0.3403 - accuracy: 0.8532 - val_loss: 0.3437 - val_accuracy: 0.8531 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 25s - loss: 0.3386 - accuracy: 0.8542 - val_loss: 0.3412 - val_accuracy: 0.8541 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 25s - loss: 0.3379 - accuracy: 0.8546 - val_loss: 0.3423 - val_accuracy: 0.8545 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 26s - loss: 0.3323 - accuracy: 0.8569 - val_loss: 0.3405 - val_accuracy: 0.8559 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 26s - loss: 0.3306 - accuracy: 0.8586 - val_loss: 0.3404 - val_accuracy: 0.8557 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 26s - loss: 0.3302 - accuracy: 0.8587 - val_loss: 0.3403 - val_accuracy: 0.8551 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 26s - loss: 0.3304 - accuracy: 0.8578 - val_loss: 0.3400 - val_accuracy: 0.8562 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 25s - loss: 0.3294 - accuracy: 0.8584 - val_loss: 0.3399 - val_accuracy: 0.8557 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3400 - accuracy: 0.8562\n"
     ]
    }
   ],
   "source": [
    "best_model= None\n",
    "best_rate=0\n",
    "best_architecture = None\n",
    "best = 0\n",
    "\n",
    "f= open(\"results.txt\",\"w+\")\n",
    "f.write('invalid_rate , model , features , accuracy \\n' )\n",
    "for invalid_rate in [0.1,0.2,0.3, 0.4,0.5]:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df,test_size=0.2, random_state=0)\n",
    "    X_train = df_train.drop([\"RainTomorrow\"], axis=1)\n",
    "    y_train = df_train.RainTomorrow\n",
    "    X_test = df_test.drop([\"RainTomorrow\"], axis=1)\n",
    "    y_test = df_test.RainTomorrow\n",
    "    \n",
    "    X_train,X_test = mean_handle_nan(X_train,X_test, invalid_rate)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train= scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    num_features = X_train.shape[1]\n",
    "    \n",
    "    for archi in ['fully_dense','conv']:\n",
    "        string = None\n",
    "        if archi == 'fully_dense':\n",
    "            model = fully_dense_model(num_features, (X_train,y_train), (X_test, y_test), units=32)\n",
    "            loss, accuracy = model.evaluate(X_test,y_test)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            model = convolution_model(num_features, (X_train,y_train), (X_test, y_test), units=128)\n",
    "            loss, accuracy = model.evaluate(X_test,y_test)\n",
    "        string = str(invalid_rate)+' '+ archi+' '+str(num_features)+' '+str(accuracy) +'\\n'\n",
    "        f.write(string)\n",
    "            \n",
    "        if best < accuracy:\n",
    "            best = accuracy\n",
    "            best_model = model\n",
    "            best_rate = invalid_rate\n",
    "            best_architecture = archi\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15ce26e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model architecture  conv best rate:  0.5 best accuracy:  0.8562491536140442\n"
     ]
    }
   ],
   "source": [
    "print('best model architecture ',best_architecture, 'best rate: ', best_rate, 'best accuracy: ', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0489373",
   "metadata": {},
   "source": [
    "### 2nd: One - hot encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1829fc9",
   "metadata": {},
   "source": [
    "red,\tgreen,\tblue\n",
    "1,\t\t0,\t\t0\n",
    "0,\t\t1,\t\t0\n",
    "0,\t\t0,\t\t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d80a2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.copy()\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(list(df1[\"RainTomorrow\"].values))\n",
    "df1[\"RainTomorrow\"] = lbl.transform(df1[\"RainTomorrow\"].values)\n",
    "\n",
    "for col in cat_feature[:-1]:\n",
    "    buffer = pd.get_dummies(df1[col])\n",
    "    df1 = pd.concat([df1,buffer], axis = 1)\n",
    "    df1 = df1.drop(columns = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07d96afd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>SE</th>\n",
       "      <th>SSE</th>\n",
       "      <th>SSW</th>\n",
       "      <th>SW</th>\n",
       "      <th>W</th>\n",
       "      <th>WNW</th>\n",
       "      <th>WSW</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "0     13.4     22.9       0.6          NaN       NaN           44.0   \n",
       "1      7.4     25.1       0.0          NaN       NaN           44.0   \n",
       "2     12.9     25.7       0.0          NaN       NaN           46.0   \n",
       "3      9.2     28.0       0.0          NaN       NaN           24.0   \n",
       "4     17.5     32.3       1.0          NaN       NaN           41.0   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  S  SE  SSE  SSW  \\\n",
       "0          20.0          24.0         71.0         22.0  ...  0   0    0    0   \n",
       "1           4.0          22.0         44.0         25.0  ...  0   0    0    0   \n",
       "2          19.0          26.0         38.0         30.0  ...  0   0    0    0   \n",
       "3          11.0           9.0         45.0         16.0  ...  0   0    0    0   \n",
       "4           7.0          20.0         82.0         33.0  ...  0   0    0    0   \n",
       "\n",
       "   SW  W  WNW  WSW  No  Yes  \n",
       "0   0  0    1    0   1    0  \n",
       "1   0  0    0    1   1    0  \n",
       "2   0  0    0    1   1    0  \n",
       "3   0  0    0    0   1    0  \n",
       "4   0  0    0    0   1    0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce7580f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_handle_nan(X_train, X_test, nan_frac):\n",
    "    global nan_col,df\n",
    "    buff = [i for i in nan_col if (df[i].isnull().sum())/N < nan_frac]\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    for col in  nan_col:\n",
    "        if col in buff:\n",
    "            X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
    "            X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
    "        else:\n",
    "            X_train = X_train.drop(columns=col)\n",
    "            X_test = X_test.drop(columns=col)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1fd56b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df1,test_size=0.2, random_state=0)\n",
    "X_train = df_train.drop([\"RainTomorrow\"], axis=1)\n",
    "y_train = df_train.RainTomorrow\n",
    "X_test = df_test.drop([\"RainTomorrow\"], axis=1)\n",
    "y_test = df_test.RainTomorrow\n",
    "X_train,X_test = median_handle_nan(X_train,X_test, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fc322ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f26c448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 112)]             0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 128)               14464     \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,630\n",
      "Trainable params: 17,530\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 27s - loss: 0.3999 - accuracy: 0.8250 - val_loss: 0.3647 - val_accuracy: 0.8460 - lr: 0.0010 - 27s/epoch - 23ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 26s - loss: 0.3592 - accuracy: 0.8470 - val_loss: 0.3584 - val_accuracy: 0.8490 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 26s - loss: 0.3500 - accuracy: 0.8501 - val_loss: 0.3535 - val_accuracy: 0.8510 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 26s - loss: 0.3437 - accuracy: 0.8534 - val_loss: 0.3525 - val_accuracy: 0.8501 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 26s - loss: 0.3377 - accuracy: 0.8572 - val_loss: 0.3547 - val_accuracy: 0.8506 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 26s - loss: 0.3334 - accuracy: 0.8587 - val_loss: 0.3551 - val_accuracy: 0.8494 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 26s - loss: 0.3298 - accuracy: 0.8601 - val_loss: 0.3542 - val_accuracy: 0.8498 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 26s - loss: 0.3266 - accuracy: 0.8618 - val_loss: 0.3548 - val_accuracy: 0.8510 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 26s - loss: 0.3234 - accuracy: 0.8626 - val_loss: 0.3533 - val_accuracy: 0.8505 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 27s - loss: 0.3201 - accuracy: 0.8643 - val_loss: 0.3570 - val_accuracy: 0.8492 - lr: 0.0010 - 27s/epoch - 23ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 26s - loss: 0.3058 - accuracy: 0.8702 - val_loss: 0.3578 - val_accuracy: 0.8498 - lr: 1.0000e-04 - 26s/epoch - 23ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 27s - loss: 0.3013 - accuracy: 0.8735 - val_loss: 0.3588 - val_accuracy: 0.8494 - lr: 1.0000e-04 - 27s/epoch - 23ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 26s - loss: 0.2980 - accuracy: 0.8746 - val_loss: 0.3606 - val_accuracy: 0.8498 - lr: 1.0000e-04 - 26s/epoch - 23ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 26s - loss: 0.2958 - accuracy: 0.8762 - val_loss: 0.3618 - val_accuracy: 0.8496 - lr: 1.0000e-04 - 26s/epoch - 23ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 26s - loss: 0.2942 - accuracy: 0.8763 - val_loss: 0.3630 - val_accuracy: 0.8485 - lr: 1.0000e-04 - 26s/epoch - 23ms/step\n"
     ]
    }
   ],
   "source": [
    "num_features = X_train.shape[1]\n",
    "model = convolution_model(num_features, (X_train,y_train), (X_test, y_test), units=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3de98c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 112)]             0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 128)               14464     \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,729\n",
      "Trainable params: 25,281\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 4s - loss: 0.4146 - accuracy: 0.8164 - val_loss: 0.3622 - val_accuracy: 0.8457 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 3s - loss: 0.3679 - accuracy: 0.8438 - val_loss: 0.3581 - val_accuracy: 0.8467 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 4s - loss: 0.3594 - accuracy: 0.8475 - val_loss: 0.3528 - val_accuracy: 0.8505 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 3s - loss: 0.3538 - accuracy: 0.8495 - val_loss: 0.3528 - val_accuracy: 0.8496 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 5s - loss: 0.3494 - accuracy: 0.8510 - val_loss: 0.3501 - val_accuracy: 0.8519 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 6s - loss: 0.3447 - accuracy: 0.8544 - val_loss: 0.3481 - val_accuracy: 0.8513 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 7s - loss: 0.3426 - accuracy: 0.8547 - val_loss: 0.3464 - val_accuracy: 0.8531 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 3s - loss: 0.3387 - accuracy: 0.8558 - val_loss: 0.3473 - val_accuracy: 0.8528 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 8s - loss: 0.3367 - accuracy: 0.8578 - val_loss: 0.3472 - val_accuracy: 0.8523 - lr: 0.0010 - 8s/epoch - 7ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 4s - loss: 0.3332 - accuracy: 0.8592 - val_loss: 0.3497 - val_accuracy: 0.8510 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 8s - loss: 0.3231 - accuracy: 0.8632 - val_loss: 0.3451 - val_accuracy: 0.8548 - lr: 1.0000e-04 - 8s/epoch - 7ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 3s - loss: 0.3207 - accuracy: 0.8640 - val_loss: 0.3455 - val_accuracy: 0.8555 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 3s - loss: 0.3194 - accuracy: 0.8646 - val_loss: 0.3454 - val_accuracy: 0.8556 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 4s - loss: 0.3190 - accuracy: 0.8649 - val_loss: 0.3459 - val_accuracy: 0.8547 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 9s - loss: 0.3185 - accuracy: 0.8651 - val_loss: 0.3457 - val_accuracy: 0.8546 - lr: 1.0000e-04 - 9s/epoch - 8ms/step\n",
      "910/910 [==============================] - 1s 738us/step - loss: 0.3454 - accuracy: 0.8556\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 112)]             0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 128)               14464     \n",
      "                                                                 \n",
      " reshape_7 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,630\n",
      "Trainable params: 17,530\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 26s - loss: 0.4007 - accuracy: 0.8245 - val_loss: 0.3621 - val_accuracy: 0.8466 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 26s - loss: 0.3582 - accuracy: 0.8481 - val_loss: 0.3580 - val_accuracy: 0.8472 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 26s - loss: 0.3497 - accuracy: 0.8519 - val_loss: 0.3541 - val_accuracy: 0.8492 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 26s - loss: 0.3435 - accuracy: 0.8540 - val_loss: 0.3525 - val_accuracy: 0.8491 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 26s - loss: 0.3386 - accuracy: 0.8555 - val_loss: 0.3542 - val_accuracy: 0.8502 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 26s - loss: 0.3340 - accuracy: 0.8581 - val_loss: 0.3540 - val_accuracy: 0.8496 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 26s - loss: 0.3297 - accuracy: 0.8605 - val_loss: 0.3545 - val_accuracy: 0.8503 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 26s - loss: 0.3260 - accuracy: 0.8614 - val_loss: 0.3562 - val_accuracy: 0.8508 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 26s - loss: 0.3236 - accuracy: 0.8620 - val_loss: 0.3559 - val_accuracy: 0.8490 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 26s - loss: 0.3199 - accuracy: 0.8639 - val_loss: 0.3592 - val_accuracy: 0.8484 - lr: 0.0010 - 26s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "1164/1164 - 26s - loss: 0.3048 - accuracy: 0.8719 - val_loss: 0.3572 - val_accuracy: 0.8498 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 26s - loss: 0.3006 - accuracy: 0.8734 - val_loss: 0.3583 - val_accuracy: 0.8494 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 26s - loss: 0.2967 - accuracy: 0.8752 - val_loss: 0.3597 - val_accuracy: 0.8491 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 26s - loss: 0.2946 - accuracy: 0.8758 - val_loss: 0.3611 - val_accuracy: 0.8484 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 26s - loss: 0.2935 - accuracy: 0.8765 - val_loss: 0.3620 - val_accuracy: 0.8479 - lr: 1.0000e-04 - 26s/epoch - 23ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3562 - accuracy: 0.8508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 114)]             0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 128)               14720     \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,985\n",
      "Trainable params: 25,537\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 6s - loss: 0.4090 - accuracy: 0.8175 - val_loss: 0.3555 - val_accuracy: 0.8483 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 3s - loss: 0.3571 - accuracy: 0.8475 - val_loss: 0.3446 - val_accuracy: 0.8516 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 4s - loss: 0.3477 - accuracy: 0.8521 - val_loss: 0.3413 - val_accuracy: 0.8547 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 3s - loss: 0.3412 - accuracy: 0.8543 - val_loss: 0.3377 - val_accuracy: 0.8573 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 3s - loss: 0.3356 - accuracy: 0.8566 - val_loss: 0.3383 - val_accuracy: 0.8564 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 3s - loss: 0.3327 - accuracy: 0.8587 - val_loss: 0.3327 - val_accuracy: 0.8585 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 3s - loss: 0.3285 - accuracy: 0.8602 - val_loss: 0.3369 - val_accuracy: 0.8566 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 3s - loss: 0.3248 - accuracy: 0.8621 - val_loss: 0.3366 - val_accuracy: 0.8564 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 3s - loss: 0.3223 - accuracy: 0.8636 - val_loss: 0.3332 - val_accuracy: 0.8589 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 3s - loss: 0.3190 - accuracy: 0.8641 - val_loss: 0.3351 - val_accuracy: 0.8574 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 4s - loss: 0.3085 - accuracy: 0.8694 - val_loss: 0.3309 - val_accuracy: 0.8605 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 3s - loss: 0.3055 - accuracy: 0.8713 - val_loss: 0.3313 - val_accuracy: 0.8592 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 3s - loss: 0.3052 - accuracy: 0.8702 - val_loss: 0.3310 - val_accuracy: 0.8602 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 3s - loss: 0.3036 - accuracy: 0.8707 - val_loss: 0.3315 - val_accuracy: 0.8600 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 5s - loss: 0.3029 - accuracy: 0.8719 - val_loss: 0.3319 - val_accuracy: 0.8605 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 1s 707us/step - loss: 0.3309 - accuracy: 0.8605\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 114)]             0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 128)               14720     \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,886\n",
      "Trainable params: 17,786\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 26s - loss: 0.3904 - accuracy: 0.8294 - val_loss: 0.3546 - val_accuracy: 0.8483 - lr: 0.0010 - 26s/epoch - 23ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 25s - loss: 0.3482 - accuracy: 0.8517 - val_loss: 0.3482 - val_accuracy: 0.8518 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 25s - loss: 0.3368 - accuracy: 0.8563 - val_loss: 0.3421 - val_accuracy: 0.8541 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 25s - loss: 0.3294 - accuracy: 0.8598 - val_loss: 0.3426 - val_accuracy: 0.8542 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 25s - loss: 0.3239 - accuracy: 0.8619 - val_loss: 0.3406 - val_accuracy: 0.8553 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 25s - loss: 0.3188 - accuracy: 0.8643 - val_loss: 0.3428 - val_accuracy: 0.8530 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 25s - loss: 0.3145 - accuracy: 0.8656 - val_loss: 0.3409 - val_accuracy: 0.8566 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 25s - loss: 0.3101 - accuracy: 0.8679 - val_loss: 0.3412 - val_accuracy: 0.8543 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 26s - loss: 0.3074 - accuracy: 0.8693 - val_loss: 0.3435 - val_accuracy: 0.8534 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 26s - loss: 0.3043 - accuracy: 0.8706 - val_loss: 0.3438 - val_accuracy: 0.8542 - lr: 0.0010 - 26s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "1164/1164 - 26s - loss: 0.2886 - accuracy: 0.8779 - val_loss: 0.3436 - val_accuracy: 0.8551 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 25s - loss: 0.2834 - accuracy: 0.8803 - val_loss: 0.3450 - val_accuracy: 0.8548 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 25s - loss: 0.2803 - accuracy: 0.8821 - val_loss: 0.3465 - val_accuracy: 0.8538 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 25s - loss: 0.2782 - accuracy: 0.8835 - val_loss: 0.3483 - val_accuracy: 0.8541 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 25s - loss: 0.2768 - accuracy: 0.8841 - val_loss: 0.3489 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 114)]             0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 128)               14720     \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,985\n",
      "Trainable params: 25,537\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 6s - loss: 0.4086 - accuracy: 0.8192 - val_loss: 0.3557 - val_accuracy: 0.8473 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 3s - loss: 0.3583 - accuracy: 0.8474 - val_loss: 0.3510 - val_accuracy: 0.8492 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 3s - loss: 0.3482 - accuracy: 0.8517 - val_loss: 0.3408 - val_accuracy: 0.8550 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 8s - loss: 0.3419 - accuracy: 0.8548 - val_loss: 0.3363 - val_accuracy: 0.8561 - lr: 0.0010 - 8s/epoch - 7ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 3s - loss: 0.3368 - accuracy: 0.8557 - val_loss: 0.3373 - val_accuracy: 0.8548 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 3s - loss: 0.3333 - accuracy: 0.8573 - val_loss: 0.3344 - val_accuracy: 0.8573 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 4s - loss: 0.3292 - accuracy: 0.8595 - val_loss: 0.3328 - val_accuracy: 0.8578 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 6s - loss: 0.3254 - accuracy: 0.8611 - val_loss: 0.3339 - val_accuracy: 0.8577 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 3s - loss: 0.3232 - accuracy: 0.8616 - val_loss: 0.3329 - val_accuracy: 0.8595 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 4s - loss: 0.3197 - accuracy: 0.8634 - val_loss: 0.3347 - val_accuracy: 0.8585 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 4s - loss: 0.3104 - accuracy: 0.8682 - val_loss: 0.3315 - val_accuracy: 0.8601 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 3s - loss: 0.3069 - accuracy: 0.8698 - val_loss: 0.3315 - val_accuracy: 0.8607 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 3s - loss: 0.3060 - accuracy: 0.8701 - val_loss: 0.3314 - val_accuracy: 0.8601 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 3s - loss: 0.3051 - accuracy: 0.8701 - val_loss: 0.3316 - val_accuracy: 0.8606 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 3s - loss: 0.3033 - accuracy: 0.8709 - val_loss: 0.3319 - val_accuracy: 0.8597 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 807us/step - loss: 0.3315 - accuracy: 0.8607\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 114)]             0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 128)               14720     \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,886\n",
      "Trainable params: 17,786\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 25s - loss: 0.3930 - accuracy: 0.8284 - val_loss: 0.3553 - val_accuracy: 0.8483 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 24s - loss: 0.3484 - accuracy: 0.8511 - val_loss: 0.3480 - val_accuracy: 0.8531 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 24s - loss: 0.3372 - accuracy: 0.8555 - val_loss: 0.3443 - val_accuracy: 0.8527 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 25s - loss: 0.3304 - accuracy: 0.8589 - val_loss: 0.3403 - val_accuracy: 0.8560 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 24s - loss: 0.3245 - accuracy: 0.8615 - val_loss: 0.3394 - val_accuracy: 0.8569 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 25s - loss: 0.3204 - accuracy: 0.8630 - val_loss: 0.3400 - val_accuracy: 0.8576 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 24s - loss: 0.3161 - accuracy: 0.8649 - val_loss: 0.3416 - val_accuracy: 0.8562 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 24s - loss: 0.3132 - accuracy: 0.8656 - val_loss: 0.3401 - val_accuracy: 0.8567 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 24s - loss: 0.3104 - accuracy: 0.8672 - val_loss: 0.3410 - val_accuracy: 0.8550 - lr: 0.0010 - 24s/epoch - 21ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 24s - loss: 0.3070 - accuracy: 0.8694 - val_loss: 0.3422 - val_accuracy: 0.8559 - lr: 0.0010 - 24s/epoch - 21ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "1164/1164 - 24s - loss: 0.2926 - accuracy: 0.8755 - val_loss: 0.3418 - val_accuracy: 0.8554 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 25s - loss: 0.2873 - accuracy: 0.8789 - val_loss: 0.3432 - val_accuracy: 0.8553 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 25s - loss: 0.2840 - accuracy: 0.8790 - val_loss: 0.3454 - val_accuracy: 0.8550 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 25s - loss: 0.2815 - accuracy: 0.8805 - val_loss: 0.3460 - val_accuracy: 0.8546 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 25s - loss: 0.2799 - accuracy: 0.8824 - val_loss: 0.3472 - val_accuracy: 0.8543 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "910/910 [==============================] - 3s 2ms/step - loss: 0.3400 - accuracy: 0.8576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 115)]             0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 128)               14848     \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,113\n",
      "Trainable params: 25,665\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 8s - loss: 0.4088 - accuracy: 0.8185 - val_loss: 0.3528 - val_accuracy: 0.8491 - lr: 0.0010 - 8s/epoch - 7ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 3s - loss: 0.3582 - accuracy: 0.8468 - val_loss: 0.3448 - val_accuracy: 0.8532 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 3s - loss: 0.3486 - accuracy: 0.8516 - val_loss: 0.3414 - val_accuracy: 0.8548 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 4s - loss: 0.3414 - accuracy: 0.8542 - val_loss: 0.3384 - val_accuracy: 0.8561 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 3s - loss: 0.3367 - accuracy: 0.8568 - val_loss: 0.3351 - val_accuracy: 0.8567 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 3s - loss: 0.3337 - accuracy: 0.8573 - val_loss: 0.3369 - val_accuracy: 0.8575 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 7s - loss: 0.3289 - accuracy: 0.8595 - val_loss: 0.3326 - val_accuracy: 0.8586 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 3s - loss: 0.3260 - accuracy: 0.8620 - val_loss: 0.3343 - val_accuracy: 0.8575 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 3s - loss: 0.3221 - accuracy: 0.8621 - val_loss: 0.3320 - val_accuracy: 0.8593 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 3s - loss: 0.3184 - accuracy: 0.8642 - val_loss: 0.3329 - val_accuracy: 0.8600 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 9s - loss: 0.3090 - accuracy: 0.8678 - val_loss: 0.3302 - val_accuracy: 0.8609 - lr: 1.0000e-04 - 9s/epoch - 8ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 3s - loss: 0.3071 - accuracy: 0.8695 - val_loss: 0.3303 - val_accuracy: 0.8616 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 3s - loss: 0.3051 - accuracy: 0.8702 - val_loss: 0.3302 - val_accuracy: 0.8619 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 3s - loss: 0.3044 - accuracy: 0.8709 - val_loss: 0.3303 - val_accuracy: 0.8611 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 5s - loss: 0.3034 - accuracy: 0.8710 - val_loss: 0.3308 - val_accuracy: 0.8609 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 1s 1ms/step - loss: 0.3302 - accuracy: 0.8619\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 115)]             0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 128)               14848     \n",
      "                                                                 \n",
      " reshape_10 (Reshape)        (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_30 (Conv1D)          (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 116)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,014\n",
      "Trainable params: 17,914\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 26s - loss: 0.3926 - accuracy: 0.8280 - val_loss: 0.3528 - val_accuracy: 0.8487 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 25s - loss: 0.3474 - accuracy: 0.8519 - val_loss: 0.3440 - val_accuracy: 0.8527 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 25s - loss: 0.3365 - accuracy: 0.8559 - val_loss: 0.3412 - val_accuracy: 0.8555 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 25s - loss: 0.3294 - accuracy: 0.8592 - val_loss: 0.3396 - val_accuracy: 0.8537 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 25s - loss: 0.3242 - accuracy: 0.8613 - val_loss: 0.3399 - val_accuracy: 0.8547 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 26s - loss: 0.3197 - accuracy: 0.8633 - val_loss: 0.3403 - val_accuracy: 0.8553 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 26s - loss: 0.3172 - accuracy: 0.8635 - val_loss: 0.3403 - val_accuracy: 0.8549 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 26s - loss: 0.3140 - accuracy: 0.8664 - val_loss: 0.3409 - val_accuracy: 0.8557 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 26s - loss: 0.3116 - accuracy: 0.8664 - val_loss: 0.3408 - val_accuracy: 0.8545 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 26s - loss: 0.3087 - accuracy: 0.8684 - val_loss: 0.3428 - val_accuracy: 0.8537 - lr: 0.0010 - 26s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "1164/1164 - 26s - loss: 0.2934 - accuracy: 0.8756 - val_loss: 0.3432 - val_accuracy: 0.8545 - lr: 1.0000e-04 - 26s/epoch - 22ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 26s - loss: 0.2882 - accuracy: 0.8775 - val_loss: 0.3447 - val_accuracy: 0.8538 - lr: 1.0000e-04 - 26s/epoch - 23ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 24s - loss: 0.2848 - accuracy: 0.8795 - val_loss: 0.3464 - val_accuracy: 0.8535 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 24s - loss: 0.2816 - accuracy: 0.8813 - val_loss: 0.3480 - val_accuracy: 0.8536 - lr: 1.0000e-04 - 24s/epoch - 21ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 25s - loss: 0.2795 - accuracy: 0.8821 - val_loss: 0.3492 - val_accuracy: 0.8527 - lr: 1.0000e-04 - 25s/epoch - 21ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-28-fd5231b4aee7>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
      "C:\\Users\\thien\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 128)               15232     \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,497\n",
      "Trainable params: 26,049\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 9s - loss: 0.3993 - accuracy: 0.8213 - val_loss: 0.3499 - val_accuracy: 0.8499 - lr: 0.0010 - 9s/epoch - 7ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 3s - loss: 0.3521 - accuracy: 0.8491 - val_loss: 0.3419 - val_accuracy: 0.8546 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 3s - loss: 0.3417 - accuracy: 0.8533 - val_loss: 0.3385 - val_accuracy: 0.8553 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 4s - loss: 0.3360 - accuracy: 0.8566 - val_loss: 0.3352 - val_accuracy: 0.8561 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 3s - loss: 0.3315 - accuracy: 0.8581 - val_loss: 0.3326 - val_accuracy: 0.8575 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 3s - loss: 0.3265 - accuracy: 0.8598 - val_loss: 0.3333 - val_accuracy: 0.8565 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 3s - loss: 0.3222 - accuracy: 0.8620 - val_loss: 0.3300 - val_accuracy: 0.8581 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 3s - loss: 0.3189 - accuracy: 0.8628 - val_loss: 0.3310 - val_accuracy: 0.8579 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 7s - loss: 0.3153 - accuracy: 0.8647 - val_loss: 0.3312 - val_accuracy: 0.8581 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 3s - loss: 0.3128 - accuracy: 0.8667 - val_loss: 0.3295 - val_accuracy: 0.8592 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 11/15\n",
      "1164/1164 - 4s - loss: 0.3017 - accuracy: 0.8707 - val_loss: 0.3272 - val_accuracy: 0.8600 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 3s - loss: 0.2992 - accuracy: 0.8732 - val_loss: 0.3274 - val_accuracy: 0.8595 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 8s - loss: 0.2979 - accuracy: 0.8724 - val_loss: 0.3277 - val_accuracy: 0.8604 - lr: 1.0000e-04 - 8s/epoch - 7ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 3s - loss: 0.2973 - accuracy: 0.8736 - val_loss: 0.3280 - val_accuracy: 0.8593 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 3s - loss: 0.2964 - accuracy: 0.8726 - val_loss: 0.3280 - val_accuracy: 0.8601 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 822us/step - loss: 0.3277 - accuracy: 0.8604\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 128)               15232     \n",
      "                                                                 \n",
      " reshape_11 (Reshape)        (None, 128, 1)            0         \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 128, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 124, 32)           192       \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 124, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 124, 32)           0         \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 120, 16)           2576      \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 120, 16)          64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 120, 16)           0         \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 116, 1)            81        \n",
      "                                                                 \n",
      " batch_normalization_80 (Bat  (None, 116, 1)           4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 116, 1)            0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 116)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,398\n",
      "Trainable params: 18,298\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1164/1164 - 26s - loss: 0.3841 - accuracy: 0.8308 - val_loss: 0.3484 - val_accuracy: 0.8506 - lr: 0.0010 - 26s/epoch - 22ms/step\n",
      "Epoch 2/15\n",
      "1164/1164 - 25s - loss: 0.3424 - accuracy: 0.8523 - val_loss: 0.3434 - val_accuracy: 0.8531 - lr: 0.0010 - 25s/epoch - 21ms/step\n",
      "Epoch 3/15\n",
      "1164/1164 - 25s - loss: 0.3330 - accuracy: 0.8564 - val_loss: 0.3378 - val_accuracy: 0.8558 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 4/15\n",
      "1164/1164 - 25s - loss: 0.3257 - accuracy: 0.8608 - val_loss: 0.3389 - val_accuracy: 0.8565 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 5/15\n",
      "1164/1164 - 25s - loss: 0.3201 - accuracy: 0.8629 - val_loss: 0.3378 - val_accuracy: 0.8550 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 6/15\n",
      "1164/1164 - 25s - loss: 0.3150 - accuracy: 0.8645 - val_loss: 0.3378 - val_accuracy: 0.8565 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 7/15\n",
      "1164/1164 - 25s - loss: 0.3113 - accuracy: 0.8659 - val_loss: 0.3377 - val_accuracy: 0.8558 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 8/15\n",
      "1164/1164 - 25s - loss: 0.3076 - accuracy: 0.8681 - val_loss: 0.3381 - val_accuracy: 0.8556 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 9/15\n",
      "1164/1164 - 25s - loss: 0.3047 - accuracy: 0.8694 - val_loss: 0.3407 - val_accuracy: 0.8535 - lr: 0.0010 - 25s/epoch - 22ms/step\n",
      "Epoch 10/15\n",
      "1164/1164 - 25s - loss: 0.3020 - accuracy: 0.8705 - val_loss: 0.3416 - val_accuracy: 0.8543 - lr: 0.0010 - 25s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "1164/1164 - 25s - loss: 0.2858 - accuracy: 0.8785 - val_loss: 0.3420 - val_accuracy: 0.8550 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "Epoch 12/15\n",
      "1164/1164 - 25s - loss: 0.2811 - accuracy: 0.8804 - val_loss: 0.3431 - val_accuracy: 0.8553 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "Epoch 13/15\n",
      "1164/1164 - 25s - loss: 0.2781 - accuracy: 0.8818 - val_loss: 0.3448 - val_accuracy: 0.8540 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "Epoch 14/15\n",
      "1164/1164 - 25s - loss: 0.2758 - accuracy: 0.8834 - val_loss: 0.3464 - val_accuracy: 0.8539 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "Epoch 15/15\n",
      "1164/1164 - 25s - loss: 0.2721 - accuracy: 0.8853 - val_loss: 0.3483 - val_accuracy: 0.8535 - lr: 1.0000e-04 - 25s/epoch - 22ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8565\n"
     ]
    }
   ],
   "source": [
    "best_model= None\n",
    "best_rate=0\n",
    "best_architecture = None\n",
    "best = 0\n",
    "\n",
    "f= open(\"results_onehot.txt\",\"w+\")\n",
    "f.write('invalid_rate , model , features , accuracy \\n' )\n",
    "for invalid_rate in [0.1,0.2,0.3, 0.4,0.5]:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df1,test_size=0.2, random_state=0)\n",
    "    X_train = df_train.drop([\"RainTomorrow\"], axis=1)\n",
    "    y_train = df_train.RainTomorrow\n",
    "    X_test = df_test.drop([\"RainTomorrow\"], axis=1)\n",
    "    y_test = df_test.RainTomorrow\n",
    "    X_train,X_test = median_handle_nan(X_train,X_test, invalid_rate)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train= scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    num_features = X_train.shape[1]\n",
    "    \n",
    "    for archi in ['fully_dense','conv']:\n",
    "        string = None\n",
    "        if archi == 'fully_dense':\n",
    "            model = fully_dense_model(num_features, (X_train,y_train), (X_test, y_test), units=32)\n",
    "            loss, accuracy = model.evaluate(X_test,y_test)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            model = convolution_model(num_features, (X_train,y_train), (X_test, y_test), units=128)\n",
    "            loss, accuracy = model.evaluate(X_test,y_test)\n",
    "        string = str(invalid_rate)+' '+ archi+' '+str(num_features)+' '+str(accuracy) +'\\n'\n",
    "        f.write(string)\n",
    "            \n",
    "        if best < accuracy:\n",
    "            best = accuracy\n",
    "            best_model = model\n",
    "            best_rate = invalid_rate\n",
    "            best_architecture = archi\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41fccad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model architecture  fully_dense best rate:  0.4 best accuracy:  0.8618520498275757\n"
     ]
    }
   ],
   "source": [
    "print('best model architecture ',best_architecture, 'best rate: ', best_rate, 'best accuracy: ', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af2f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
