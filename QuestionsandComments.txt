This document is to put some important information, questions, comments or things to do
_______________________________________________________________________________________________


TO DO

On Franke Function

- Find the confidence interval for our parameters (Yazeed working on it)
- Define a scaler function ( that takes our matrix and subtracts the mean; but how does this scaling influence the rest of the functions for OLS and Ridge?, it might not be such a simple problem)

- Study the effect of the noise, we need a systematic study of how the noise affects our system ( for loop through different noise values). We expect a better fit for Ridge than for OLS in the case of noisy systems, we should check this.

- Comment the important aspects of each graph on the cell under (this analysis will go directly in the report, therefore every graph should be very well understood) 

On the REAL DATA

- Bootstrap and Cross validation analysis of real data (for OLS)
- If they agree, see the influence of the number of parameters (correlation threshold) on this value, how does the optimal complexity change? 

- Bootstrap and Cross validation analysis of real data (for Ridge)

- What are some extra/ interesting things that we can do ?

----------------------------------------------------------------------------------
---------------------------------------------------------------------------------

PRACTICALITIES (comments about organization)

- Marvin: I have created a file name MarvinProject1, where I have cleaned up all the functions and code from the files Project1 and ProjectUniform. I have found some mistakes in different places, small but difficult to see, so I recommend making a copy of this file, and working on it from now on.
















-----------------------------------------------------------------------------------------------

IMPORTANT QUESTIONS


- What conclusion can we extract from the comparison of cross validation and bootstrap graph?


- Discussion of the scaling, importance, effects, etc


- Influence of the number of bootstrap points

- We need to understand the results coming from cross validation, a bit strange 

- What is the effect of the number of points on the optimal complexity (MSE train-Test). If we change from 70 to 100 points a lot changes...

- What is the influence of the number of folds, both on the MSE and on the complexity?

- Again, what is the role of the n of points; and noise, for the Ridge regression, when does the ridge regression give better predictions than the OLS?

- The complexity tradeoff(train-test) of OLS is clear, while for Ridge there doesnt seem to be this tendency, why?

- What is the influence of the scaling on our results? Maybe we should do an experiment of computing everything for the scaled data and without, then compare

NOTES


- The bootstrap sampling gives us the same optimal complexity as the MSE (training and test ), and this is good, but the cross validation gives us an optimal complexity of 3, why? 

THINGS TO CHANGE ON CODE

- Need to use same set of data for everything, to be able to compare, sometimes we create new data for a section


- The error, bias, variance plot, might be more interesting to plot separately, since it is hard to see the difference between them on the same graph


- Careful, it we should not have the number of bootstrap resamples higher than the number of points


- Careful, for the rescaling of the data, usually we calculate z using the unscaled matrix, and then we rescale the data... i think this is not correct (see Mortens book, section on scaling). If we rescale our design matrix X, then we should calculate z with this new rescaled matrix, and usually what we have done is we create the design matrix, compute z, then rescale the matrix X . Careful!!
Example shown:
"""
#Model training, we compute the mean value of y and X
y_train_mean = np.mean(y_train)
X_train_mean = np.mean(X_train,axis=0)
X_train = X_train - X_train_mean
y_train = y_train - y_train_mean

# The we fit our model with the training data
trained_model = some_model.fit(X_train,y_train)


#Model prediction, we need also to transform our data set used for the prediction.
X_test = X_test - X_train_mean #Use mean from training data
y_pred = trained_model(X_test)
y_pred = y_pred + y_train_mean
"""

- Fit intercept should be true or false? For ridge we obtain better MSE if we do not penalize the intercept, so it would make sense to scale. 

- In scaling the data, is it important to normalize by STD, why?



CONSIDERING THE REAL DATASET


IDEAS

- Vary the number of points of our data ( see how this influences the results, complexity, etc)

- Rescale also the z (calculate then rescale) (separately from the feature) , following the example from his book



- the MSE for the OLS using the scaled and non scaled data is the same (as should be)
Now, for the ridge regression, there should be a difference -to check (scaling should give a better result, and also compare with skl function that does everything ) . 


Concepts


- The noise directly influences the optimal complexity of our system. The bigger the noise, a smaller complexity gives better predictions and viceversa






