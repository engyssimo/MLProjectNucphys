{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a33ddaf",
   "metadata": {},
   "source": [
    "### Import independencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f99868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import random, seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5eb34",
   "metadata": {},
   "source": [
    "# Part I: Data overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaeea9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n",
      "None\n",
      "----------------------------\n",
      "(145460, 23)\n"
     ]
    }
   ],
   "source": [
    "# Loading our dataset \n",
    "data = pd.read_csv('weatherAUS.csv')\n",
    "print(data.info())\n",
    "print(\"----------------------------\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de607774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>...</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>...</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
       "0   Albury     13.4     22.9       0.6          NaN       NaN           W   \n",
       "1   Albury      7.4     25.1       0.0          NaN       NaN         WNW   \n",
       "2   Albury     12.9     25.7       0.0          NaN       NaN         WSW   \n",
       "3   Albury      9.2     28.0       0.0          NaN       NaN          NE   \n",
       "4   Albury     17.5     32.3       1.0          NaN       NaN           W   \n",
       "\n",
       "   WindGustSpeed WindDir9am WindDir3pm  ...  Pressure3pm  Cloud9am  Cloud3pm  \\\n",
       "0           44.0          W        WNW  ...       1007.1       8.0       NaN   \n",
       "1           44.0        NNW        WSW  ...       1007.8       NaN       NaN   \n",
       "2           46.0          W        WSW  ...       1008.7       NaN       2.0   \n",
       "3           24.0         SE          E  ...       1012.8       NaN       NaN   \n",
       "4           41.0        ENE         NW  ...       1006.0       7.0       8.0   \n",
       "\n",
       "   Temp9am  Temp3pm  RainToday  RainTomorrow  Year  Month  Day  \n",
       "0     16.9     21.8         No            No  2008     12    1  \n",
       "1     17.2     24.3         No            No  2008     12    2  \n",
       "2     21.0     23.2         No            No  2008     12    3  \n",
       "3     18.1     26.5         No            No  2008     12    4  \n",
       "4     17.8     29.7         No            No  2008     12    5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our dataset \n",
    "data = pd.read_csv('weatherAUS.csv')\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])       # Change to datetime type so we can then divide into year , month and day\n",
    "data[\"Year\"] = data[\"Date\"].dt.year\n",
    "data[\"Month\"] = data[\"Date\"].dt.month\n",
    "data[\"Day\"] = data[\"Date\"].dt.day\n",
    "data.drop(\"Date\",axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0256499a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location             0\n",
       "MinTemp           1485\n",
       "MaxTemp           1261\n",
       "Rainfall          3261\n",
       "Evaporation      62790\n",
       "Sunshine         69835\n",
       "WindGustDir      10326\n",
       "WindGustSpeed    10263\n",
       "WindDir9am       10566\n",
       "WindDir3pm        4228\n",
       "WindSpeed9am      1767\n",
       "WindSpeed3pm      3062\n",
       "Humidity9am       2654\n",
       "Humidity3pm       4507\n",
       "Pressure9am      15065\n",
       "Pressure3pm      15028\n",
       "Cloud9am         55888\n",
       "Cloud3pm         59358\n",
       "Temp9am           1767\n",
       "Temp3pm           3609\n",
       "RainToday         3261\n",
       "RainTomorrow      3267\n",
       "Year                 0\n",
       "Month                0\n",
       "Day                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a98646",
   "metadata": {},
   "source": [
    "# Part II: Data preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5194a1",
   "metadata": {},
   "source": [
    "## A. Categorical features:  Replace missing values by common and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbf3a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albury</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albury</td>\n",
       "      <td>WNW</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albury</td>\n",
       "      <td>WSW</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albury</td>\n",
       "      <td>NE</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albury</td>\n",
       "      <td>W</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Location WindGustDir WindDir9am WindDir3pm RainToday RainTomorrow\n",
       "0   Albury           W          W        WNW        No           No\n",
       "1   Albury         WNW        NNW        WSW        No           No\n",
       "2   Albury         WSW          W        WSW        No           No\n",
       "3   Albury          NE         SE          E        No           No\n",
       "4   Albury           W        ENE         NW        No           No"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical feature\n",
    "cat_feature = [i for i in data.columns if data[i].dtype=='O']\n",
    "data[cat_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e03c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_feature:\n",
    "    if data[col].isnull().sum() !=0 : \n",
    "        common = data[col].mode()[0]         # returns the most frequent value \n",
    "        data[col] = data[col].fillna(common)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85723f5a",
   "metadata": {},
   "source": [
    "## B: Model\n",
    "Two models are used, Convolutional and Fully_dense => Try to play with design of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2965431d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bf75942310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "array  = image.imread('model.png')\n",
    "plt.figure(figsize = (20,6))\n",
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d03bafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense , Dropout, Conv1D, Reshape, BatchNormalization as BN\n",
    "import tensorflow as tf\n",
    "\n",
    "def train_model(model, name, train_data, val_data, batch_size=100, epochs=30):\n",
    "    def lr_scheduler(epochs):\n",
    "        if epochs < 10:\n",
    "            return 1e-3\n",
    "        else:\n",
    "            if epochs < 20:\n",
    "                return 1e-4\n",
    "            else:\n",
    "                return 1e-5\n",
    "\n",
    "    filepath =  './models/' + name + '.hdf5'\n",
    "    saving = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                monitor='val_accuracy',\n",
    "                                                save_best_only=True,\n",
    "                                                 save_weights_only=True)\n",
    "    history = model.fit(\n",
    "    train_data[0], train_data[1],\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=val_data,\n",
    "    verbose=2,\n",
    "    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_scheduler), saving]\n",
    "    )   \n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def fully_dense_model(num_features, train_data, val_data, \n",
    "                      units, activation, rate=0):\n",
    "    inputs = tf.keras.layers.Input(shape=(num_features,))\n",
    "    x = Dense(4*units, activation=activation)(inputs)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Dense(2*units, activation=activation)(x)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Dense(units, activation=activation)(x)\n",
    "    x = BN()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    name = 'fully_dense_num-features=' + str(num_features)\n",
    "    file_path = './models/' + name + '.hdf5'\n",
    "    train_model(model, name, train_data, val_data)\n",
    "    model.load_weights(file_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd6039",
   "metadata": {},
   "source": [
    "## C: Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed72f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "698f7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical variables to numeric ones\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in cat_feature:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(df[col].values))\n",
    "    df[col] = lbl.transform(df[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd58b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
       "0         2     13.4     22.9       0.6          NaN       NaN           13   \n",
       "1         2      7.4     25.1       0.0          NaN       NaN           14   \n",
       "2         2     12.9     25.7       0.0          NaN       NaN           15   \n",
       "3         2      9.2     28.0       0.0          NaN       NaN            4   \n",
       "4         2     17.5     32.3       1.0          NaN       NaN           13   \n",
       "\n",
       "   WindGustSpeed  WindDir9am  WindDir3pm  ...  Pressure3pm  Cloud9am  \\\n",
       "0           44.0          13          14  ...       1007.1       8.0   \n",
       "1           44.0           6          15  ...       1007.8       NaN   \n",
       "2           46.0          13          15  ...       1008.7       NaN   \n",
       "3           24.0           9           0  ...       1012.8       NaN   \n",
       "4           41.0           1           7  ...       1006.0       7.0   \n",
       "\n",
       "   Cloud3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  Year  Month  Day  \n",
       "0       NaN     16.9     21.8          0             0  2008     12    1  \n",
       "1       NaN     17.2     24.3          0             0  2008     12    2  \n",
       "2       2.0     21.0     23.2          0             0  2008     12    3  \n",
       "3       NaN     18.1     26.5          0             0  2008     12    4  \n",
       "4       8.0     17.8     29.7          0             0  2008     12    5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c8eb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluding the outliers\n",
    "\n",
    "features_with_outliers = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'WindGustSpeed','WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
    "for feature in features_with_outliers:\n",
    "    q1 = df[feature].quantile(0.25)\n",
    "    q3 = df[feature].quantile(0.75)\n",
    "    IQR = q3-q1\n",
    "    lower_limit = q1 - (IQR*1.5)\n",
    "    upper_limit = q3 + (IQR*1.5)\n",
    "    df.loc[df[feature]<lower_limit,feature] = lower_limit\n",
    "    df.loc[df[feature]>upper_limit,feature] = upper_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603e196",
   "metadata": {},
   "source": [
    "## D: Handle NaN values: replaced by mean values \n",
    "This part should be seperated between train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2df20ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "nan_col = [i for i in df.columns if df[i].isnull().sum() != 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59dd57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_nan(X_train, X_test, method = 'median'):\n",
    "    global nan_col,df\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy= method)\n",
    "    for col in  nan_col:\n",
    "        X_train[[col]] = imputer.fit_transform(X_train[[col]])\n",
    "        X_test[[col]] = imputer.fit_transform(X_test[[col]])\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74898e",
   "metadata": {},
   "source": [
    "## Part III: Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27664d63",
   "metadata": {},
   "source": [
    "Split and standardize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339fc83f",
   "metadata": {},
   "source": [
    "## Part IV: Choosing the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5553f3",
   "metadata": {},
   "source": [
    "### Median + interger encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ac4a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6400      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,409\n",
      "Trainable params: 48,513\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 5s - loss: 0.3786 - accuracy: 0.8367 - val_loss: 0.3479 - val_accuracy: 0.8499 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 4s - loss: 0.3492 - accuracy: 0.8481 - val_loss: 0.3443 - val_accuracy: 0.8511 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 4s - loss: 0.3435 - accuracy: 0.8514 - val_loss: 0.3435 - val_accuracy: 0.8523 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 3s - loss: 0.3397 - accuracy: 0.8532 - val_loss: 0.3406 - val_accuracy: 0.8532 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 4s - loss: 0.3368 - accuracy: 0.8540 - val_loss: 0.3392 - val_accuracy: 0.8536 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.3341 - accuracy: 0.8551 - val_loss: 0.3368 - val_accuracy: 0.8545 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 3s - loss: 0.3317 - accuracy: 0.8565 - val_loss: 0.3361 - val_accuracy: 0.8571 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 4s - loss: 0.3287 - accuracy: 0.8578 - val_loss: 0.3361 - val_accuracy: 0.8560 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 4s - loss: 0.3261 - accuracy: 0.8586 - val_loss: 0.3364 - val_accuracy: 0.8551 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 4s - loss: 0.3238 - accuracy: 0.8594 - val_loss: 0.3374 - val_accuracy: 0.8549 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 4s - loss: 0.3130 - accuracy: 0.8647 - val_loss: 0.3328 - val_accuracy: 0.8574 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 4s - loss: 0.3099 - accuracy: 0.8662 - val_loss: 0.3333 - val_accuracy: 0.8573 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 4s - loss: 0.3077 - accuracy: 0.8675 - val_loss: 0.3341 - val_accuracy: 0.8570 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 4s - loss: 0.3064 - accuracy: 0.8678 - val_loss: 0.3350 - val_accuracy: 0.8570 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 4s - loss: 0.3051 - accuracy: 0.8679 - val_loss: 0.3349 - val_accuracy: 0.8558 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 4s - loss: 0.3040 - accuracy: 0.8690 - val_loss: 0.3355 - val_accuracy: 0.8563 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 4s - loss: 0.3036 - accuracy: 0.8683 - val_loss: 0.3352 - val_accuracy: 0.8554 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 4s - loss: 0.3024 - accuracy: 0.8691 - val_loss: 0.3360 - val_accuracy: 0.8558 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 4s - loss: 0.3018 - accuracy: 0.8695 - val_loss: 0.3365 - val_accuracy: 0.8562 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 4s - loss: 0.3015 - accuracy: 0.8697 - val_loss: 0.3359 - val_accuracy: 0.8561 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.2982 - accuracy: 0.8717 - val_loss: 0.3363 - val_accuracy: 0.8559 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 4s - loss: 0.2987 - accuracy: 0.8705 - val_loss: 0.3361 - val_accuracy: 0.8560 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 4s - loss: 0.2984 - accuracy: 0.8710 - val_loss: 0.3364 - val_accuracy: 0.8559 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 4s - loss: 0.2975 - accuracy: 0.8716 - val_loss: 0.3366 - val_accuracy: 0.8560 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 4s - loss: 0.2976 - accuracy: 0.8715 - val_loss: 0.3365 - val_accuracy: 0.8560 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 4s - loss: 0.2981 - accuracy: 0.8712 - val_loss: 0.3369 - val_accuracy: 0.8560 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 4s - loss: 0.2988 - accuracy: 0.8710 - val_loss: 0.3365 - val_accuracy: 0.8559 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 3s - loss: 0.2973 - accuracy: 0.8716 - val_loss: 0.3368 - val_accuracy: 0.8561 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 4s - loss: 0.2984 - accuracy: 0.8708 - val_loss: 0.3367 - val_accuracy: 0.8554 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 3s - loss: 0.2981 - accuracy: 0.8711 - val_loss: 0.3368 - val_accuracy: 0.8557 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 917us/step - loss: 0.3328 - accuracy: 0.8574\n",
      "3637/3637 [==============================] - 4s 919us/step - loss: 0.3004 - accuracy: 0.87070s -\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               6400      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,409\n",
      "Trainable params: 48,513\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1164/1164 - 4s - loss: 0.3881 - accuracy: 0.8309 - val_loss: 0.3574 - val_accuracy: 0.8452 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 4s - loss: 0.3592 - accuracy: 0.8452 - val_loss: 0.3523 - val_accuracy: 0.8487 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 4s - loss: 0.3526 - accuracy: 0.8478 - val_loss: 0.3511 - val_accuracy: 0.8504 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 4s - loss: 0.3484 - accuracy: 0.8499 - val_loss: 0.3513 - val_accuracy: 0.8487 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 4s - loss: 0.3459 - accuracy: 0.8504 - val_loss: 0.3474 - val_accuracy: 0.8511 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 4s - loss: 0.3437 - accuracy: 0.8518 - val_loss: 0.3462 - val_accuracy: 0.8494 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 4s - loss: 0.3424 - accuracy: 0.8516 - val_loss: 0.3460 - val_accuracy: 0.8515 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 4s - loss: 0.3392 - accuracy: 0.8529 - val_loss: 0.3458 - val_accuracy: 0.8498 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 4s - loss: 0.3374 - accuracy: 0.8550 - val_loss: 0.3437 - val_accuracy: 0.8506 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 4s - loss: 0.3355 - accuracy: 0.8546 - val_loss: 0.3417 - val_accuracy: 0.8537 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 4s - loss: 0.3273 - accuracy: 0.8585 - val_loss: 0.3402 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 3s - loss: 0.3253 - accuracy: 0.8593 - val_loss: 0.3399 - val_accuracy: 0.8528 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 4s - loss: 0.3232 - accuracy: 0.8603 - val_loss: 0.3399 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 5s - loss: 0.3230 - accuracy: 0.8599 - val_loss: 0.3398 - val_accuracy: 0.8543 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 4s - loss: 0.3210 - accuracy: 0.8614 - val_loss: 0.3410 - val_accuracy: 0.8538 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 4s - loss: 0.3210 - accuracy: 0.8615 - val_loss: 0.3405 - val_accuracy: 0.8535 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 4s - loss: 0.3201 - accuracy: 0.8613 - val_loss: 0.3404 - val_accuracy: 0.8532 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 4s - loss: 0.3197 - accuracy: 0.8622 - val_loss: 0.3404 - val_accuracy: 0.8534 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 4s - loss: 0.3193 - accuracy: 0.8618 - val_loss: 0.3408 - val_accuracy: 0.8531 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 4s - loss: 0.3177 - accuracy: 0.8625 - val_loss: 0.3408 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 4s - loss: 0.3166 - accuracy: 0.8634 - val_loss: 0.3406 - val_accuracy: 0.8528 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 4s - loss: 0.3172 - accuracy: 0.8633 - val_loss: 0.3405 - val_accuracy: 0.8532 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 4s - loss: 0.3176 - accuracy: 0.8627 - val_loss: 0.3406 - val_accuracy: 0.8529 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 4s - loss: 0.3161 - accuracy: 0.8627 - val_loss: 0.3406 - val_accuracy: 0.8531 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 4s - loss: 0.3166 - accuracy: 0.8638 - val_loss: 0.3406 - val_accuracy: 0.8529 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 4s - loss: 0.3158 - accuracy: 0.8633 - val_loss: 0.3407 - val_accuracy: 0.8528 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 4s - loss: 0.3161 - accuracy: 0.8638 - val_loss: 0.3408 - val_accuracy: 0.8529 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 4s - loss: 0.3162 - accuracy: 0.8635 - val_loss: 0.3408 - val_accuracy: 0.8527 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 4s - loss: 0.3169 - accuracy: 0.8631 - val_loss: 0.3408 - val_accuracy: 0.8525 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 4s - loss: 0.3154 - accuracy: 0.8633 - val_loss: 0.3410 - val_accuracy: 0.8526 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 991us/step - loss: 0.3398 - accuracy: 0.8543\n",
      "3637/3637 [==============================] - 4s 1ms/step - loss: 0.3099 - accuracy: 0.8660\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               6400      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,409\n",
      "Trainable params: 48,513\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 4s - loss: 0.3853 - accuracy: 0.8310 - val_loss: 0.3629 - val_accuracy: 0.8419 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 4s - loss: 0.3581 - accuracy: 0.8450 - val_loss: 0.3477 - val_accuracy: 0.8496 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 4s - loss: 0.3525 - accuracy: 0.8473 - val_loss: 0.3448 - val_accuracy: 0.8536 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 7s - loss: 0.3486 - accuracy: 0.8485 - val_loss: 0.3435 - val_accuracy: 0.8524 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 3s - loss: 0.3464 - accuracy: 0.8500 - val_loss: 0.3441 - val_accuracy: 0.8528 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 4s - loss: 0.3440 - accuracy: 0.8507 - val_loss: 0.3415 - val_accuracy: 0.8526 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 4s - loss: 0.3416 - accuracy: 0.8526 - val_loss: 0.3420 - val_accuracy: 0.8522 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 4s - loss: 0.3399 - accuracy: 0.8539 - val_loss: 0.3431 - val_accuracy: 0.8531 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 4s - loss: 0.3377 - accuracy: 0.8543 - val_loss: 0.3423 - val_accuracy: 0.8523 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 4s - loss: 0.3362 - accuracy: 0.8549 - val_loss: 0.3466 - val_accuracy: 0.8501 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 4s - loss: 0.3289 - accuracy: 0.8573 - val_loss: 0.3354 - val_accuracy: 0.8568 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 4s - loss: 0.3266 - accuracy: 0.8588 - val_loss: 0.3354 - val_accuracy: 0.8566 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 4s - loss: 0.3260 - accuracy: 0.8592 - val_loss: 0.3358 - val_accuracy: 0.8559 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "1164/1164 - 4s - loss: 0.3249 - accuracy: 0.8597 - val_loss: 0.3357 - val_accuracy: 0.8558 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 4s - loss: 0.3242 - accuracy: 0.8597 - val_loss: 0.3356 - val_accuracy: 0.8547 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 4s - loss: 0.3235 - accuracy: 0.8597 - val_loss: 0.3356 - val_accuracy: 0.8558 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 4s - loss: 0.3235 - accuracy: 0.8603 - val_loss: 0.3357 - val_accuracy: 0.8562 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.3227 - accuracy: 0.8609 - val_loss: 0.3358 - val_accuracy: 0.8557 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 4s - loss: 0.3225 - accuracy: 0.8602 - val_loss: 0.3352 - val_accuracy: 0.8557 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 4s - loss: 0.3224 - accuracy: 0.8612 - val_loss: 0.3357 - val_accuracy: 0.8548 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 4s - loss: 0.3214 - accuracy: 0.8605 - val_loss: 0.3353 - val_accuracy: 0.8555 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 4s - loss: 0.3203 - accuracy: 0.8615 - val_loss: 0.3352 - val_accuracy: 0.8553 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 4s - loss: 0.3206 - accuracy: 0.8611 - val_loss: 0.3353 - val_accuracy: 0.8555 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 4s - loss: 0.3210 - accuracy: 0.8622 - val_loss: 0.3351 - val_accuracy: 0.8555 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 4s - loss: 0.3215 - accuracy: 0.8606 - val_loss: 0.3351 - val_accuracy: 0.8559 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 4s - loss: 0.3209 - accuracy: 0.8612 - val_loss: 0.3351 - val_accuracy: 0.8560 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 4s - loss: 0.3213 - accuracy: 0.8614 - val_loss: 0.3352 - val_accuracy: 0.8559 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 4s - loss: 0.3206 - accuracy: 0.8618 - val_loss: 0.3352 - val_accuracy: 0.8558 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 4s - loss: 0.3206 - accuracy: 0.8618 - val_loss: 0.3352 - val_accuracy: 0.8559 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 4s - loss: 0.3205 - accuracy: 0.8624 - val_loss: 0.3352 - val_accuracy: 0.8554 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "910/910 [==============================] - 2s 1ms/step - loss: 0.3354 - accuracy: 0.8568\n",
      "3637/3637 [==============================] - 4s 950us/step - loss: 0.3175 - accuracy: 0.8630\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               12800     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,737\n",
      "Trainable params: 178,945\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 6s - loss: 0.3766 - accuracy: 0.8392 - val_loss: 0.3484 - val_accuracy: 0.8484 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3491 - accuracy: 0.8477 - val_loss: 0.3422 - val_accuracy: 0.8528 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3433 - accuracy: 0.8508 - val_loss: 0.3417 - val_accuracy: 0.8516 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 5s - loss: 0.3392 - accuracy: 0.8531 - val_loss: 0.3368 - val_accuracy: 0.8536 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 5s - loss: 0.3356 - accuracy: 0.8543 - val_loss: 0.3389 - val_accuracy: 0.8535 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.3329 - accuracy: 0.8556 - val_loss: 0.3367 - val_accuracy: 0.8557 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 5s - loss: 0.3291 - accuracy: 0.8578 - val_loss: 0.3333 - val_accuracy: 0.8568 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 5s - loss: 0.3256 - accuracy: 0.8590 - val_loss: 0.3366 - val_accuracy: 0.8555 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.3234 - accuracy: 0.8612 - val_loss: 0.3339 - val_accuracy: 0.8568 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 5s - loss: 0.3195 - accuracy: 0.8615 - val_loss: 0.3390 - val_accuracy: 0.8544 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 5s - loss: 0.3049 - accuracy: 0.8679 - val_loss: 0.3322 - val_accuracy: 0.8576 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 5s - loss: 0.2991 - accuracy: 0.8707 - val_loss: 0.3327 - val_accuracy: 0.8574 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 5s - loss: 0.2962 - accuracy: 0.8719 - val_loss: 0.3337 - val_accuracy: 0.8559 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 5s - loss: 0.2943 - accuracy: 0.8726 - val_loss: 0.3349 - val_accuracy: 0.8562 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 5s - loss: 0.2912 - accuracy: 0.8739 - val_loss: 0.3369 - val_accuracy: 0.8555 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 5s - loss: 0.2902 - accuracy: 0.8740 - val_loss: 0.3373 - val_accuracy: 0.8554 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 5s - loss: 0.2885 - accuracy: 0.8746 - val_loss: 0.3382 - val_accuracy: 0.8552 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.2852 - accuracy: 0.8765 - val_loss: 0.3399 - val_accuracy: 0.8561 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 5s - loss: 0.2848 - accuracy: 0.8770 - val_loss: 0.3401 - val_accuracy: 0.8556 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 5s - loss: 0.2827 - accuracy: 0.8778 - val_loss: 0.3407 - val_accuracy: 0.8557 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.2787 - accuracy: 0.8794 - val_loss: 0.3408 - val_accuracy: 0.8549 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.2783 - accuracy: 0.8796 - val_loss: 0.3407 - val_accuracy: 0.8548 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.2782 - accuracy: 0.8803 - val_loss: 0.3416 - val_accuracy: 0.8551 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 5s - loss: 0.2781 - accuracy: 0.8799 - val_loss: 0.3414 - val_accuracy: 0.8551 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.2775 - accuracy: 0.8793 - val_loss: 0.3419 - val_accuracy: 0.8555 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 5s - loss: 0.2766 - accuracy: 0.8812 - val_loss: 0.3425 - val_accuracy: 0.8554 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "1164/1164 - 5s - loss: 0.2766 - accuracy: 0.8809 - val_loss: 0.3424 - val_accuracy: 0.8553 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 5s - loss: 0.2763 - accuracy: 0.8801 - val_loss: 0.3431 - val_accuracy: 0.8553 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 5s - loss: 0.2768 - accuracy: 0.8807 - val_loss: 0.3434 - val_accuracy: 0.8555 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 5s - loss: 0.2766 - accuracy: 0.8798 - val_loss: 0.3433 - val_accuracy: 0.8551 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3322 - accuracy: 0.8576\n",
      "3637/3637 [==============================] - ETA: 0s - loss: 0.2914 - accuracy: 0.87 - 5s 1ms/step - loss: 0.2910 - accuracy: 0.8746\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               12800     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,737\n",
      "Trainable params: 178,945\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 6s - loss: 0.3883 - accuracy: 0.8302 - val_loss: 0.3636 - val_accuracy: 0.8447 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3591 - accuracy: 0.8436 - val_loss: 0.3532 - val_accuracy: 0.8481 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3520 - accuracy: 0.8478 - val_loss: 0.3531 - val_accuracy: 0.8469 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 5s - loss: 0.3493 - accuracy: 0.8486 - val_loss: 0.3471 - val_accuracy: 0.8510 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 5s - loss: 0.3461 - accuracy: 0.8494 - val_loss: 0.3508 - val_accuracy: 0.8490 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.3451 - accuracy: 0.8503 - val_loss: 0.3459 - val_accuracy: 0.8504 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 5s - loss: 0.3427 - accuracy: 0.8517 - val_loss: 0.3484 - val_accuracy: 0.8522 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 5s - loss: 0.3403 - accuracy: 0.8530 - val_loss: 0.3449 - val_accuracy: 0.8518 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.3384 - accuracy: 0.8536 - val_loss: 0.3423 - val_accuracy: 0.8529 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 5s - loss: 0.3367 - accuracy: 0.8536 - val_loss: 0.3502 - val_accuracy: 0.8493 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 5s - loss: 0.3265 - accuracy: 0.8589 - val_loss: 0.3398 - val_accuracy: 0.8550 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 6s - loss: 0.3232 - accuracy: 0.8600 - val_loss: 0.3397 - val_accuracy: 0.8545 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 5s - loss: 0.3209 - accuracy: 0.8613 - val_loss: 0.3393 - val_accuracy: 0.8539 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 5s - loss: 0.3193 - accuracy: 0.8618 - val_loss: 0.3401 - val_accuracy: 0.8548 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 5s - loss: 0.3183 - accuracy: 0.8628 - val_loss: 0.3396 - val_accuracy: 0.8546 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 5s - loss: 0.3165 - accuracy: 0.8641 - val_loss: 0.3400 - val_accuracy: 0.8548 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 5s - loss: 0.3140 - accuracy: 0.8648 - val_loss: 0.3399 - val_accuracy: 0.8551 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.3131 - accuracy: 0.8646 - val_loss: 0.3399 - val_accuracy: 0.8547 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 5s - loss: 0.3124 - accuracy: 0.8641 - val_loss: 0.3399 - val_accuracy: 0.8545 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 5s - loss: 0.3110 - accuracy: 0.8660 - val_loss: 0.3401 - val_accuracy: 0.8548 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.3090 - accuracy: 0.8668 - val_loss: 0.3400 - val_accuracy: 0.8554 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 6s - loss: 0.3089 - accuracy: 0.8662 - val_loss: 0.3399 - val_accuracy: 0.8550 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 6s - loss: 0.3095 - accuracy: 0.8662 - val_loss: 0.3400 - val_accuracy: 0.8547 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 5s - loss: 0.3086 - accuracy: 0.8665 - val_loss: 0.3401 - val_accuracy: 0.8548 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.3083 - accuracy: 0.8674 - val_loss: 0.3400 - val_accuracy: 0.8550 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 5s - loss: 0.3077 - accuracy: 0.8667 - val_loss: 0.3403 - val_accuracy: 0.8551 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 5s - loss: 0.3079 - accuracy: 0.8681 - val_loss: 0.3402 - val_accuracy: 0.8548 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 5s - loss: 0.3082 - accuracy: 0.8671 - val_loss: 0.3402 - val_accuracy: 0.8550 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 6s - loss: 0.3082 - accuracy: 0.8665 - val_loss: 0.3401 - val_accuracy: 0.8549 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 5s - loss: 0.3079 - accuracy: 0.8674 - val_loss: 0.3405 - val_accuracy: 0.8551 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8554\n",
      "3637/3637 [==============================] - 5s 1ms/step - loss: 0.2947 - accuracy: 0.8729\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 24)]              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 512)               12800     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,737\n",
      "Trainable params: 178,945\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1164/1164 - 6s - loss: 0.3839 - accuracy: 0.8316 - val_loss: 0.3565 - val_accuracy: 0.8468 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3564 - accuracy: 0.8461 - val_loss: 0.3515 - val_accuracy: 0.8478 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3506 - accuracy: 0.8481 - val_loss: 0.3473 - val_accuracy: 0.8496 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 5s - loss: 0.3461 - accuracy: 0.8508 - val_loss: 0.3444 - val_accuracy: 0.8520 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 5s - loss: 0.3423 - accuracy: 0.8519 - val_loss: 0.3434 - val_accuracy: 0.8529 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.3399 - accuracy: 0.8532 - val_loss: 0.3420 - val_accuracy: 0.8524 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 5s - loss: 0.3379 - accuracy: 0.8536 - val_loss: 0.3405 - val_accuracy: 0.8548 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 5s - loss: 0.3355 - accuracy: 0.8556 - val_loss: 0.3436 - val_accuracy: 0.8512 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.3327 - accuracy: 0.8558 - val_loss: 0.3442 - val_accuracy: 0.8521 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 5s - loss: 0.3309 - accuracy: 0.8575 - val_loss: 0.3427 - val_accuracy: 0.8532 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 5s - loss: 0.3188 - accuracy: 0.8624 - val_loss: 0.3368 - val_accuracy: 0.8554 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 6s - loss: 0.3149 - accuracy: 0.8644 - val_loss: 0.3374 - val_accuracy: 0.8553 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 6s - loss: 0.3129 - accuracy: 0.8650 - val_loss: 0.3372 - val_accuracy: 0.8554 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 6s - loss: 0.3114 - accuracy: 0.8663 - val_loss: 0.3376 - val_accuracy: 0.8542 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 5s - loss: 0.3102 - accuracy: 0.8665 - val_loss: 0.3380 - val_accuracy: 0.8539 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 5s - loss: 0.3087 - accuracy: 0.8675 - val_loss: 0.3384 - val_accuracy: 0.8538 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 5s - loss: 0.3073 - accuracy: 0.8676 - val_loss: 0.3388 - val_accuracy: 0.8542 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.3067 - accuracy: 0.8684 - val_loss: 0.3388 - val_accuracy: 0.8545 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 5s - loss: 0.3055 - accuracy: 0.8684 - val_loss: 0.3395 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 5s - loss: 0.3052 - accuracy: 0.8689 - val_loss: 0.3396 - val_accuracy: 0.8541 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.3023 - accuracy: 0.8707 - val_loss: 0.3394 - val_accuracy: 0.8539 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.3027 - accuracy: 0.8696 - val_loss: 0.3394 - val_accuracy: 0.8539 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.3027 - accuracy: 0.8694 - val_loss: 0.3395 - val_accuracy: 0.8545 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 5s - loss: 0.3024 - accuracy: 0.8698 - val_loss: 0.3392 - val_accuracy: 0.8540 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.3027 - accuracy: 0.8697 - val_loss: 0.3396 - val_accuracy: 0.8541 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 5s - loss: 0.3021 - accuracy: 0.8708 - val_loss: 0.3396 - val_accuracy: 0.8537 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 5s - loss: 0.3022 - accuracy: 0.8701 - val_loss: 0.3396 - val_accuracy: 0.8544 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 5s - loss: 0.3022 - accuracy: 0.8692 - val_loss: 0.3395 - val_accuracy: 0.8542 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 5s - loss: 0.3018 - accuracy: 0.8704 - val_loss: 0.3395 - val_accuracy: 0.8542 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 5s - loss: 0.3020 - accuracy: 0.8704 - val_loss: 0.3396 - val_accuracy: 0.8538 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 1s 1ms/step - loss: 0.3368 - accuracy: 0.8554\n",
      "3637/3637 [==============================] - 5s 1ms/step - loss: 0.3050 - accuracy: 0.8695\n"
     ]
    }
   ],
   "source": [
    "best_function= None\n",
    "best_unit = None\n",
    "best = 0\n",
    "units = [64,128]\n",
    "functions = ['relu', 'tanh', 'sigmoid']\n",
    "f= open(\"median_interger.txt\",\"w+\")\n",
    "for unit in units:\n",
    "    for func in functions:\n",
    "        f.write(' unit, activation function, features , train accuracy, test accuracy \\n' )\n",
    "        \n",
    "        df_train, df_test = train_test_split(df,test_size=0.2, random_state=0)\n",
    "        X_train = df_train.drop([\"RainTomorrow\"], axis=1)\n",
    "        y_train = df_train.RainTomorrow\n",
    "        X_test = df_test.drop([\"RainTomorrow\"], axis=1)\n",
    "        y_test = df_test.RainTomorrow\n",
    "\n",
    "        X_train,X_test = handle_nan(X_train, X_test)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train= scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        num_features = X_train.shape[1]\n",
    "\n",
    "        model = fully_dense_model(num_features, (X_train,y_train), (X_test, y_test), units = unit,activation = func )\n",
    "        loss, test_accuracy = model.evaluate(X_test,y_test)\n",
    "        _, train_accuracy = model.evaluate(X_train, y_train)\n",
    "        string = str(unit) + ' ' + func+ ' ' +str(num_features)+' '+str(train_accuracy)+ ' '+str(test_accuracy)+'\\n'\n",
    "        f.write(string)\n",
    "\n",
    "        if best < test_accuracy:\n",
    "            best = test_accuracy\n",
    "            best_unit = unit\n",
    "            best_function = func\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15ce26e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy:  0.8575897216796875 best unit 128 best function relu\n"
     ]
    }
   ],
   "source": [
    "print('best accuracy: ', best, 'best unit', best_unit, 'best function', best_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0489373",
   "metadata": {},
   "source": [
    "### 2nd: One - hot encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1829fc9",
   "metadata": {},
   "source": [
    "red,\tgreen,\tblue\n",
    "1,\t\t0,\t\t0\n",
    "0,\t\t1,\t\t0\n",
    "0,\t\t0,\t\t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d80a2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.copy()\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(list(df1[\"RainTomorrow\"].values))\n",
    "df1[\"RainTomorrow\"] = lbl.transform(df1[\"RainTomorrow\"].values)\n",
    "\n",
    "for col in cat_feature[:-1]:\n",
    "    buffer = pd.get_dummies(df1[col])\n",
    "    df1 = pd.concat([df1,buffer], axis = 1)\n",
    "    df1 = df1.drop(columns = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77475490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluding the outliers\n",
    "\n",
    "features_with_outliers = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'WindGustSpeed','WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
    "for feature in features_with_outliers:\n",
    "    q1 = df1[feature].quantile(0.25)\n",
    "    q3 = df1[feature].quantile(0.75)\n",
    "    IQR = q3-q1\n",
    "    lower_limit = q1 - (IQR*1.5)\n",
    "    upper_limit = q3 + (IQR*1.5)\n",
    "    df1.loc[df[feature]<lower_limit,feature] = lower_limit\n",
    "    df1.loc[df[feature]>upper_limit,feature] = upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52af2f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               30464     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,473\n",
      "Trainable params: 72,577\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 5s - loss: 0.3826 - accuracy: 0.8335 - val_loss: 0.3365 - val_accuracy: 0.8534 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3330 - accuracy: 0.8560 - val_loss: 0.3293 - val_accuracy: 0.8582 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3233 - accuracy: 0.8599 - val_loss: 0.3294 - val_accuracy: 0.8591 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 4s - loss: 0.3162 - accuracy: 0.8641 - val_loss: 0.3270 - val_accuracy: 0.8594 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 4s - loss: 0.3106 - accuracy: 0.8655 - val_loss: 0.3300 - val_accuracy: 0.8572 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 4s - loss: 0.3040 - accuracy: 0.8696 - val_loss: 0.3289 - val_accuracy: 0.8582 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 4s - loss: 0.2982 - accuracy: 0.8713 - val_loss: 0.3294 - val_accuracy: 0.8582 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 4s - loss: 0.2922 - accuracy: 0.8732 - val_loss: 0.3307 - val_accuracy: 0.8604 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 4s - loss: 0.2868 - accuracy: 0.8755 - val_loss: 0.3312 - val_accuracy: 0.8577 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 4s - loss: 0.2811 - accuracy: 0.8789 - val_loss: 0.3363 - val_accuracy: 0.8571 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 4s - loss: 0.2575 - accuracy: 0.8894 - val_loss: 0.3351 - val_accuracy: 0.8584 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 4s - loss: 0.2493 - accuracy: 0.8930 - val_loss: 0.3397 - val_accuracy: 0.8577 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 4s - loss: 0.2450 - accuracy: 0.8951 - val_loss: 0.3452 - val_accuracy: 0.8574 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 4s - loss: 0.2416 - accuracy: 0.8971 - val_loss: 0.3489 - val_accuracy: 0.8567 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 4s - loss: 0.2370 - accuracy: 0.8990 - val_loss: 0.3529 - val_accuracy: 0.8558 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 4s - loss: 0.2350 - accuracy: 0.8982 - val_loss: 0.3560 - val_accuracy: 0.8554 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 4s - loss: 0.2328 - accuracy: 0.9005 - val_loss: 0.3579 - val_accuracy: 0.8547 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.2308 - accuracy: 0.9015 - val_loss: 0.3606 - val_accuracy: 0.8543 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 8s - loss: 0.2292 - accuracy: 0.9013 - val_loss: 0.3633 - val_accuracy: 0.8546 - lr: 1.0000e-04 - 8s/epoch - 7ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 4s - loss: 0.2263 - accuracy: 0.9029 - val_loss: 0.3654 - val_accuracy: 0.8530 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.2217 - accuracy: 0.9057 - val_loss: 0.3655 - val_accuracy: 0.8528 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.2217 - accuracy: 0.9049 - val_loss: 0.3666 - val_accuracy: 0.8533 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.2221 - accuracy: 0.9056 - val_loss: 0.3670 - val_accuracy: 0.8533 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 4s - loss: 0.2201 - accuracy: 0.9062 - val_loss: 0.3673 - val_accuracy: 0.8527 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 6s - loss: 0.2210 - accuracy: 0.9057 - val_loss: 0.3686 - val_accuracy: 0.8529 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 4s - loss: 0.2206 - accuracy: 0.9061 - val_loss: 0.3685 - val_accuracy: 0.8530 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 4s - loss: 0.2208 - accuracy: 0.9053 - val_loss: 0.3693 - val_accuracy: 0.8527 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 4s - loss: 0.2201 - accuracy: 0.9065 - val_loss: 0.3696 - val_accuracy: 0.8526 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 4s - loss: 0.2189 - accuracy: 0.9071 - val_loss: 0.3694 - val_accuracy: 0.8521 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 5s - loss: 0.2199 - accuracy: 0.9061 - val_loss: 0.3701 - val_accuracy: 0.8527 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 1s 1ms/step - loss: 0.3307 - accuracy: 0.8604\n",
      "3637/3637 [==============================] - 4s 954us/step - loss: 0.2649 - accuracy: 0.8855\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 256)               30464     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,473\n",
      "Trainable params: 72,577\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1164/1164 - 5s - loss: 0.3844 - accuracy: 0.8312 - val_loss: 0.3471 - val_accuracy: 0.8499 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3409 - accuracy: 0.8540 - val_loss: 0.3402 - val_accuracy: 0.8535 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 4s - loss: 0.3316 - accuracy: 0.8580 - val_loss: 0.3340 - val_accuracy: 0.8580 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 4s - loss: 0.3240 - accuracy: 0.8605 - val_loss: 0.3313 - val_accuracy: 0.8566 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 4s - loss: 0.3177 - accuracy: 0.8639 - val_loss: 0.3339 - val_accuracy: 0.8558 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 4s - loss: 0.3120 - accuracy: 0.8663 - val_loss: 0.3337 - val_accuracy: 0.8561 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 4s - loss: 0.3069 - accuracy: 0.8688 - val_loss: 0.3314 - val_accuracy: 0.8565 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 4s - loss: 0.3001 - accuracy: 0.8711 - val_loss: 0.3317 - val_accuracy: 0.8561 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.2943 - accuracy: 0.8737 - val_loss: 0.3328 - val_accuracy: 0.8556 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 4s - loss: 0.2884 - accuracy: 0.8758 - val_loss: 0.3366 - val_accuracy: 0.8567 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 4s - loss: 0.2657 - accuracy: 0.8881 - val_loss: 0.3351 - val_accuracy: 0.8586 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 4s - loss: 0.2588 - accuracy: 0.8907 - val_loss: 0.3381 - val_accuracy: 0.8575 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 4s - loss: 0.2554 - accuracy: 0.8911 - val_loss: 0.3393 - val_accuracy: 0.8572 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 4s - loss: 0.2531 - accuracy: 0.8932 - val_loss: 0.3414 - val_accuracy: 0.8569 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 4s - loss: 0.2497 - accuracy: 0.8943 - val_loss: 0.3447 - val_accuracy: 0.8558 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 4s - loss: 0.2470 - accuracy: 0.8954 - val_loss: 0.3467 - val_accuracy: 0.8558 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 4s - loss: 0.2450 - accuracy: 0.8969 - val_loss: 0.3493 - val_accuracy: 0.8551 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 4s - loss: 0.2449 - accuracy: 0.8963 - val_loss: 0.3496 - val_accuracy: 0.8545 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 4s - loss: 0.2425 - accuracy: 0.8975 - val_loss: 0.3518 - val_accuracy: 0.8550 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 5s - loss: 0.2407 - accuracy: 0.8978 - val_loss: 0.3528 - val_accuracy: 0.8544 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 4s - loss: 0.2369 - accuracy: 0.9001 - val_loss: 0.3527 - val_accuracy: 0.8542 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 4s - loss: 0.2356 - accuracy: 0.9008 - val_loss: 0.3531 - val_accuracy: 0.8544 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 4s - loss: 0.2366 - accuracy: 0.9007 - val_loss: 0.3536 - val_accuracy: 0.8540 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 4s - loss: 0.2349 - accuracy: 0.9012 - val_loss: 0.3535 - val_accuracy: 0.8538 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.2357 - accuracy: 0.9004 - val_loss: 0.3539 - val_accuracy: 0.8538 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 4s - loss: 0.2347 - accuracy: 0.9009 - val_loss: 0.3545 - val_accuracy: 0.8541 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 4s - loss: 0.2355 - accuracy: 0.9008 - val_loss: 0.3548 - val_accuracy: 0.8539 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 4s - loss: 0.2348 - accuracy: 0.9014 - val_loss: 0.3547 - val_accuracy: 0.8537 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 4s - loss: 0.2354 - accuracy: 0.9008 - val_loss: 0.3553 - val_accuracy: 0.8535 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 4s - loss: 0.2358 - accuracy: 0.9012 - val_loss: 0.3555 - val_accuracy: 0.8539 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "910/910 [==============================] - 3s 3ms/step - loss: 0.3351 - accuracy: 0.8586\n",
      "3637/3637 [==============================] - 7s 2ms/step - loss: 0.2396 - accuracy: 0.8995\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 256)               30464     \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,473\n",
      "Trainable params: 72,577\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 5s - loss: 0.3797 - accuracy: 0.8340 - val_loss: 0.3428 - val_accuracy: 0.8531 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 4s - loss: 0.3447 - accuracy: 0.8505 - val_loss: 0.3379 - val_accuracy: 0.8543 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 4s - loss: 0.3361 - accuracy: 0.8559 - val_loss: 0.3314 - val_accuracy: 0.8569 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 4s - loss: 0.3303 - accuracy: 0.8585 - val_loss: 0.3291 - val_accuracy: 0.8592 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 4s - loss: 0.3249 - accuracy: 0.8599 - val_loss: 0.3275 - val_accuracy: 0.8579 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.3203 - accuracy: 0.8617 - val_loss: 0.3286 - val_accuracy: 0.8591 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 4s - loss: 0.3161 - accuracy: 0.8645 - val_loss: 0.3270 - val_accuracy: 0.8596 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 4s - loss: 0.3121 - accuracy: 0.8664 - val_loss: 0.3283 - val_accuracy: 0.8606 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 4s - loss: 0.3079 - accuracy: 0.8682 - val_loss: 0.3260 - val_accuracy: 0.8609 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 4s - loss: 0.3042 - accuracy: 0.8689 - val_loss: 0.3257 - val_accuracy: 0.8605 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 4s - loss: 0.2884 - accuracy: 0.8761 - val_loss: 0.3221 - val_accuracy: 0.8633 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 4s - loss: 0.2846 - accuracy: 0.8782 - val_loss: 0.3225 - val_accuracy: 0.8639 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 4s - loss: 0.2829 - accuracy: 0.8786 - val_loss: 0.3233 - val_accuracy: 0.8629 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "1164/1164 - 4s - loss: 0.2811 - accuracy: 0.8797 - val_loss: 0.3231 - val_accuracy: 0.8636 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 5s - loss: 0.2803 - accuracy: 0.8797 - val_loss: 0.3237 - val_accuracy: 0.8637 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 4s - loss: 0.2784 - accuracy: 0.8812 - val_loss: 0.3248 - val_accuracy: 0.8629 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 4s - loss: 0.2773 - accuracy: 0.8814 - val_loss: 0.3255 - val_accuracy: 0.8635 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 4s - loss: 0.2755 - accuracy: 0.8824 - val_loss: 0.3271 - val_accuracy: 0.8619 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 4s - loss: 0.2753 - accuracy: 0.8819 - val_loss: 0.3272 - val_accuracy: 0.8626 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 4s - loss: 0.2752 - accuracy: 0.8825 - val_loss: 0.3276 - val_accuracy: 0.8626 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 4s - loss: 0.2731 - accuracy: 0.8839 - val_loss: 0.3272 - val_accuracy: 0.8629 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.2717 - accuracy: 0.8842 - val_loss: 0.3271 - val_accuracy: 0.8628 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.2712 - accuracy: 0.8850 - val_loss: 0.3273 - val_accuracy: 0.8626 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 4s - loss: 0.2707 - accuracy: 0.8842 - val_loss: 0.3274 - val_accuracy: 0.8620 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 4s - loss: 0.2713 - accuracy: 0.8842 - val_loss: 0.3278 - val_accuracy: 0.8625 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 4s - loss: 0.2717 - accuracy: 0.8841 - val_loss: 0.3278 - val_accuracy: 0.8627 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 4s - loss: 0.2719 - accuracy: 0.8837 - val_loss: 0.3279 - val_accuracy: 0.8626 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 4s - loss: 0.2708 - accuracy: 0.8836 - val_loss: 0.3279 - val_accuracy: 0.8617 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 4s - loss: 0.2712 - accuracy: 0.8841 - val_loss: 0.3280 - val_accuracy: 0.8622 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 4s - loss: 0.2706 - accuracy: 0.8843 - val_loss: 0.3279 - val_accuracy: 0.8622 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "910/910 [==============================] - 2s 1ms/step - loss: 0.3225 - accuracy: 0.8639\n",
      "3637/3637 [==============================] - 5s 1ms/step - loss: 0.2678 - accuracy: 0.8860\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 512)               60928     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 228,865\n",
      "Trainable params: 227,073\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 6s - loss: 0.3753 - accuracy: 0.8378 - val_loss: 0.3362 - val_accuracy: 0.8556 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3310 - accuracy: 0.8570 - val_loss: 0.3335 - val_accuracy: 0.8573 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3210 - accuracy: 0.8617 - val_loss: 0.3298 - val_accuracy: 0.8580 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 5s - loss: 0.3134 - accuracy: 0.8648 - val_loss: 0.3305 - val_accuracy: 0.8581 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 5s - loss: 0.3069 - accuracy: 0.8665 - val_loss: 0.3293 - val_accuracy: 0.8585 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.3007 - accuracy: 0.8695 - val_loss: 0.3327 - val_accuracy: 0.8590 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 5s - loss: 0.2910 - accuracy: 0.8749 - val_loss: 0.3320 - val_accuracy: 0.8575 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 5s - loss: 0.2842 - accuracy: 0.8776 - val_loss: 0.3312 - val_accuracy: 0.8593 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.2740 - accuracy: 0.8803 - val_loss: 0.3356 - val_accuracy: 0.8591 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 5s - loss: 0.2648 - accuracy: 0.8851 - val_loss: 0.3440 - val_accuracy: 0.8579 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 5s - loss: 0.2274 - accuracy: 0.9028 - val_loss: 0.3503 - val_accuracy: 0.8569 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 5s - loss: 0.2122 - accuracy: 0.9098 - val_loss: 0.3651 - val_accuracy: 0.8546 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 6s - loss: 0.2033 - accuracy: 0.9134 - val_loss: 0.3765 - val_accuracy: 0.8526 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 6s - loss: 0.1964 - accuracy: 0.9169 - val_loss: 0.3876 - val_accuracy: 0.8517 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 5s - loss: 0.1901 - accuracy: 0.9201 - val_loss: 0.3999 - val_accuracy: 0.8500 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 5s - loss: 0.1853 - accuracy: 0.9212 - val_loss: 0.4078 - val_accuracy: 0.8502 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 5s - loss: 0.1808 - accuracy: 0.9240 - val_loss: 0.4164 - val_accuracy: 0.8487 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.1745 - accuracy: 0.9267 - val_loss: 0.4245 - val_accuracy: 0.8474 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 5s - loss: 0.1720 - accuracy: 0.9269 - val_loss: 0.4341 - val_accuracy: 0.8484 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 5s - loss: 0.1675 - accuracy: 0.9300 - val_loss: 0.4401 - val_accuracy: 0.8459 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.1606 - accuracy: 0.9333 - val_loss: 0.4411 - val_accuracy: 0.8462 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.1574 - accuracy: 0.9345 - val_loss: 0.4430 - val_accuracy: 0.8473 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.1580 - accuracy: 0.9340 - val_loss: 0.4452 - val_accuracy: 0.8472 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 6s - loss: 0.1562 - accuracy: 0.9356 - val_loss: 0.4476 - val_accuracy: 0.8470 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.1565 - accuracy: 0.9348 - val_loss: 0.4488 - val_accuracy: 0.8472 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 6s - loss: 0.1563 - accuracy: 0.9351 - val_loss: 0.4492 - val_accuracy: 0.8467 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "1164/1164 - 6s - loss: 0.1557 - accuracy: 0.9353 - val_loss: 0.4512 - val_accuracy: 0.8467 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 6s - loss: 0.1544 - accuracy: 0.9356 - val_loss: 0.4529 - val_accuracy: 0.8469 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 6s - loss: 0.1541 - accuracy: 0.9355 - val_loss: 0.4541 - val_accuracy: 0.8468 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 6s - loss: 0.1549 - accuracy: 0.9353 - val_loss: 0.4544 - val_accuracy: 0.8468 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "910/910 [==============================] - 2s 1ms/step - loss: 0.3312 - accuracy: 0.8593\n",
      "3637/3637 [==============================] - 5s 1ms/step - loss: 0.2498 - accuracy: 0.8927: 0s - loss: 0.249\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 512)               60928     \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 228,865\n",
      "Trainable params: 227,073\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 7s - loss: 0.3788 - accuracy: 0.8344 - val_loss: 0.3536 - val_accuracy: 0.8468 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 6s - loss: 0.3407 - accuracy: 0.8526 - val_loss: 0.3422 - val_accuracy: 0.8537 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3322 - accuracy: 0.8572 - val_loss: 0.3371 - val_accuracy: 0.8547 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 5s - loss: 0.3255 - accuracy: 0.8601 - val_loss: 0.3368 - val_accuracy: 0.8567 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 5s - loss: 0.3200 - accuracy: 0.8622 - val_loss: 0.3370 - val_accuracy: 0.8562 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.3139 - accuracy: 0.8643 - val_loss: 0.3319 - val_accuracy: 0.8588 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 5s - loss: 0.3080 - accuracy: 0.8680 - val_loss: 0.3320 - val_accuracy: 0.8561 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 5s - loss: 0.3006 - accuracy: 0.8705 - val_loss: 0.3348 - val_accuracy: 0.8562 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.2942 - accuracy: 0.8730 - val_loss: 0.3334 - val_accuracy: 0.8581 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 5s - loss: 0.2885 - accuracy: 0.8760 - val_loss: 0.3377 - val_accuracy: 0.8563 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 5s - loss: 0.2590 - accuracy: 0.8903 - val_loss: 0.3378 - val_accuracy: 0.8590 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 5s - loss: 0.2496 - accuracy: 0.8938 - val_loss: 0.3416 - val_accuracy: 0.8584 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 5s - loss: 0.2418 - accuracy: 0.8974 - val_loss: 0.3463 - val_accuracy: 0.8573 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 5s - loss: 0.2360 - accuracy: 0.9006 - val_loss: 0.3527 - val_accuracy: 0.8562 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 5s - loss: 0.2311 - accuracy: 0.9027 - val_loss: 0.3576 - val_accuracy: 0.8561 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 5s - loss: 0.2260 - accuracy: 0.9051 - val_loss: 0.3604 - val_accuracy: 0.8547 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 6s - loss: 0.2231 - accuracy: 0.9065 - val_loss: 0.3647 - val_accuracy: 0.8548 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.2177 - accuracy: 0.9093 - val_loss: 0.3705 - val_accuracy: 0.8544 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 5s - loss: 0.2161 - accuracy: 0.9094 - val_loss: 0.3733 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 5s - loss: 0.2124 - accuracy: 0.9113 - val_loss: 0.3774 - val_accuracy: 0.8521 - lr: 1.0000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.2054 - accuracy: 0.9145 - val_loss: 0.3769 - val_accuracy: 0.8527 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.2044 - accuracy: 0.9146 - val_loss: 0.3779 - val_accuracy: 0.8534 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.2045 - accuracy: 0.9151 - val_loss: 0.3789 - val_accuracy: 0.8529 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 5s - loss: 0.2028 - accuracy: 0.9162 - val_loss: 0.3796 - val_accuracy: 0.8536 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.2021 - accuracy: 0.9170 - val_loss: 0.3800 - val_accuracy: 0.8529 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 5s - loss: 0.2027 - accuracy: 0.9151 - val_loss: 0.3804 - val_accuracy: 0.8527 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 5s - loss: 0.2031 - accuracy: 0.9154 - val_loss: 0.3815 - val_accuracy: 0.8529 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 5s - loss: 0.2015 - accuracy: 0.9160 - val_loss: 0.3815 - val_accuracy: 0.8520 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 5s - loss: 0.2022 - accuracy: 0.9159 - val_loss: 0.3822 - val_accuracy: 0.8532 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 5s - loss: 0.2019 - accuracy: 0.9161 - val_loss: 0.3832 - val_accuracy: 0.8525 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "910/910 [==============================] - 4s 4ms/step - loss: 0.3378 - accuracy: 0.8590\n",
      "3637/3637 [==============================] - 4s 1ms/step - loss: 0.2325 - accuracy: 0.9028\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 512)               60928     \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 228,865\n",
      "Trainable params: 227,073\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1164/1164 - 7s - loss: 0.3764 - accuracy: 0.8351 - val_loss: 0.3442 - val_accuracy: 0.8519 - lr: 0.0010 - 7s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 6s - loss: 0.3433 - accuracy: 0.8532 - val_loss: 0.3372 - val_accuracy: 0.8549 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 6s - loss: 0.3330 - accuracy: 0.8566 - val_loss: 0.3317 - val_accuracy: 0.8573 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 6s - loss: 0.3283 - accuracy: 0.8584 - val_loss: 0.3334 - val_accuracy: 0.8571 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 6s - loss: 0.3224 - accuracy: 0.8611 - val_loss: 0.3295 - val_accuracy: 0.8593 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 6s - loss: 0.3176 - accuracy: 0.8631 - val_loss: 0.3265 - val_accuracy: 0.8614 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 6s - loss: 0.3124 - accuracy: 0.8651 - val_loss: 0.3294 - val_accuracy: 0.8597 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 6s - loss: 0.3069 - accuracy: 0.8677 - val_loss: 0.3256 - val_accuracy: 0.8598 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 6s - loss: 0.3005 - accuracy: 0.8701 - val_loss: 0.3302 - val_accuracy: 0.8591 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 6s - loss: 0.2956 - accuracy: 0.8726 - val_loss: 0.3306 - val_accuracy: 0.8606 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 6s - loss: 0.2724 - accuracy: 0.8830 - val_loss: 0.3268 - val_accuracy: 0.8623 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 6s - loss: 0.2649 - accuracy: 0.8870 - val_loss: 0.3288 - val_accuracy: 0.8614 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 6s - loss: 0.2608 - accuracy: 0.8881 - val_loss: 0.3327 - val_accuracy: 0.8604 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 6s - loss: 0.2575 - accuracy: 0.8902 - val_loss: 0.3336 - val_accuracy: 0.8610 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 6s - loss: 0.2544 - accuracy: 0.8911 - val_loss: 0.3359 - val_accuracy: 0.8599 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 6s - loss: 0.2517 - accuracy: 0.8926 - val_loss: 0.3377 - val_accuracy: 0.8597 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 6s - loss: 0.2498 - accuracy: 0.8928 - val_loss: 0.3398 - val_accuracy: 0.8597 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 6s - loss: 0.2476 - accuracy: 0.8946 - val_loss: 0.3418 - val_accuracy: 0.8584 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 6s - loss: 0.2459 - accuracy: 0.8952 - val_loss: 0.3428 - val_accuracy: 0.8584 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 6s - loss: 0.2434 - accuracy: 0.8963 - val_loss: 0.3449 - val_accuracy: 0.8573 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 6s - loss: 0.2378 - accuracy: 0.8989 - val_loss: 0.3452 - val_accuracy: 0.8583 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 6s - loss: 0.2382 - accuracy: 0.8991 - val_loss: 0.3453 - val_accuracy: 0.8578 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 6s - loss: 0.2384 - accuracy: 0.8985 - val_loss: 0.3451 - val_accuracy: 0.8578 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 6s - loss: 0.2369 - accuracy: 0.8983 - val_loss: 0.3459 - val_accuracy: 0.8584 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 6s - loss: 0.2360 - accuracy: 0.8999 - val_loss: 0.3463 - val_accuracy: 0.8586 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 6s - loss: 0.2370 - accuracy: 0.8989 - val_loss: 0.3466 - val_accuracy: 0.8581 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 6s - loss: 0.2371 - accuracy: 0.8996 - val_loss: 0.3469 - val_accuracy: 0.8579 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 6s - loss: 0.2361 - accuracy: 0.9002 - val_loss: 0.3470 - val_accuracy: 0.8581 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 6s - loss: 0.2361 - accuracy: 0.8998 - val_loss: 0.3474 - val_accuracy: 0.8581 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 6s - loss: 0.2364 - accuracy: 0.8992 - val_loss: 0.3479 - val_accuracy: 0.8586 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3268 - accuracy: 0.8623\n",
      "3637/3637 [==============================] - 5s 1ms/step - loss: 0.2512 - accuracy: 0.8934\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1024)              121856    \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785,409\n",
      "Trainable params: 781,825\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 12s - loss: 0.3748 - accuracy: 0.8386 - val_loss: 0.3399 - val_accuracy: 0.8539 - lr: 0.0010 - 12s/epoch - 10ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 11s - loss: 0.3302 - accuracy: 0.8574 - val_loss: 0.3306 - val_accuracy: 0.8574 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 11s - loss: 0.3206 - accuracy: 0.8612 - val_loss: 0.3274 - val_accuracy: 0.8591 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 11s - loss: 0.3145 - accuracy: 0.8637 - val_loss: 0.3261 - val_accuracy: 0.8595 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 11s - loss: 0.3075 - accuracy: 0.8671 - val_loss: 0.3249 - val_accuracy: 0.8601 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 11s - loss: 0.2988 - accuracy: 0.8705 - val_loss: 0.3259 - val_accuracy: 0.8590 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 11s - loss: 0.2905 - accuracy: 0.8742 - val_loss: 0.3362 - val_accuracy: 0.8571 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 11s - loss: 0.2798 - accuracy: 0.8784 - val_loss: 0.3417 - val_accuracy: 0.8557 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 11s - loss: 0.2673 - accuracy: 0.8849 - val_loss: 0.3425 - val_accuracy: 0.8584 - lr: 0.0010 - 11s/epoch - 9ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 11s - loss: 0.2556 - accuracy: 0.8887 - val_loss: 0.3487 - val_accuracy: 0.8555 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 11s - loss: 0.2062 - accuracy: 0.9128 - val_loss: 0.3741 - val_accuracy: 0.8553 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 11s - loss: 0.1849 - accuracy: 0.9225 - val_loss: 0.4011 - val_accuracy: 0.8512 - lr: 1.0000e-04 - 11s/epoch - 9ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 11s - loss: 0.1719 - accuracy: 0.9277 - val_loss: 0.4238 - val_accuracy: 0.8503 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "1164/1164 - 11s - loss: 0.1608 - accuracy: 0.9334 - val_loss: 0.4451 - val_accuracy: 0.8491 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 11s - loss: 0.1518 - accuracy: 0.9367 - val_loss: 0.4674 - val_accuracy: 0.8472 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 11s - loss: 0.1435 - accuracy: 0.9403 - val_loss: 0.4898 - val_accuracy: 0.8456 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 11s - loss: 0.1364 - accuracy: 0.9433 - val_loss: 0.5056 - val_accuracy: 0.8461 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 11s - loss: 0.1290 - accuracy: 0.9467 - val_loss: 0.5226 - val_accuracy: 0.8445 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 11s - loss: 0.1248 - accuracy: 0.9485 - val_loss: 0.5426 - val_accuracy: 0.8435 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 11s - loss: 0.1183 - accuracy: 0.9513 - val_loss: 0.5631 - val_accuracy: 0.8435 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 11s - loss: 0.1058 - accuracy: 0.9575 - val_loss: 0.5666 - val_accuracy: 0.8433 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 11s - loss: 0.1060 - accuracy: 0.9574 - val_loss: 0.5687 - val_accuracy: 0.8441 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 11s - loss: 0.1050 - accuracy: 0.9579 - val_loss: 0.5740 - val_accuracy: 0.8434 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 11s - loss: 0.1036 - accuracy: 0.9581 - val_loss: 0.5791 - val_accuracy: 0.8429 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 11s - loss: 0.1017 - accuracy: 0.9591 - val_loss: 0.5802 - val_accuracy: 0.8428 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 11s - loss: 0.1016 - accuracy: 0.9592 - val_loss: 0.5835 - val_accuracy: 0.8426 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 11s - loss: 0.1014 - accuracy: 0.9588 - val_loss: 0.5871 - val_accuracy: 0.8427 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 11s - loss: 0.1014 - accuracy: 0.9593 - val_loss: 0.5903 - val_accuracy: 0.8429 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 11s - loss: 0.0994 - accuracy: 0.9602 - val_loss: 0.5950 - val_accuracy: 0.8421 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 11s - loss: 0.0990 - accuracy: 0.9607 - val_loss: 0.5961 - val_accuracy: 0.8418 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3249 - accuracy: 0.8601\n",
      "3637/3637 [==============================] - 6s 2ms/step - loss: 0.2818 - accuracy: 0.8798\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1024)              121856    \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785,409\n",
      "Trainable params: 781,825\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 12s - loss: 0.3821 - accuracy: 0.8332 - val_loss: 0.3519 - val_accuracy: 0.8472 - lr: 0.0010 - 12s/epoch - 10ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 11s - loss: 0.3431 - accuracy: 0.8520 - val_loss: 0.3417 - val_accuracy: 0.8519 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 12s - loss: 0.3356 - accuracy: 0.8552 - val_loss: 0.3401 - val_accuracy: 0.8549 - lr: 0.0010 - 12s/epoch - 10ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 11s - loss: 0.3292 - accuracy: 0.8584 - val_loss: 0.3348 - val_accuracy: 0.8572 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 11s - loss: 0.3258 - accuracy: 0.8598 - val_loss: 0.3337 - val_accuracy: 0.8569 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 11s - loss: 0.3214 - accuracy: 0.8616 - val_loss: 0.3308 - val_accuracy: 0.8573 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 11s - loss: 0.3175 - accuracy: 0.8629 - val_loss: 0.3328 - val_accuracy: 0.8580 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 11s - loss: 0.3108 - accuracy: 0.8662 - val_loss: 0.3323 - val_accuracy: 0.8588 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 12s - loss: 0.3061 - accuracy: 0.8678 - val_loss: 0.3287 - val_accuracy: 0.8586 - lr: 0.0010 - 12s/epoch - 10ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 11s - loss: 0.2994 - accuracy: 0.8706 - val_loss: 0.3291 - val_accuracy: 0.8595 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 11s - loss: 0.2745 - accuracy: 0.8828 - val_loss: 0.3273 - val_accuracy: 0.8621 - lr: 1.0000e-04 - 11s/epoch - 9ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 11s - loss: 0.2637 - accuracy: 0.8868 - val_loss: 0.3312 - val_accuracy: 0.8625 - lr: 1.0000e-04 - 11s/epoch - 9ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 12s - loss: 0.2551 - accuracy: 0.8904 - val_loss: 0.3351 - val_accuracy: 0.8606 - lr: 1.0000e-04 - 12s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 11s - loss: 0.2486 - accuracy: 0.8938 - val_loss: 0.3392 - val_accuracy: 0.8588 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 11s - loss: 0.2410 - accuracy: 0.8975 - val_loss: 0.3448 - val_accuracy: 0.8587 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 11s - loss: 0.2358 - accuracy: 0.9005 - val_loss: 0.3474 - val_accuracy: 0.8566 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 12s - loss: 0.2304 - accuracy: 0.9030 - val_loss: 0.3528 - val_accuracy: 0.8555 - lr: 1.0000e-04 - 12s/epoch - 10ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 12s - loss: 0.2236 - accuracy: 0.9059 - val_loss: 0.3582 - val_accuracy: 0.8557 - lr: 1.0000e-04 - 12s/epoch - 10ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 11s - loss: 0.2186 - accuracy: 0.9080 - val_loss: 0.3628 - val_accuracy: 0.8555 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 11s - loss: 0.2133 - accuracy: 0.9102 - val_loss: 0.3666 - val_accuracy: 0.8550 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 11s - loss: 0.2037 - accuracy: 0.9157 - val_loss: 0.3676 - val_accuracy: 0.8547 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 11s - loss: 0.2036 - accuracy: 0.9152 - val_loss: 0.3687 - val_accuracy: 0.8547 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 12s - loss: 0.2022 - accuracy: 0.9161 - val_loss: 0.3692 - val_accuracy: 0.8545 - lr: 1.0000e-05 - 12s/epoch - 10ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 12s - loss: 0.2024 - accuracy: 0.9160 - val_loss: 0.3706 - val_accuracy: 0.8542 - lr: 1.0000e-05 - 12s/epoch - 10ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 12s - loss: 0.2011 - accuracy: 0.9164 - val_loss: 0.3718 - val_accuracy: 0.8545 - lr: 1.0000e-05 - 12s/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1164/1164 - 12s - loss: 0.1992 - accuracy: 0.9177 - val_loss: 0.3725 - val_accuracy: 0.8543 - lr: 1.0000e-05 - 12s/epoch - 10ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 12s - loss: 0.1996 - accuracy: 0.9173 - val_loss: 0.3732 - val_accuracy: 0.8539 - lr: 1.0000e-05 - 12s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 12s - loss: 0.1999 - accuracy: 0.9165 - val_loss: 0.3742 - val_accuracy: 0.8538 - lr: 1.0000e-05 - 12s/epoch - 11ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 11s - loss: 0.1982 - accuracy: 0.9183 - val_loss: 0.3747 - val_accuracy: 0.8538 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 11s - loss: 0.1971 - accuracy: 0.9188 - val_loss: 0.3756 - val_accuracy: 0.8534 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3312 - accuracy: 0.8625\n",
      "3637/3637 [==============================] - 7s 2ms/step - loss: 0.2397 - accuracy: 0.8986\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1024)              121856    \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785,409\n",
      "Trainable params: 781,825\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 12s - loss: 0.3813 - accuracy: 0.8340 - val_loss: 0.3669 - val_accuracy: 0.8428 - lr: 0.0010 - 12s/epoch - 10ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 11s - loss: 0.3435 - accuracy: 0.8537 - val_loss: 0.3389 - val_accuracy: 0.8558 - lr: 0.0010 - 11s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 11s - loss: 0.3354 - accuracy: 0.8558 - val_loss: 0.3348 - val_accuracy: 0.8577 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 11s - loss: 0.3289 - accuracy: 0.8579 - val_loss: 0.3407 - val_accuracy: 0.8541 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 11s - loss: 0.3236 - accuracy: 0.8610 - val_loss: 0.3330 - val_accuracy: 0.8586 - lr: 0.0010 - 11s/epoch - 9ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 11s - loss: 0.3194 - accuracy: 0.8631 - val_loss: 0.3310 - val_accuracy: 0.8586 - lr: 0.0010 - 11s/epoch - 9ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 11s - loss: 0.3150 - accuracy: 0.8653 - val_loss: 0.3306 - val_accuracy: 0.8589 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 11s - loss: 0.3092 - accuracy: 0.8670 - val_loss: 0.3265 - val_accuracy: 0.8598 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 11s - loss: 0.3038 - accuracy: 0.8696 - val_loss: 0.3308 - val_accuracy: 0.8576 - lr: 0.0010 - 11s/epoch - 10ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 11s - loss: 0.2983 - accuracy: 0.8716 - val_loss: 0.3289 - val_accuracy: 0.8587 - lr: 0.0010 - 11s/epoch - 9ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 11s - loss: 0.2714 - accuracy: 0.8836 - val_loss: 0.3288 - val_accuracy: 0.8603 - lr: 1.0000e-04 - 11s/epoch - 9ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 11s - loss: 0.2606 - accuracy: 0.8887 - val_loss: 0.3314 - val_accuracy: 0.8596 - lr: 1.0000e-04 - 11s/epoch - 9ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 11s - loss: 0.2532 - accuracy: 0.8922 - val_loss: 0.3361 - val_accuracy: 0.8591 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 11s - loss: 0.2482 - accuracy: 0.8949 - val_loss: 0.3396 - val_accuracy: 0.8581 - lr: 1.0000e-04 - 11s/epoch - 9ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 11s - loss: 0.2422 - accuracy: 0.8975 - val_loss: 0.3437 - val_accuracy: 0.8574 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 11s - loss: 0.2370 - accuracy: 0.8994 - val_loss: 0.3487 - val_accuracy: 0.8573 - lr: 1.0000e-04 - 11s/epoch - 9ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 11s - loss: 0.2318 - accuracy: 0.9019 - val_loss: 0.3532 - val_accuracy: 0.8560 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 11s - loss: 0.2275 - accuracy: 0.9043 - val_loss: 0.3575 - val_accuracy: 0.8559 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 11s - loss: 0.2246 - accuracy: 0.9049 - val_loss: 0.3595 - val_accuracy: 0.8546 - lr: 1.0000e-04 - 11s/epoch - 9ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 11s - loss: 0.2200 - accuracy: 0.9075 - val_loss: 0.3646 - val_accuracy: 0.8536 - lr: 1.0000e-04 - 11s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 11s - loss: 0.2120 - accuracy: 0.9113 - val_loss: 0.3650 - val_accuracy: 0.8544 - lr: 1.0000e-05 - 11s/epoch - 9ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 11s - loss: 0.2117 - accuracy: 0.9111 - val_loss: 0.3650 - val_accuracy: 0.8539 - lr: 1.0000e-05 - 11s/epoch - 9ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 11s - loss: 0.2090 - accuracy: 0.9128 - val_loss: 0.3657 - val_accuracy: 0.8540 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 11s - loss: 0.2101 - accuracy: 0.9117 - val_loss: 0.3665 - val_accuracy: 0.8538 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 11s - loss: 0.2095 - accuracy: 0.9126 - val_loss: 0.3672 - val_accuracy: 0.8535 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 11s - loss: 0.2087 - accuracy: 0.9130 - val_loss: 0.3681 - val_accuracy: 0.8539 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 11s - loss: 0.2078 - accuracy: 0.9132 - val_loss: 0.3685 - val_accuracy: 0.8535 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 12s - loss: 0.2070 - accuracy: 0.9141 - val_loss: 0.3692 - val_accuracy: 0.8534 - lr: 1.0000e-05 - 12s/epoch - 10ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 11s - loss: 0.2071 - accuracy: 0.9135 - val_loss: 0.3695 - val_accuracy: 0.8526 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 11s - loss: 0.2060 - accuracy: 0.9144 - val_loss: 0.3703 - val_accuracy: 0.8529 - lr: 1.0000e-05 - 11s/epoch - 10ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8603\n",
      "3637/3637 [==============================] - 7s 2ms/step - loss: 0.2484 - accuracy: 0.8942\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 2048)              243712    \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 2048)             8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,881,537\n",
      "Trainable params: 2,874,369\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1164/1164 - 29s - loss: 0.3796 - accuracy: 0.8384 - val_loss: 0.3412 - val_accuracy: 0.8511 - lr: 0.0010 - 29s/epoch - 25ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 28s - loss: 0.3327 - accuracy: 0.8570 - val_loss: 0.3286 - val_accuracy: 0.8585 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 28s - loss: 0.3241 - accuracy: 0.8608 - val_loss: 0.3276 - val_accuracy: 0.8594 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 28s - loss: 0.3176 - accuracy: 0.8623 - val_loss: 0.3353 - val_accuracy: 0.8524 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 28s - loss: 0.3104 - accuracy: 0.8659 - val_loss: 0.3351 - val_accuracy: 0.8541 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 28s - loss: 0.3027 - accuracy: 0.8688 - val_loss: 0.3275 - val_accuracy: 0.8610 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 28s - loss: 0.2941 - accuracy: 0.8728 - val_loss: 0.3266 - val_accuracy: 0.8614 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 28s - loss: 0.2841 - accuracy: 0.8763 - val_loss: 0.3397 - val_accuracy: 0.8553 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 28s - loss: 0.2721 - accuracy: 0.8817 - val_loss: 0.3421 - val_accuracy: 0.8588 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 28s - loss: 0.2586 - accuracy: 0.8871 - val_loss: 0.3504 - val_accuracy: 0.8521 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 28s - loss: 0.2060 - accuracy: 0.9127 - val_loss: 0.3813 - val_accuracy: 0.8548 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 28s - loss: 0.1823 - accuracy: 0.9228 - val_loss: 0.4162 - val_accuracy: 0.8501 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 29s - loss: 0.1669 - accuracy: 0.9300 - val_loss: 0.4473 - val_accuracy: 0.8468 - lr: 1.0000e-04 - 29s/epoch - 25ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 28s - loss: 0.1556 - accuracy: 0.9345 - val_loss: 0.4708 - val_accuracy: 0.8457 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 28s - loss: 0.1434 - accuracy: 0.9408 - val_loss: 0.5105 - val_accuracy: 0.8445 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 29s - loss: 0.1334 - accuracy: 0.9447 - val_loss: 0.5302 - val_accuracy: 0.8421 - lr: 1.0000e-04 - 29s/epoch - 25ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 28s - loss: 0.1235 - accuracy: 0.9491 - val_loss: 0.5726 - val_accuracy: 0.8419 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 28s - loss: 0.1154 - accuracy: 0.9523 - val_loss: 0.6004 - val_accuracy: 0.8392 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 28s - loss: 0.1066 - accuracy: 0.9570 - val_loss: 0.6293 - val_accuracy: 0.8402 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 28s - loss: 0.0986 - accuracy: 0.9597 - val_loss: 0.6603 - val_accuracy: 0.8376 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 28s - loss: 0.0849 - accuracy: 0.9668 - val_loss: 0.6668 - val_accuracy: 0.8387 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 29s - loss: 0.0835 - accuracy: 0.9668 - val_loss: 0.6766 - val_accuracy: 0.8385 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 28s - loss: 0.0824 - accuracy: 0.9678 - val_loss: 0.6848 - val_accuracy: 0.8381 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 28s - loss: 0.0802 - accuracy: 0.9689 - val_loss: 0.6894 - val_accuracy: 0.8377 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 28s - loss: 0.0794 - accuracy: 0.9691 - val_loss: 0.6976 - val_accuracy: 0.8371 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 28s - loss: 0.0781 - accuracy: 0.9694 - val_loss: 0.7036 - val_accuracy: 0.8372 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 33s - loss: 0.0775 - accuracy: 0.9697 - val_loss: 0.7088 - val_accuracy: 0.8372 - lr: 1.0000e-05 - 33s/epoch - 29ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 30s - loss: 0.0772 - accuracy: 0.9691 - val_loss: 0.7153 - val_accuracy: 0.8374 - lr: 1.0000e-05 - 30s/epoch - 26ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 30s - loss: 0.0749 - accuracy: 0.9708 - val_loss: 0.7252 - val_accuracy: 0.8370 - lr: 1.0000e-05 - 30s/epoch - 26ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 30s - loss: 0.0743 - accuracy: 0.9708 - val_loss: 0.7322 - val_accuracy: 0.8375 - lr: 1.0000e-05 - 30s/epoch - 25ms/step\n",
      "910/910 [==============================] - 4s 4ms/step - loss: 0.3266 - accuracy: 0.8614\n",
      "3637/3637 [==============================] - 14s 4ms/step - loss: 0.2666 - accuracy: 0.8851\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 2048)              243712    \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 2048)             8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,881,537\n",
      "Trainable params: 2,874,369\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 31s - loss: 0.3910 - accuracy: 0.8301 - val_loss: 0.3524 - val_accuracy: 0.8491 - lr: 0.0010 - 31s/epoch - 26ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 29s - loss: 0.3507 - accuracy: 0.8491 - val_loss: 0.3443 - val_accuracy: 0.8517 - lr: 0.0010 - 29s/epoch - 25ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 29s - loss: 0.3423 - accuracy: 0.8520 - val_loss: 0.3485 - val_accuracy: 0.8496 - lr: 0.0010 - 29s/epoch - 25ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 28s - loss: 0.3381 - accuracy: 0.8549 - val_loss: 0.3403 - val_accuracy: 0.8512 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 28s - loss: 0.3339 - accuracy: 0.8565 - val_loss: 0.3348 - val_accuracy: 0.8569 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 28s - loss: 0.3308 - accuracy: 0.8575 - val_loss: 0.3355 - val_accuracy: 0.8558 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 28s - loss: 0.3265 - accuracy: 0.8594 - val_loss: 0.3328 - val_accuracy: 0.8566 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 28s - loss: 0.3227 - accuracy: 0.8612 - val_loss: 0.3304 - val_accuracy: 0.8566 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 28s - loss: 0.3189 - accuracy: 0.8620 - val_loss: 0.3302 - val_accuracy: 0.8591 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 28s - loss: 0.3145 - accuracy: 0.8638 - val_loss: 0.3300 - val_accuracy: 0.8586 - lr: 0.0010 - 28s/epoch - 24ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 28s - loss: 0.2961 - accuracy: 0.8728 - val_loss: 0.3250 - val_accuracy: 0.8614 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 28s - loss: 0.2883 - accuracy: 0.8757 - val_loss: 0.3251 - val_accuracy: 0.8607 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "1164/1164 - 28s - loss: 0.2832 - accuracy: 0.8773 - val_loss: 0.3257 - val_accuracy: 0.8620 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 28s - loss: 0.2777 - accuracy: 0.8802 - val_loss: 0.3271 - val_accuracy: 0.8618 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 28s - loss: 0.2721 - accuracy: 0.8828 - val_loss: 0.3287 - val_accuracy: 0.8621 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 28s - loss: 0.2679 - accuracy: 0.8844 - val_loss: 0.3319 - val_accuracy: 0.8596 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 28s - loss: 0.2615 - accuracy: 0.8881 - val_loss: 0.3345 - val_accuracy: 0.8595 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 28s - loss: 0.2567 - accuracy: 0.8897 - val_loss: 0.3352 - val_accuracy: 0.8594 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 28s - loss: 0.2511 - accuracy: 0.8931 - val_loss: 0.3386 - val_accuracy: 0.8588 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 28s - loss: 0.2454 - accuracy: 0.8948 - val_loss: 0.3417 - val_accuracy: 0.8586 - lr: 1.0000e-04 - 28s/epoch - 24ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 28s - loss: 0.2377 - accuracy: 0.8995 - val_loss: 0.3425 - val_accuracy: 0.8586 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 28s - loss: 0.2360 - accuracy: 0.8998 - val_loss: 0.3434 - val_accuracy: 0.8587 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 28s - loss: 0.2355 - accuracy: 0.9000 - val_loss: 0.3434 - val_accuracy: 0.8587 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 30s - loss: 0.2349 - accuracy: 0.9007 - val_loss: 0.3439 - val_accuracy: 0.8583 - lr: 1.0000e-05 - 30s/epoch - 25ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 28s - loss: 0.2339 - accuracy: 0.9005 - val_loss: 0.3446 - val_accuracy: 0.8580 - lr: 1.0000e-05 - 28s/epoch - 24ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 29s - loss: 0.2331 - accuracy: 0.9014 - val_loss: 0.3445 - val_accuracy: 0.8579 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 29s - loss: 0.2315 - accuracy: 0.9029 - val_loss: 0.3450 - val_accuracy: 0.8573 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 29s - loss: 0.2304 - accuracy: 0.9029 - val_loss: 0.3465 - val_accuracy: 0.8578 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 29s - loss: 0.2310 - accuracy: 0.9020 - val_loss: 0.3466 - val_accuracy: 0.8576 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 29s - loss: 0.2304 - accuracy: 0.9026 - val_loss: 0.3474 - val_accuracy: 0.8579 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "910/910 [==============================] - 4s 4ms/step - loss: 0.3287 - accuracy: 0.8621\n",
      "3637/3637 [==============================] - 14s 4ms/step - loss: 0.2506 - accuracy: 0.8936\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 2048)              243712    \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 2048)             8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,881,537\n",
      "Trainable params: 2,874,369\n",
      "Non-trainable params: 7,168\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 31s - loss: 0.3919 - accuracy: 0.8311 - val_loss: 0.3534 - val_accuracy: 0.8512 - lr: 0.0010 - 31s/epoch - 27ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 29s - loss: 0.3507 - accuracy: 0.8487 - val_loss: 0.3412 - val_accuracy: 0.8539 - lr: 0.0010 - 29s/epoch - 25ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 29s - loss: 0.3416 - accuracy: 0.8529 - val_loss: 0.3373 - val_accuracy: 0.8549 - lr: 0.0010 - 29s/epoch - 25ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 30s - loss: 0.3363 - accuracy: 0.8553 - val_loss: 0.3406 - val_accuracy: 0.8509 - lr: 0.0010 - 30s/epoch - 26ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 30s - loss: 0.3316 - accuracy: 0.8580 - val_loss: 0.3346 - val_accuracy: 0.8571 - lr: 0.0010 - 30s/epoch - 26ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 30s - loss: 0.3283 - accuracy: 0.8586 - val_loss: 0.3392 - val_accuracy: 0.8543 - lr: 0.0010 - 30s/epoch - 26ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 29s - loss: 0.3245 - accuracy: 0.8605 - val_loss: 0.3276 - val_accuracy: 0.8596 - lr: 0.0010 - 29s/epoch - 25ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 30s - loss: 0.3214 - accuracy: 0.8612 - val_loss: 0.3289 - val_accuracy: 0.8586 - lr: 0.0010 - 30s/epoch - 25ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 30s - loss: 0.3185 - accuracy: 0.8626 - val_loss: 0.3290 - val_accuracy: 0.8588 - lr: 0.0010 - 30s/epoch - 25ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 29s - loss: 0.3140 - accuracy: 0.8645 - val_loss: 0.3250 - val_accuracy: 0.8591 - lr: 0.0010 - 29s/epoch - 25ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 29s - loss: 0.2952 - accuracy: 0.8739 - val_loss: 0.3206 - val_accuracy: 0.8624 - lr: 1.0000e-04 - 29s/epoch - 25ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 30s - loss: 0.2875 - accuracy: 0.8763 - val_loss: 0.3222 - val_accuracy: 0.8628 - lr: 1.0000e-04 - 30s/epoch - 25ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 29s - loss: 0.2807 - accuracy: 0.8785 - val_loss: 0.3232 - val_accuracy: 0.8629 - lr: 1.0000e-04 - 29s/epoch - 25ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 30s - loss: 0.2755 - accuracy: 0.8810 - val_loss: 0.3253 - val_accuracy: 0.8616 - lr: 1.0000e-04 - 30s/epoch - 26ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 30s - loss: 0.2700 - accuracy: 0.8831 - val_loss: 0.3278 - val_accuracy: 0.8615 - lr: 1.0000e-04 - 30s/epoch - 26ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 29s - loss: 0.2646 - accuracy: 0.8855 - val_loss: 0.3309 - val_accuracy: 0.8602 - lr: 1.0000e-04 - 29s/epoch - 25ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 29s - loss: 0.2593 - accuracy: 0.8882 - val_loss: 0.3333 - val_accuracy: 0.8591 - lr: 1.0000e-04 - 29s/epoch - 25ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 30s - loss: 0.2545 - accuracy: 0.8907 - val_loss: 0.3366 - val_accuracy: 0.8587 - lr: 1.0000e-04 - 30s/epoch - 26ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 30s - loss: 0.2490 - accuracy: 0.8928 - val_loss: 0.3397 - val_accuracy: 0.8571 - lr: 1.0000e-04 - 30s/epoch - 26ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 30s - loss: 0.2447 - accuracy: 0.8954 - val_loss: 0.3443 - val_accuracy: 0.8557 - lr: 1.0000e-04 - 30s/epoch - 25ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 30s - loss: 0.2360 - accuracy: 0.8997 - val_loss: 0.3442 - val_accuracy: 0.8557 - lr: 1.0000e-05 - 30s/epoch - 25ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 30s - loss: 0.2347 - accuracy: 0.8996 - val_loss: 0.3449 - val_accuracy: 0.8558 - lr: 1.0000e-05 - 30s/epoch - 25ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 30s - loss: 0.2340 - accuracy: 0.9005 - val_loss: 0.3451 - val_accuracy: 0.8559 - lr: 1.0000e-05 - 30s/epoch - 26ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 30s - loss: 0.2321 - accuracy: 0.9010 - val_loss: 0.3457 - val_accuracy: 0.8559 - lr: 1.0000e-05 - 30s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "1164/1164 - 29s - loss: 0.2329 - accuracy: 0.9009 - val_loss: 0.3463 - val_accuracy: 0.8557 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 30s - loss: 0.2307 - accuracy: 0.9014 - val_loss: 0.3467 - val_accuracy: 0.8560 - lr: 1.0000e-05 - 30s/epoch - 25ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 29s - loss: 0.2309 - accuracy: 0.9020 - val_loss: 0.3477 - val_accuracy: 0.8557 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 29s - loss: 0.2293 - accuracy: 0.9022 - val_loss: 0.3480 - val_accuracy: 0.8555 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 29s - loss: 0.2288 - accuracy: 0.9024 - val_loss: 0.3487 - val_accuracy: 0.8553 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 29s - loss: 0.2268 - accuracy: 0.9044 - val_loss: 0.3497 - val_accuracy: 0.8553 - lr: 1.0000e-05 - 29s/epoch - 25ms/step\n",
      "910/910 [==============================] - 4s 4ms/step - loss: 0.3232 - accuracy: 0.8629\n",
      "3637/3637 [==============================] - 14s 4ms/step - loss: 0.2612 - accuracy: 0.8882\n"
     ]
    }
   ],
   "source": [
    "best_function= None\n",
    "best_unit = None\n",
    "best = 0\n",
    "units = [64,128, 256,512]\n",
    "functions = ['relu', 'tanh', 'sigmoid']\n",
    "f= open(\"median_onehot.txt\",\"w+\")\n",
    "for unit in units:\n",
    "    for func in functions:\n",
    "        f.write(' unit, activation function, features , train accuracy, test accuracy \\n' )\n",
    "        df_train, df_test = train_test_split(df1,test_size=0.2, random_state=0)\n",
    "        X_train = df_train.drop([\"RainTomorrow\"], axis=1)\n",
    "        y_train = df_train.RainTomorrow\n",
    "        X_test = df_test.drop([\"RainTomorrow\"], axis=1)\n",
    "        y_test = df_test.RainTomorrow\n",
    "\n",
    "        X_train,X_test = handle_nan(X_train, X_test)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train= scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        num_features = X_train.shape[1]\n",
    "\n",
    "        model = fully_dense_model(num_features, (X_train,y_train), (X_test, y_test), units = unit,activation = func )\n",
    "        loss, test_accuracy = model.evaluate(X_test,y_test)\n",
    "        _, train_accuracy = model.evaluate(X_train, y_train)\n",
    "        string = str(unit) + ' ' + func+ ' ' +str(num_features)+' '+str(train_accuracy)+ ' '+str(test_accuracy)+'\\n'\n",
    "        f.write(string)\n",
    "        \n",
    "        if best < test_accuracy:\n",
    "            best = test_accuracy\n",
    "            best_unit = unit\n",
    "            best_function = func\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0958226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy:  0.8638800978660583 best unit 64 best function sigmoid\n"
     ]
    }
   ],
   "source": [
    "print('best accuracy: ', best, 'best unit', best_unit, 'best function', best_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7294bc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 256)               30464     \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,473\n",
      "Trainable params: 72,577\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 4s - loss: 0.3733 - accuracy: 0.8376 - val_loss: 0.3409 - val_accuracy: 0.8510 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 3s - loss: 0.3265 - accuracy: 0.8589 - val_loss: 0.3352 - val_accuracy: 0.8562 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 3s - loss: 0.3163 - accuracy: 0.8632 - val_loss: 0.3292 - val_accuracy: 0.8581 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 3s - loss: 0.3088 - accuracy: 0.8671 - val_loss: 0.3294 - val_accuracy: 0.8602 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 3s - loss: 0.3015 - accuracy: 0.8694 - val_loss: 0.3311 - val_accuracy: 0.8602 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 3s - loss: 0.2936 - accuracy: 0.8730 - val_loss: 0.3343 - val_accuracy: 0.8564 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 3s - loss: 0.2850 - accuracy: 0.8779 - val_loss: 0.3430 - val_accuracy: 0.8548 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 3s - loss: 0.2770 - accuracy: 0.8814 - val_loss: 0.3423 - val_accuracy: 0.8560 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 3s - loss: 0.2684 - accuracy: 0.8839 - val_loss: 0.3473 - val_accuracy: 0.8557 - lr: 0.0010 - 3s/epoch - 2ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 3s - loss: 0.2595 - accuracy: 0.8880 - val_loss: 0.3626 - val_accuracy: 0.8483 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 6s - loss: 0.2223 - accuracy: 0.9060 - val_loss: 0.3589 - val_accuracy: 0.8531 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 3s - loss: 0.2090 - accuracy: 0.9127 - val_loss: 0.3689 - val_accuracy: 0.8526 - lr: 1.0000e-04 - 3s/epoch - 2ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 3s - loss: 0.2024 - accuracy: 0.9154 - val_loss: 0.3790 - val_accuracy: 0.8508 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 3s - loss: 0.1955 - accuracy: 0.9192 - val_loss: 0.3872 - val_accuracy: 0.8489 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 3s - loss: 0.1906 - accuracy: 0.9213 - val_loss: 0.3964 - val_accuracy: 0.8481 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 3s - loss: 0.1860 - accuracy: 0.9233 - val_loss: 0.4054 - val_accuracy: 0.8479 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 3s - loss: 0.1816 - accuracy: 0.9260 - val_loss: 0.4131 - val_accuracy: 0.8462 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 3s - loss: 0.1784 - accuracy: 0.9265 - val_loss: 0.4202 - val_accuracy: 0.8446 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 3s - loss: 0.1742 - accuracy: 0.9282 - val_loss: 0.4274 - val_accuracy: 0.8443 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 3s - loss: 0.1703 - accuracy: 0.9300 - val_loss: 0.4342 - val_accuracy: 0.8437 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 6s - loss: 0.1622 - accuracy: 0.9348 - val_loss: 0.4348 - val_accuracy: 0.8436 - lr: 1.0000e-05 - 6s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 3s - loss: 0.1616 - accuracy: 0.9345 - val_loss: 0.4357 - val_accuracy: 0.8437 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 3s - loss: 0.1602 - accuracy: 0.9357 - val_loss: 0.4372 - val_accuracy: 0.8435 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 3s - loss: 0.1603 - accuracy: 0.9352 - val_loss: 0.4379 - val_accuracy: 0.8437 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 4s - loss: 0.1609 - accuracy: 0.9350 - val_loss: 0.4393 - val_accuracy: 0.8433 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 4s - loss: 0.1604 - accuracy: 0.9350 - val_loss: 0.4408 - val_accuracy: 0.8431 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 3s - loss: 0.1595 - accuracy: 0.9353 - val_loss: 0.4402 - val_accuracy: 0.8430 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 3s - loss: 0.1592 - accuracy: 0.9360 - val_loss: 0.4413 - val_accuracy: 0.8433 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 3s - loss: 0.1577 - accuracy: 0.9360 - val_loss: 0.4440 - val_accuracy: 0.8434 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 3s - loss: 0.1575 - accuracy: 0.9369 - val_loss: 0.4454 - val_accuracy: 0.8432 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3311 - accuracy: 0.8602\n",
      "3637/3637 [==============================] - 9s 2ms/step - loss: 0.2763 - accuracy: 0.8815\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 256)               30464     \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,473\n",
      "Trainable params: 72,577\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1164/1164 - 4s - loss: 0.3780 - accuracy: 0.8339 - val_loss: 0.3511 - val_accuracy: 0.8489 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 3s - loss: 0.3355 - accuracy: 0.8557 - val_loss: 0.3384 - val_accuracy: 0.8539 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 3s - loss: 0.3249 - accuracy: 0.8597 - val_loss: 0.3352 - val_accuracy: 0.8565 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 3s - loss: 0.3154 - accuracy: 0.8649 - val_loss: 0.3348 - val_accuracy: 0.8590 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 4s - loss: 0.3071 - accuracy: 0.8674 - val_loss: 0.3364 - val_accuracy: 0.8569 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.2984 - accuracy: 0.8717 - val_loss: 0.3384 - val_accuracy: 0.8568 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 3s - loss: 0.2897 - accuracy: 0.8756 - val_loss: 0.3395 - val_accuracy: 0.8555 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 4s - loss: 0.2801 - accuracy: 0.8806 - val_loss: 0.3446 - val_accuracy: 0.8555 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 3s - loss: 0.2707 - accuracy: 0.8845 - val_loss: 0.3505 - val_accuracy: 0.8540 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 4s - loss: 0.2588 - accuracy: 0.8905 - val_loss: 0.3592 - val_accuracy: 0.8488 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 3s - loss: 0.2225 - accuracy: 0.9083 - val_loss: 0.3589 - val_accuracy: 0.8542 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 3s - loss: 0.2098 - accuracy: 0.9141 - val_loss: 0.3670 - val_accuracy: 0.8525 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 3s - loss: 0.2023 - accuracy: 0.9175 - val_loss: 0.3732 - val_accuracy: 0.8508 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 3s - loss: 0.1968 - accuracy: 0.9202 - val_loss: 0.3795 - val_accuracy: 0.8491 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 3s - loss: 0.1907 - accuracy: 0.9230 - val_loss: 0.3869 - val_accuracy: 0.8491 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 3s - loss: 0.1888 - accuracy: 0.9228 - val_loss: 0.3917 - val_accuracy: 0.8489 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 3s - loss: 0.1838 - accuracy: 0.9254 - val_loss: 0.3996 - val_accuracy: 0.8472 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 3s - loss: 0.1805 - accuracy: 0.9266 - val_loss: 0.4036 - val_accuracy: 0.8467 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 3s - loss: 0.1770 - accuracy: 0.9283 - val_loss: 0.4089 - val_accuracy: 0.8454 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 3s - loss: 0.1740 - accuracy: 0.9306 - val_loss: 0.4140 - val_accuracy: 0.8453 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 3s - loss: 0.1660 - accuracy: 0.9338 - val_loss: 0.4145 - val_accuracy: 0.8462 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 3s - loss: 0.1655 - accuracy: 0.9340 - val_loss: 0.4153 - val_accuracy: 0.8461 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 3s - loss: 0.1655 - accuracy: 0.9335 - val_loss: 0.4161 - val_accuracy: 0.8460 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 5s - loss: 0.1638 - accuracy: 0.9357 - val_loss: 0.4174 - val_accuracy: 0.8458 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 4s - loss: 0.1650 - accuracy: 0.9342 - val_loss: 0.4187 - val_accuracy: 0.8462 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 3s - loss: 0.1636 - accuracy: 0.9352 - val_loss: 0.4194 - val_accuracy: 0.8458 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 3s - loss: 0.1627 - accuracy: 0.9360 - val_loss: 0.4192 - val_accuracy: 0.8449 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 4s - loss: 0.1626 - accuracy: 0.9355 - val_loss: 0.4207 - val_accuracy: 0.8462 - lr: 1.0000e-05 - 4s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 3s - loss: 0.1621 - accuracy: 0.9359 - val_loss: 0.4207 - val_accuracy: 0.8456 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 3s - loss: 0.1625 - accuracy: 0.9354 - val_loss: 0.4225 - val_accuracy: 0.8461 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 1ms/step - loss: 0.3348 - accuracy: 0.8590\n",
      "3637/3637 [==============================] - 5s 1ms/step - loss: 0.2923 - accuracy: 0.8762\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 256)               30464     \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,473\n",
      "Trainable params: 72,577\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 4s - loss: 0.3730 - accuracy: 0.8371 - val_loss: 0.3423 - val_accuracy: 0.8543 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 3s - loss: 0.3375 - accuracy: 0.8550 - val_loss: 0.3380 - val_accuracy: 0.8548 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 4s - loss: 0.3287 - accuracy: 0.8575 - val_loss: 0.3340 - val_accuracy: 0.8573 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 3s - loss: 0.3227 - accuracy: 0.8614 - val_loss: 0.3292 - val_accuracy: 0.8569 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 3s - loss: 0.3167 - accuracy: 0.8644 - val_loss: 0.3264 - val_accuracy: 0.8618 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 3s - loss: 0.3111 - accuracy: 0.8664 - val_loss: 0.3333 - val_accuracy: 0.8578 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 3s - loss: 0.3061 - accuracy: 0.8685 - val_loss: 0.3315 - val_accuracy: 0.8583 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 3s - loss: 0.3000 - accuracy: 0.8706 - val_loss: 0.3339 - val_accuracy: 0.8571 - lr: 0.0010 - 3s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 4s - loss: 0.2943 - accuracy: 0.8728 - val_loss: 0.3328 - val_accuracy: 0.8576 - lr: 0.0010 - 4s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 4s - loss: 0.2876 - accuracy: 0.8767 - val_loss: 0.3392 - val_accuracy: 0.8549 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 3s - loss: 0.2631 - accuracy: 0.8877 - val_loss: 0.3331 - val_accuracy: 0.8607 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 4s - loss: 0.2569 - accuracy: 0.8908 - val_loss: 0.3338 - val_accuracy: 0.8591 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 3s - loss: 0.2538 - accuracy: 0.8921 - val_loss: 0.3367 - val_accuracy: 0.8578 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "1164/1164 - 4s - loss: 0.2505 - accuracy: 0.8947 - val_loss: 0.3389 - val_accuracy: 0.8587 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 4s - loss: 0.2488 - accuracy: 0.8952 - val_loss: 0.3410 - val_accuracy: 0.8571 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 3s - loss: 0.2458 - accuracy: 0.8961 - val_loss: 0.3423 - val_accuracy: 0.8568 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 4s - loss: 0.2444 - accuracy: 0.8970 - val_loss: 0.3449 - val_accuracy: 0.8569 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 3s - loss: 0.2421 - accuracy: 0.8980 - val_loss: 0.3467 - val_accuracy: 0.8565 - lr: 1.0000e-04 - 3s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 4s - loss: 0.2399 - accuracy: 0.8994 - val_loss: 0.3482 - val_accuracy: 0.8562 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 4s - loss: 0.2380 - accuracy: 0.8996 - val_loss: 0.3496 - val_accuracy: 0.8543 - lr: 1.0000e-04 - 4s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 3s - loss: 0.2342 - accuracy: 0.9018 - val_loss: 0.3501 - val_accuracy: 0.8553 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 3s - loss: 0.2334 - accuracy: 0.9023 - val_loss: 0.3501 - val_accuracy: 0.8554 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 3s - loss: 0.2328 - accuracy: 0.9027 - val_loss: 0.3503 - val_accuracy: 0.8555 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 3s - loss: 0.2328 - accuracy: 0.9026 - val_loss: 0.3509 - val_accuracy: 0.8558 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 3s - loss: 0.2327 - accuracy: 0.9017 - val_loss: 0.3510 - val_accuracy: 0.8553 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 3s - loss: 0.2323 - accuracy: 0.9020 - val_loss: 0.3514 - val_accuracy: 0.8553 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 3s - loss: 0.2319 - accuracy: 0.9033 - val_loss: 0.3515 - val_accuracy: 0.8557 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 3s - loss: 0.2309 - accuracy: 0.9037 - val_loss: 0.3520 - val_accuracy: 0.8548 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 3s - loss: 0.2315 - accuracy: 0.9028 - val_loss: 0.3522 - val_accuracy: 0.8557 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 3s - loss: 0.2309 - accuracy: 0.9034 - val_loss: 0.3523 - val_accuracy: 0.8551 - lr: 1.0000e-05 - 3s/epoch - 3ms/step\n",
      "910/910 [==============================] - 1s 971us/step - loss: 0.3264 - accuracy: 0.8618\n",
      "3637/3637 [==============================] - 4s 931us/step - loss: 0.2988 - accuracy: 0.8718\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 512)               60928     \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 228,865\n",
      "Trainable params: 227,073\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 5s - loss: 0.3688 - accuracy: 0.8414 - val_loss: 0.3442 - val_accuracy: 0.8523 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3272 - accuracy: 0.8582 - val_loss: 0.3336 - val_accuracy: 0.8567 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3172 - accuracy: 0.8631 - val_loss: 0.3290 - val_accuracy: 0.8577 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 5s - loss: 0.3079 - accuracy: 0.8668 - val_loss: 0.3288 - val_accuracy: 0.8606 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 5s - loss: 0.2991 - accuracy: 0.8703 - val_loss: 0.3345 - val_accuracy: 0.8578 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.2906 - accuracy: 0.8748 - val_loss: 0.3345 - val_accuracy: 0.8559 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 5s - loss: 0.2801 - accuracy: 0.8793 - val_loss: 0.3402 - val_accuracy: 0.8576 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 5s - loss: 0.2674 - accuracy: 0.8846 - val_loss: 0.3494 - val_accuracy: 0.8557 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.2533 - accuracy: 0.8900 - val_loss: 0.3536 - val_accuracy: 0.8530 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 5s - loss: 0.2405 - accuracy: 0.8957 - val_loss: 0.3643 - val_accuracy: 0.8511 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 5s - loss: 0.1889 - accuracy: 0.9216 - val_loss: 0.3833 - val_accuracy: 0.8507 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 5s - loss: 0.1686 - accuracy: 0.9305 - val_loss: 0.4061 - val_accuracy: 0.8454 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 5s - loss: 0.1557 - accuracy: 0.9362 - val_loss: 0.4307 - val_accuracy: 0.8439 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 5s - loss: 0.1448 - accuracy: 0.9413 - val_loss: 0.4524 - val_accuracy: 0.8425 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 5s - loss: 0.1361 - accuracy: 0.9449 - val_loss: 0.4704 - val_accuracy: 0.8423 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 5s - loss: 0.1279 - accuracy: 0.9489 - val_loss: 0.4925 - val_accuracy: 0.8414 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 5s - loss: 0.1210 - accuracy: 0.9514 - val_loss: 0.5111 - val_accuracy: 0.8403 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.1147 - accuracy: 0.9545 - val_loss: 0.5314 - val_accuracy: 0.8387 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 5s - loss: 0.1078 - accuracy: 0.9576 - val_loss: 0.5476 - val_accuracy: 0.8379 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 5s - loss: 0.1026 - accuracy: 0.9594 - val_loss: 0.5679 - val_accuracy: 0.8378 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.0920 - accuracy: 0.9659 - val_loss: 0.5683 - val_accuracy: 0.8370 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.0912 - accuracy: 0.9656 - val_loss: 0.5718 - val_accuracy: 0.8376 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.0904 - accuracy: 0.9655 - val_loss: 0.5753 - val_accuracy: 0.8378 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 5s - loss: 0.0890 - accuracy: 0.9665 - val_loss: 0.5778 - val_accuracy: 0.8372 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.0894 - accuracy: 0.9659 - val_loss: 0.5790 - val_accuracy: 0.8373 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 5s - loss: 0.0876 - accuracy: 0.9671 - val_loss: 0.5833 - val_accuracy: 0.8381 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "1164/1164 - 5s - loss: 0.0868 - accuracy: 0.9680 - val_loss: 0.5862 - val_accuracy: 0.8374 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 5s - loss: 0.0868 - accuracy: 0.9675 - val_loss: 0.5883 - val_accuracy: 0.8369 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 5s - loss: 0.0864 - accuracy: 0.9672 - val_loss: 0.5912 - val_accuracy: 0.8369 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 5s - loss: 0.0857 - accuracy: 0.9683 - val_loss: 0.5945 - val_accuracy: 0.8362 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8606\n",
      "3637/3637 [==============================] - 4s 1ms/step - loss: 0.2843 - accuracy: 0.8770\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 512)               60928     \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 228,865\n",
      "Trainable params: 227,073\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1164/1164 - 6s - loss: 0.3760 - accuracy: 0.8358 - val_loss: 0.3413 - val_accuracy: 0.8531 - lr: 0.0010 - 6s/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3377 - accuracy: 0.8544 - val_loss: 0.3350 - val_accuracy: 0.8551 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3272 - accuracy: 0.8588 - val_loss: 0.3362 - val_accuracy: 0.8553 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 5s - loss: 0.3202 - accuracy: 0.8617 - val_loss: 0.3350 - val_accuracy: 0.8557 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 5s - loss: 0.3135 - accuracy: 0.8651 - val_loss: 0.3330 - val_accuracy: 0.8561 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 5s - loss: 0.3058 - accuracy: 0.8670 - val_loss: 0.3368 - val_accuracy: 0.8551 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 5s - loss: 0.2970 - accuracy: 0.8720 - val_loss: 0.3382 - val_accuracy: 0.8537 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 5s - loss: 0.2882 - accuracy: 0.8750 - val_loss: 0.3414 - val_accuracy: 0.8533 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.2786 - accuracy: 0.8800 - val_loss: 0.3444 - val_accuracy: 0.8542 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 5s - loss: 0.2680 - accuracy: 0.8849 - val_loss: 0.3510 - val_accuracy: 0.8513 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 5s - loss: 0.2284 - accuracy: 0.9051 - val_loss: 0.3534 - val_accuracy: 0.8538 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 5s - loss: 0.2118 - accuracy: 0.9124 - val_loss: 0.3633 - val_accuracy: 0.8533 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 5s - loss: 0.1992 - accuracy: 0.9186 - val_loss: 0.3729 - val_accuracy: 0.8516 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 5s - loss: 0.1894 - accuracy: 0.9228 - val_loss: 0.3833 - val_accuracy: 0.8499 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 5s - loss: 0.1814 - accuracy: 0.9264 - val_loss: 0.3948 - val_accuracy: 0.8478 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 5s - loss: 0.1740 - accuracy: 0.9303 - val_loss: 0.4043 - val_accuracy: 0.8463 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 5s - loss: 0.1665 - accuracy: 0.9322 - val_loss: 0.4153 - val_accuracy: 0.8454 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.1609 - accuracy: 0.9355 - val_loss: 0.4232 - val_accuracy: 0.8436 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 5s - loss: 0.1558 - accuracy: 0.9384 - val_loss: 0.4344 - val_accuracy: 0.8427 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 6s - loss: 0.1486 - accuracy: 0.9410 - val_loss: 0.4451 - val_accuracy: 0.8418 - lr: 1.0000e-04 - 6s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 5s - loss: 0.1391 - accuracy: 0.9456 - val_loss: 0.4464 - val_accuracy: 0.8425 - lr: 1.0000e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.1379 - accuracy: 0.9466 - val_loss: 0.4482 - val_accuracy: 0.8426 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.1375 - accuracy: 0.9472 - val_loss: 0.4491 - val_accuracy: 0.8424 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 5s - loss: 0.1367 - accuracy: 0.9480 - val_loss: 0.4499 - val_accuracy: 0.8417 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.1349 - accuracy: 0.9482 - val_loss: 0.4514 - val_accuracy: 0.8409 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 5s - loss: 0.1336 - accuracy: 0.9488 - val_loss: 0.4532 - val_accuracy: 0.8420 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 5s - loss: 0.1338 - accuracy: 0.9487 - val_loss: 0.4552 - val_accuracy: 0.8412 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 5s - loss: 0.1330 - accuracy: 0.9495 - val_loss: 0.4579 - val_accuracy: 0.8417 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 5s - loss: 0.1317 - accuracy: 0.9500 - val_loss: 0.4581 - val_accuracy: 0.8411 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 5s - loss: 0.1318 - accuracy: 0.9497 - val_loss: 0.4597 - val_accuracy: 0.8408 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 3s 2ms/step - loss: 0.3330 - accuracy: 0.8561\n",
      "3637/3637 [==============================] - 8s 2ms/step - loss: 0.2899 - accuracy: 0.8761\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 118)]             0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 512)               60928     \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 228,865\n",
      "Trainable params: 227,073\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1164/1164 - 5s - loss: 0.3737 - accuracy: 0.8372 - val_loss: 0.3414 - val_accuracy: 0.8534 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "1164/1164 - 5s - loss: 0.3377 - accuracy: 0.8544 - val_loss: 0.3348 - val_accuracy: 0.8571 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1164/1164 - 5s - loss: 0.3302 - accuracy: 0.8573 - val_loss: 0.3351 - val_accuracy: 0.8568 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1164/1164 - 4s - loss: 0.3224 - accuracy: 0.8618 - val_loss: 0.3355 - val_accuracy: 0.8566 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1164/1164 - 4s - loss: 0.3152 - accuracy: 0.8651 - val_loss: 0.3354 - val_accuracy: 0.8570 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1164/1164 - 4s - loss: 0.3085 - accuracy: 0.8668 - val_loss: 0.3316 - val_accuracy: 0.8569 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1164/1164 - 5s - loss: 0.3020 - accuracy: 0.8701 - val_loss: 0.3330 - val_accuracy: 0.8574 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1164/1164 - 5s - loss: 0.2949 - accuracy: 0.8730 - val_loss: 0.3334 - val_accuracy: 0.8581 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1164/1164 - 5s - loss: 0.2862 - accuracy: 0.8769 - val_loss: 0.3378 - val_accuracy: 0.8549 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1164/1164 - 5s - loss: 0.2773 - accuracy: 0.8810 - val_loss: 0.3452 - val_accuracy: 0.8541 - lr: 0.0010 - 5s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1164/1164 - 5s - loss: 0.2441 - accuracy: 0.8968 - val_loss: 0.3411 - val_accuracy: 0.8560 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1164/1164 - 5s - loss: 0.2317 - accuracy: 0.9026 - val_loss: 0.3474 - val_accuracy: 0.8555 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1164/1164 - 5s - loss: 0.2245 - accuracy: 0.9062 - val_loss: 0.3530 - val_accuracy: 0.8545 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1164/1164 - 5s - loss: 0.2202 - accuracy: 0.9080 - val_loss: 0.3576 - val_accuracy: 0.8532 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1164/1164 - 4s - loss: 0.2140 - accuracy: 0.9116 - val_loss: 0.3637 - val_accuracy: 0.8515 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1164/1164 - 4s - loss: 0.2100 - accuracy: 0.9128 - val_loss: 0.3685 - val_accuracy: 0.8512 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1164/1164 - 4s - loss: 0.2051 - accuracy: 0.9150 - val_loss: 0.3725 - val_accuracy: 0.8488 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1164/1164 - 5s - loss: 0.2017 - accuracy: 0.9168 - val_loss: 0.3779 - val_accuracy: 0.8489 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1164/1164 - 5s - loss: 0.1983 - accuracy: 0.9182 - val_loss: 0.3836 - val_accuracy: 0.8493 - lr: 1.0000e-04 - 5s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1164/1164 - 4s - loss: 0.1953 - accuracy: 0.9202 - val_loss: 0.3884 - val_accuracy: 0.8481 - lr: 1.0000e-04 - 4s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1164/1164 - 4s - loss: 0.1867 - accuracy: 0.9234 - val_loss: 0.3882 - val_accuracy: 0.8479 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1164/1164 - 5s - loss: 0.1861 - accuracy: 0.9244 - val_loss: 0.3892 - val_accuracy: 0.8484 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1164/1164 - 5s - loss: 0.1853 - accuracy: 0.9249 - val_loss: 0.3898 - val_accuracy: 0.8477 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1164/1164 - 5s - loss: 0.1844 - accuracy: 0.9251 - val_loss: 0.3906 - val_accuracy: 0.8473 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1164/1164 - 5s - loss: 0.1847 - accuracy: 0.9252 - val_loss: 0.3914 - val_accuracy: 0.8475 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1164/1164 - 5s - loss: 0.1840 - accuracy: 0.9259 - val_loss: 0.3924 - val_accuracy: 0.8481 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1164/1164 - 5s - loss: 0.1838 - accuracy: 0.9262 - val_loss: 0.3931 - val_accuracy: 0.8478 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1164/1164 - 5s - loss: 0.1840 - accuracy: 0.9257 - val_loss: 0.3935 - val_accuracy: 0.8477 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1164/1164 - 4s - loss: 0.1827 - accuracy: 0.9259 - val_loss: 0.3940 - val_accuracy: 0.8472 - lr: 1.0000e-05 - 4s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1164/1164 - 5s - loss: 0.1821 - accuracy: 0.9260 - val_loss: 0.3947 - val_accuracy: 0.8470 - lr: 1.0000e-05 - 5s/epoch - 4ms/step\n",
      "910/910 [==============================] - 3s 3ms/step - loss: 0.3334 - accuracy: 0.8581\n",
      "3637/3637 [==============================] - 5s 1ms/step - loss: 0.2673 - accuracy: 0.8868\n"
     ]
    }
   ],
   "source": [
    "best_function= None\n",
    "best_unit = None\n",
    "best = 0\n",
    "units = [64,128]\n",
    "functions = ['relu', 'tanh', 'sigmoid']\n",
    "f= open(\"median_onehot_0.txt\",\"w+\")\n",
    "for unit in units:\n",
    "    for func in functions:\n",
    "        f.write(' unit, activation function, features , train accuracy, test accuracy \\n' )\n",
    "        df_train, df_test = train_test_split(df1,test_size=0.2, random_state=0)\n",
    "        X_train = df_train.drop([\"RainTomorrow\"], axis=1)\n",
    "        y_train = df_train.RainTomorrow\n",
    "        X_test = df_test.drop([\"RainTomorrow\"], axis=1)\n",
    "        y_test = df_test.RainTomorrow\n",
    "\n",
    "        X_train,X_test = handle_nan(X_train, X_test)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train= scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        num_features = X_train.shape[1]\n",
    "\n",
    "        model = fully_dense_model(num_features, (X_train,y_train), (X_test, y_test), units = unit,activation = func )\n",
    "        loss, test_accuracy = model.evaluate(X_test,y_test)\n",
    "        _, train_accuracy = model.evaluate(X_train, y_train)\n",
    "        string = str(unit) + ' ' + func+ ' ' +str(num_features)+' '+str(train_accuracy)+ ' '+str(test_accuracy)+'\\n'\n",
    "        f.write(string)\n",
    "        \n",
    "        if best < test_accuracy:\n",
    "            best = test_accuracy\n",
    "            best_unit = unit\n",
    "            best_function = func\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f43147e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy:  0.8618176579475403 best unit 64 best function sigmoid\n"
     ]
    }
   ],
   "source": [
    "print('best accuracy: ', best, 'best unit', best_unit, 'best function', best_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d498d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
